/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --funasr-nano-encoder-adaptor=./sherpa-onnx-funasr-nano-int8-2025-12-30/encoder_adaptor.int8.onnx --funasr-nano-llm=./sherpa-onnx-funasr-nano-int8-2025-12-30/llm.int8.onnx --funasr-nano-tokenizer=./sherpa-onnx-funasr-nano-int8-2025-12-30/Qwen3-0.6B --funasr-nano-embedding=./sherpa-onnx-funasr-nano-int8-2025-12-30/embedding.int8.onnx ./sherpa-onnx-funasr-nano-int8-2025-12-30/test_wavs/lyrics_en_3.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename="", decoder_filename="", joiner_filename=""), paraformer=OfflineParaformerModelConfig(model=""), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=""), whisper=OfflineWhisperModelConfig(encoder="", decoder="", language="", task="transcribe", tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder="", decoder=""), tdnn=OfflineTdnnModelConfig(model=""), zipformer_ctc=OfflineZipformerCtcModelConfig(model=""), wenet_ctc=OfflineWenetCtcModelConfig(model=""), sense_voice=OfflineSenseVoiceModelConfig(model="", language="auto", use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor="", encoder="", uncached_decoder="", cached_decoder=""), dolphin=OfflineDolphinModelConfig(model=""), canary=OfflineCanaryModelConfig(encoder="", decoder="", src_lang="", tgt_lang="", use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=""), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor="./sherpa-onnx-funasr-nano-int8-2025-12-30/encoder_adaptor.int8.onnx", llm="./sherpa-onnx-funasr-nano-int8-2025-12-30/llm.int8.onnx", embedding="./sherpa-onnx-funasr-nano-int8-2025-12-30/embedding.int8.onnx", tokenizer="./sherpa-onnx-funasr-nano-int8-2025-12-30/Qwen3-0.6B", system_prompt="You are a helpful assistant.", user_prompt="语音转写：", max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=""), telespeech_ctc="", tokens="", num_threads=2, debug=False, provider="cpu", model_type="", modeling_unit="cjkchar", bpe_vocab=""), lm_config=OfflineLMConfig(model="", scale=0.5, lodr_scale=0.01, lodr_fst="", lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph="", max_active=3000), decoding_method="greedy_search", max_active_paths=4, hotwords_file="", hotwords_score=1.5, blank_penalty=0, rule_fsts="", rule_fars="", hr=HomophoneReplacerConfig(lexicon="", rule_fsts=""))
Creating recognizer ...
recognizer created in 1.758 s
Started
Done!

./sherpa-onnx-funasr-nano-int8-2025-12-30/test_wavs/lyrics_en_3.wav
{"lang": "", "emotion": "", "event": "", "text": "An empty street, an empty house, a hole inside my heart. I'm all alone, the rooms are getting smaller. I wonder how, I wonder why, I wonder where they are. The days we had, the songs we sang together.", "timestamps": [0.00, 0.50, 0.99, 1.49, 1.99, 2.49, 2.98, 3.48, 3.98, 4.47, 4.97, 5.47, 5.96, 6.46, 6.96, 7.45, 7.95, 8.45, 8.95, 9.44, 9.94, 10.44, 10.93, 11.43, 11.93, 12.43, 12.92, 13.42, 13.92, 14.41, 14.91, 15.41, 15.90, 16.40, 16.90, 17.40, 17.89, 18.39, 18.89, 19.38, 19.88, 20.38, 20.87, 21.37, 21.87, 22.36, 22.86, 23.36, 23.86, 24.35], "durations": [], "tokens":["An", "empty", "street", ",", "an", "empty", "house", ",", "a", "hole", "inside", "my", "heart", ".", "I", "'m", "all", "alone", ",", "the", "rooms", "are", "getting", "smaller", ".", "I", "wonder", "how", ",", "I", "wonder", "why", ",", "I", "wonder", "where", "they", "are", ".", "The", "days", "we", "had", ",", "the", "songs", "we", "sang", "together", "."], "ys_log_probs": [], "words": []}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 4.418 s
Real time factor (RTF): 4.418 / 24.882 = 0.178
