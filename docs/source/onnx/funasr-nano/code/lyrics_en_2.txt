/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --funasr-nano-encoder-adaptor=./sherpa-onnx-funasr-nano-int8-2025-12-30/encoder_adaptor.int8.onnx --funasr-nano-llm=./sherpa-onnx-funasr-nano-int8-2025-12-30/llm.int8.onnx --funasr-nano-tokenizer=./sherpa-onnx-funasr-nano-int8-2025-12-30/Qwen3-0.6B --funasr-nano-embedding=./sherpa-onnx-funasr-nano-int8-2025-12-30/embedding.int8.onnx ./sherpa-onnx-funasr-nano-int8-2025-12-30/test_wavs/lyrics_en_2.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename="", decoder_filename="", joiner_filename=""), paraformer=OfflineParaformerModelConfig(model=""), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=""), whisper=OfflineWhisperModelConfig(encoder="", decoder="", language="", task="transcribe", tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder="", decoder=""), tdnn=OfflineTdnnModelConfig(model=""), zipformer_ctc=OfflineZipformerCtcModelConfig(model=""), wenet_ctc=OfflineWenetCtcModelConfig(model=""), sense_voice=OfflineSenseVoiceModelConfig(model="", language="auto", use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor="", encoder="", uncached_decoder="", cached_decoder=""), dolphin=OfflineDolphinModelConfig(model=""), canary=OfflineCanaryModelConfig(encoder="", decoder="", src_lang="", tgt_lang="", use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=""), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor="./sherpa-onnx-funasr-nano-int8-2025-12-30/encoder_adaptor.int8.onnx", llm="./sherpa-onnx-funasr-nano-int8-2025-12-30/llm.int8.onnx", embedding="./sherpa-onnx-funasr-nano-int8-2025-12-30/embedding.int8.onnx", tokenizer="./sherpa-onnx-funasr-nano-int8-2025-12-30/Qwen3-0.6B", system_prompt="You are a helpful assistant.", user_prompt="语音转写：", max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=""), telespeech_ctc="", tokens="", num_threads=2, debug=False, provider="cpu", model_type="", modeling_unit="cjkchar", bpe_vocab=""), lm_config=OfflineLMConfig(model="", scale=0.5, lodr_scale=0.01, lodr_fst="", lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph="", max_active=3000), decoding_method="greedy_search", max_active_paths=4, hotwords_file="", hotwords_score=1.5, blank_penalty=0, rule_fsts="", rule_fars="", hr=HomophoneReplacerConfig(lexicon="", rule_fsts=""))
Creating recognizer ...
recognizer created in 1.707 s
Started
Done!

./sherpa-onnx-funasr-nano-int8-2025-12-30/test_wavs/lyrics_en_2.wav
{"lang": "", "emotion": "", "event": "", "text": "I see your monsters, I see your pain, tell me your problems, I'll chase them away. I'll be your lighthouse, I'll make it okay. When I see your monsters, I'll stand there so brave and chase them all away.", "timestamps": [0.00, 0.42, 0.83, 1.25, 1.67, 2.08, 2.50, 2.92, 3.33, 3.75, 4.17, 4.58, 5.00, 5.42, 5.83, 6.25, 6.67, 7.08, 7.50, 7.92, 8.33, 8.75, 9.17, 9.58, 10.00, 10.42, 10.84, 11.25, 11.67, 12.09, 12.50, 12.92, 13.34, 13.75, 14.17, 14.59, 15.00, 15.42, 15.84, 16.25, 16.67, 17.09, 17.50, 17.92, 18.34, 18.75, 19.17, 19.59, 20.00, 20.42, 20.84, 21.25], "durations": [], "tokens":["I", "see", "your", "monsters", ",", "I", "see", "your", "pain", ",", "tell", "me", "your", "problems", ",", "I", "'ll", "chase", "them", "away", ".", "I", "'ll", "be", "your", "l", "ighthouse", ",", "I", "'ll", "make", "it", "okay", ".", "When", "I", "see", "your", "monsters", ",", "I", "'ll", "stand", "there", "so", "brave", "and", "chase", "them", "all", "away", "."], "ys_log_probs": [], "words": []}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 3.741 s
Real time factor (RTF): 3.741 / 21.711 = 0.172
