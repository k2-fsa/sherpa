/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --funasr-nano-encoder-adaptor=./sherpa-onnx-funasr-nano-int8-2025-12-30/encoder_adaptor.int8.onnx --funasr-nano-llm=./sherpa-onnx-funasr-nano-int8-2025-12-30/llm.int8.onnx --funasr-nano-tokenizer=./sherpa-onnx-funasr-nano-int8-2025-12-30/Qwen3-0.6B --funasr-nano-embedding=./sherpa-onnx-funasr-nano-int8-2025-12-30/embedding.int8.onnx ./sherpa-onnx-funasr-nano-int8-2025-12-30/test_wavs/noise_en.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename="", decoder_filename="", joiner_filename=""), paraformer=OfflineParaformerModelConfig(model=""), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=""), whisper=OfflineWhisperModelConfig(encoder="", decoder="", language="", task="transcribe", tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder="", decoder=""), tdnn=OfflineTdnnModelConfig(model=""), zipformer_ctc=OfflineZipformerCtcModelConfig(model=""), wenet_ctc=OfflineWenetCtcModelConfig(model=""), sense_voice=OfflineSenseVoiceModelConfig(model="", language="auto", use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor="", encoder="", uncached_decoder="", cached_decoder=""), dolphin=OfflineDolphinModelConfig(model=""), canary=OfflineCanaryModelConfig(encoder="", decoder="", src_lang="", tgt_lang="", use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=""), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor="./sherpa-onnx-funasr-nano-int8-2025-12-30/encoder_adaptor.int8.onnx", llm="./sherpa-onnx-funasr-nano-int8-2025-12-30/llm.int8.onnx", embedding="./sherpa-onnx-funasr-nano-int8-2025-12-30/embedding.int8.onnx", tokenizer="./sherpa-onnx-funasr-nano-int8-2025-12-30/Qwen3-0.6B", system_prompt="You are a helpful assistant.", user_prompt="语音转写：", max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=""), telespeech_ctc="", tokens="", num_threads=2, debug=False, provider="cpu", model_type="", modeling_unit="cjkchar", bpe_vocab=""), lm_config=OfflineLMConfig(model="", scale=0.5, lodr_scale=0.01, lodr_fst="", lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph="", max_active=3000), decoding_method="greedy_search", max_active_paths=4, hotwords_file="", hotwords_score=1.5, blank_penalty=0, rule_fsts="", rule_fars="", hr=HomophoneReplacerConfig(lexicon="", rule_fsts=""))
Creating recognizer ...
recognizer created in 1.661 s
Started
Done!

./sherpa-onnx-funasr-nano-int8-2025-12-30/test_wavs/noise_en.wav
{"lang": "", "emotion": "", "event": "", "text": "So what's interesting here is, I feel that you know brands knowing this when people sort of speak to the voice assistants at home, and if you want to be the brand.", "timestamps": [0.00, 0.29, 0.59, 0.88, 1.17, 1.47, 1.76, 2.06, 2.35, 2.64, 2.94, 3.23, 3.52, 3.82, 4.11, 4.40, 4.70, 4.99, 5.28, 5.58, 5.87, 6.17, 6.46, 6.75, 7.05, 7.34, 7.63, 7.93, 8.22, 8.51, 8.81, 9.10, 9.40, 9.69, 9.98, 10.28], "durations": [], "tokens":["So", "what", "'s", "interesting", "here", "is", ",", "I", "feel", "that", "you", "know", "brands", "knowing", "this", "when", "people", "sort", "of", "speak", "to", "the", "voice", "assistants", "at", "home", ",", "and", "if", "you", "want", "to", "be", "the", "brand", "."], "ys_log_probs": [], "words": []}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.968 s
Real time factor (RTF): 1.968 / 10.568 = 0.186
