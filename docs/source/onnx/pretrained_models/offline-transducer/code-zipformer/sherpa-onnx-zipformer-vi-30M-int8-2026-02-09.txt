/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-vi-30M-int8-2026-02-09/tokens.txt --encoder=./sherpa-onnx-zipformer-vi-30M-int8-2026-02-09/encoder.int8.onnx --decoder=./sherpa-onnx-zipformer-vi-30M-int8-2026-02-09/decoder.onnx --joiner=./sherpa-onnx-zipformer-vi-30M-int8-2026-02-09/joiner.int8.onnx --num-threads=1 ./sherpa-onnx-zipformer-vi-30M-int8-2026-02-09/test_wavs/0.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename="./sherpa-onnx-zipformer-vi-30M-int8-2026-02-09/encoder.int8.onnx", decoder_filename="./sherpa-onnx-zipformer-vi-30M-int8-2026-02-09/decoder.onnx", joiner_filename="./sherpa-onnx-zipformer-vi-30M-int8-2026-02-09/joiner.int8.onnx"), paraformer=OfflineParaformerModelConfig(model=""), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=""), whisper=OfflineWhisperModelConfig(encoder="", decoder="", language="", task="transcribe", tail_paddings=-1, enable_token_timestamps=False, enable_segment_timestamps=False), fire_red_asr=OfflineFireRedAsrModelConfig(encoder="", decoder=""), tdnn=OfflineTdnnModelConfig(model=""), zipformer_ctc=OfflineZipformerCtcModelConfig(model=""), wenet_ctc=OfflineWenetCtcModelConfig(model=""), sense_voice=OfflineSenseVoiceModelConfig(model="", language="auto", use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor="", encoder="", uncached_decoder="", cached_decoder=""), dolphin=OfflineDolphinModelConfig(model=""), canary=OfflineCanaryModelConfig(encoder="", decoder="", src_lang="", tgt_lang="", use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=""), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor="", llm="", embedding="", tokenizer="", system_prompt="You are a helpful assistant.", user_prompt="语音转写：", max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42, language="", itn=True, hotwords=""), medasr=OfflineMedAsrCtcModelConfig(model=""), telespeech_ctc="", tokens="./sherpa-onnx-zipformer-vi-30M-int8-2026-02-09/tokens.txt", num_threads=1, debug=False, provider="cpu", model_type="", modeling_unit="cjkchar", bpe_vocab=""), lm_config=OfflineLMConfig(model="", scale=0.5, lodr_scale=0.01, lodr_fst="", lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph="", max_active=3000), decoding_method="greedy_search", max_active_paths=4, hotwords_file="", hotwords_score=1.5, blank_penalty=0, rule_fsts="", rule_fars="", hr=HomophoneReplacerConfig(lexicon="", rule_fsts=""))
Creating recognizer ...
recognizer created in 0.499 s
Started
Done!

./sherpa-onnx-zipformer-vi-30M-int8-2026-02-09/test_wavs/0.wav
{"lang": "", "emotion": "", "event": "", "text": " RỒI CŨNG HỖ TRỢ CHO LÂU LÂU CŨNG CHO GẠO CHO NÀY KIA", "timestamps": [0.00, 0.16, 0.48, 0.64, 1.00, 1.28, 1.44, 1.76, 1.96, 2.24, 2.28, 2.36, 2.60, 2.92, 3.28], "durations": [], "tokens":[" RỒI", " CŨNG", " HỖ", " TRỢ", " CHO", " LÂU", " LÂU", " CŨNG", " CHO", " G", "Ạ", "O", " CHO", " NÀY", " KIA"], "ys_log_probs": [-0.005669, -0.000495, -0.000783, -0.612615, -0.431208, -0.005395, -0.160663, -0.000072, -0.000384, -0.000350, -0.000093, -0.017432, -0.000839, -0.001392, -0.000243], "words": []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.041 s
Real time factor (RTF): 0.041 / 3.740 = 0.011
