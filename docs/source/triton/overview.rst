
.. _triton_overview:

Triton
======

Nvidia `Triton`_ Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.


The following content describes how to deploy ASR models trained by `icefall`_ using Triton.


.. toctree::
   :maxdepth: 2
   :caption: Environment Preparetion

   ./installation/index


.. toctree::
   :maxdepth: 2
   :caption: Triton Server

   ./server/index


.. toctree::
   :maxdepth: 2
   :caption: Triton Client

   ./client/index


.. toctree::
   :maxdepth: 2
   :caption: Benchmark with Perf Analyzer

   ./perf/index

.. toctree::
   :maxdepth: 2
   :caption: TensorRT acceleration

   ./trt/index
