# Copyright      2022  Xiaomi Corp.       (author: Fangjun Kuang)

# See ../../LICENSE for clarification regarding multiple authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
name: Run streaming ASR tests with very long waves

on:
  push:
    branches:
      - master
  pull_request:
    types: [labeled]

jobs:
  run_streaming_asr_tests_with_long_test_waves:
    if: github.event.label.name == 'ready' || github.event_name == 'push'
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-18.04]
        torch: ["1.10.0", "1.6.0"]
        torchaudio: ["0.10.0", "0.6.0"]
        python-version: ["3.8"]
        decoding: ["greedy_search", "modified_beam_search"]
        exclude:
          - torch: "1.10.0"
            torchaudio: "0.6.0"
          - torch: "1.6.0"
            torchaudio: "0.10.0"
          - torch: "1.6.0"
            python-version: "3.9"

    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install GCC 7
        if: startsWith(matrix.os, 'ubuntu')
        run: |
          sudo apt-get install -y gcc-7 g++-7
          echo "CC=/usr/bin/gcc-7" >> $GITHUB_ENV
          echo "CXX=/usr/bin/g++-7" >> $GITHUB_ENV

      - name: Install PyTorch ${{ matrix.torch }}
        shell: bash
        if: startsWith(matrix.os, 'ubuntu')
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install wheel twine typing_extensions websockets sentencepiece>=0.1.96
          python3 -m pip install torch==${{ matrix.torch }}+cpu numpy -f https://download.pytorch.org/whl/cpu/torch_stable.html

          pip install k2==1.16.dev20220621+cpu.torch${{ matrix.torch }} -f https://k2-fsa.org/nightly/index.html

          python3 -m torch.utils.collect_env
          .github/scripts/install-icefall.sh

          if [[ ${{ matrix.torchaudio }} == "0.10.0" ]]; then
            pip install torchaudio==${{ matrix.torchaudio }}+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html
          else
            pip install torchaudio==${{ matrix.torchaudio }}
          fi

      - name: Install PyTorch ${{ matrix.torch }}
        shell: bash
        if: startsWith(matrix.os, 'macos')
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install wheel twine typing_extensions websockets sentencepiece>=0.1.96
          python3 -m pip install torch==${{ matrix.torch }} torchaudio==${{ matrix.torchaudio }} numpy -f https://download.pytorch.org/whl/cpu/torch_stable.html

          pip install k2==1.16.dev20220621+cpu.torch${{ matrix.torch }} -f https://k2-fsa.org/nightly/index.html

          python3 -m torch.utils.collect_env
          .github/scripts/install-icefall.sh

      - name: Cache kaldifeat
        id: my-cache
        uses: actions/cache@v2
        with:
          path: |
            ~/tmp/kaldifeat
          key: cache-tmp-${{ matrix.python-version }}-${{ matrix.os }}-${{ matrix.torch }}

      - name: Install kaldifeat
        if: steps.my-cache.outputs.cache-hit != 'true'
        shell: bash
        run: |
          .github/scripts/install-kaldifeat.sh

      - name: Install sherpa
        shell: bash
        run: |
          python3 setup.py install

      - name: Download pretrained model
        shell: bash
        run: |
          git lfs install
          git clone https://huggingface.co/csukuangfj/icefall-asr-librispeech-pruned-stateless-emformer-rnnt2-2022-06-01

      - name: Download test data
        shell: bash
        run: |
          git lfs install
          git clone https://huggingface.co/csukuangfj/sherpa-long-audio-test-data

      - name: Start server
        shell: bash
        run: |
          export PYTHONPATH=~/tmp/kaldifeat/kaldifeat/python:$PYTHONPATH
          export PYTHONPATH=~/tmp/kaldifeat/build/lib:$PYTHONPATH
          export PYTHONPATH=~/tmp/icefall/:$PYTHONPATH

          ./sherpa/bin/pruned_stateless_emformer_rnnt2/streaming_server.py \
            --decoding-method ${{ matrix.decoding }} \
            --port 6006 \
            --max-batch-size 50 \
            --max-wait-ms 5 \
            --nn-pool-size 1 \
            --nn-model-filename ./icefall-asr-librispeech-pruned-stateless-emformer-rnnt2-2022-06-01/exp/cpu_jit-epoch-39-avg-6-use-averaged-model-1-torch-${{ matrix.torch }}.pt \
            --bpe-model-filename ./icefall-asr-librispeech-pruned-stateless-emformer-rnnt2-2022-06-01/data/lang_bpe_500/bpe.model &

          echo "Sleep 10 seconds to wait for the server startup"
          sleep 10

      - name: Start client (10-minutes.wav)
        shell: bash
        run: |
          ./sherpa/bin/pruned_stateless_emformer_rnnt2/streaming_client.py \
            --server-addr localhost \
            --server-port 6006 \
            ./sherpa-long-audio-test-data/10-minutes.wav

      # - name: Start client (20-minutes.wav)
      #   shell: bash
      #   run: |
      #     ./sherpa/bin/pruned_stateless_emformer_rnnt2/streaming_client.py \
      #       --server-addr localhost \
      #       --server-port 6006 \
      #       ./sherpa-long-audio-test-data/20-minutes.wav
      #
      # - name: Start client (30-minutes.wav)
      #   shell: bash
      #   run: |
      #     ./sherpa/bin/pruned_stateless_emformer_rnnt2/streaming_client.py \
      #       --server-addr localhost \
      #       --server-port 6006 \
      #       ./sherpa-long-audio-test-data/30-minutes.wav
