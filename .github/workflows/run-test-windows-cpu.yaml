# Copyright      2022  Xiaomi Corp.       (author: Fangjun Kuang)

# See ../../LICENSE for clarification regarding multiple authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
name: Run tests windows cpu

on:
  push:
    branches:
      - master
    paths:
      - '.github/workflows/run-test-windows-cpu.yaml'
      - 'CMakeLists.txt'
      - 'cmake/**'
      - 'sherpa/csrc/**'
      - 'sherpa/cpp_api/**'
      - 'sherpa/bin/pruned_transducer_statelessX/**'
      - 'sherpa/python/**'
  pull_request:
    types: [labeled]
    paths:
      - '.github/workflows/run-test-windows-cpu.yaml'
      - 'CMakeLists.txt'
      - 'cmake/**'
      - 'sherpa/csrc/**'
      - 'sherpa/cpp_api/**'
      - 'sherpa/bin/pruned_transducer_statelessX/**'
      - 'sherpa/python/**'

concurrency:
  group: run_tests_windows_cpu-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run_tests_windows_cpu:
    if: github.event.label.name == 'ready' || github.event.label.name == 'windows' || github.event_name == 'push'
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [windows-2019]
        decoding: ["greedy_search", "modified_beam_search"]
        torch: ["1.13.1"]
        torchaudio: ["0.13.1"]
        python-version: [3.7, 3.8, 3.9]
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      # see https://github.com/microsoft/setup-msbuild
      - name: Add msbuild to PATH
        uses: microsoft/setup-msbuild@v1.0.2

      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Display Python version
        run: python -c "import sys; print(sys.version)"

      - name: Install PyTorch ${{ matrix.torch }}
        shell: bash
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install wheel twine typing_extensions websockets sentencepiece>=0.1.96 soundfile
          python3 -m pip install torch==${{ matrix.torch }}+cpu torchaudio==${{ matrix.torchaudio }}+cpu numpy -f https://download.pytorch.org/whl/cpu/torch_stable.html

          python3 -m pip install k2==1.23.3.dev20230127+cpu.torch${{ matrix.torch }} -f https://k2-fsa.org/nightly/index.html

          python3 -m torch.utils.collect_env


      - name: Install kaldifeat
        shell: bash
        run: |
          python3 -m pip install --verbose kaldifeat

      - name: Install sherpa
        shell: bash
        run: |
          python3 setup.py install

      - name: Download pretrained model and test-data
        shell: bash
        run: |
          git lfs install
          git clone https://huggingface.co/csukuangfj/icefall-asr-librispeech-pruned-transducer-stateless3-2022-05-13

      - name: Start server
        shell: bash
        run: |
          export PYTHONPATH=~/tmp/kaldifeat/kaldifeat/python:$PYTHONPATH
          export PYTHONPATH=~/tmp/kaldifeat/build/lib:$PYTHONPATH

          sherpa/bin/pruned_transducer_statelessX/offline_server.py \
            --decoding-method ${{ matrix.decoding }} \
            --port 6006 \
            --num-device 0 \
            --max-batch-size 10 \
            --max-wait-ms 5 \
            --feature-extractor-pool-size 5 \
            --nn-pool-size 1 \
            --nn-model-filename ./icefall-asr-librispeech-pruned-transducer-stateless3-2022-05-13/exp/cpu_jit.pt \
            --lang-dir ./icefall-asr-librispeech-pruned-transducer-stateless3-2022-05-13/data/lang_bpe_500/ \
            --bpe-model-filename ./icefall-asr-librispeech-pruned-transducer-stateless3-2022-05-13/data/lang_bpe_500/bpe.model &
          echo "Sleep 10 seconds to wait for the server startup"
          sleep 10

      - name: Start client
        shell: bash
        run: |
          sherpa/bin/pruned_transducer_statelessX/offline_client.py \
            --server-addr localhost \
            --server-port 6006 \
            icefall-asr-librispeech-pruned-transducer-stateless3-2022-05-13/test_wavs/1089-134686-0001.wav \
            icefall-asr-librispeech-pruned-transducer-stateless3-2022-05-13/test_wavs/1221-135766-0001.wav \
            icefall-asr-librispeech-pruned-transducer-stateless3-2022-05-13/test_wavs/1221-135766-0002.wav
