# Copyright      2022  Xiaomi Corp.       (author: Fangjun Kuang)

# See ../../LICENSE for clarification regarding multiple authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
name: Test aishell offline asr

on:
  push:
    branches:
      - master
  pull_request:
    types: [labeled]

jobs:
  run_tests_aishell_offline_asr:
    if: github.event.label.name == 'ready' || github.event_name == 'push'
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-18.04, macos-latest]
        decoding: ["greedy_search", "modified_beam_search"]
        torch: ["1.10.0", "1.6.0"]
        torchaudio: ["0.10.0", "0.6.0"]
        python-version: ["3.7", "3.8", "3.9"]
        exclude:
          - torch: "1.10.0"
            torchaudio: "0.6.0"
          - torch: "1.6.0"
            torchaudio: "0.10.0"
          - torch: "1.6.0"
            python-version: "3.9"
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install GCC 7
        if: startsWith(matrix.os, 'ubuntu')
        run: |
          sudo apt-get install -y gcc-7 g++-7
          echo "CC=/usr/bin/gcc-7" >> $GITHUB_ENV
          echo "CXX=/usr/bin/g++-7" >> $GITHUB_ENV

      - name: Install PyTorch ${{ matrix.torch }}
        shell: bash
        if: startsWith(matrix.os, 'ubuntu')
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install wheel twine typing_extensions websockets sentencepiece>=0.1.96
          python3 -m pip install torch==${{ matrix.torch }}+cpu numpy -f https://download.pytorch.org/whl/cpu/torch_stable.html


          pip install k2==1.16.dev20220621+cpu.torch${{ matrix.torch }} -f https://k2-fsa.org/nightly/index.html
          if [[ ${{ matrix.torchaudio }} == "0.10.0" ]]; then
            pip install torchaudio==${{ matrix.torchaudio }}+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html
          else
            pip install torchaudio==${{ matrix.torchaudio }}
          fi

          python3 -m torch.utils.collect_env


      - name: Install PyTorch ${{ matrix.torch }}
        shell: bash
        if: startsWith(matrix.os, 'macos')
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install wheel twine typing_extensions websockets sentencepiece>=0.1.96
          python3 -m pip install torch==${{ matrix.torch }} torchaudio==${{ matrix.torchaudio }} numpy -f https://download.pytorch.org/whl/cpu/torch_stable.html

          pip install k2==1.16.dev20220621+cpu.torch${{ matrix.torch }} -f https://k2-fsa.org/nightly/index.html

          python3 -m torch.utils.collect_env


      - name: Cache kaldifeat
        id: my-cache
        uses: actions/cache@v2
        with:
          path: |
            ~/tmp/kaldifeat
          key: cache-tmp-${{ matrix.python-version }}-${{ matrix.os }}-${{ matrix.torch }}

      - name: Install kaldifeat
        if: steps.my-cache.outputs.cache-hit != 'true'
        shell: bash
        run: |
          .github/scripts/install-kaldifeat.sh

      - name: Install sherpa
        shell: bash
        run: |
          python3 setup.py install

      - name: Download pretrained model and test-data
        shell: bash
        run: |
          git lfs install
          git clone https://huggingface.co/csukuangfj/icefall-aishell-pruned-transducer-stateless3-2022-06-20

      - name: Start server
        shell: bash
        run: |
          export PYTHONPATH=~/tmp/kaldifeat/kaldifeat/python:$PYTHONPATH
          export PYTHONPATH=~/tmp/kaldifeat/build/lib:$PYTHONPATH

          sherpa/bin/pruned_transducer_statelessX/offline_server.py \
            --decoding-method ${{ matrix.decoding }} \
            --port 6006 \
            --num-device 0 \
            --max-batch-size 10 \
            --max-wait-ms 5 \
            --feature-extractor-pool-size 5 \
            --nn-pool-size 1 \
            --nn-model-filename ./icefall-aishell-pruned-transducer-stateless3-2022-06-20/exp/cpu_jit-epoch-29-avg-5-torch-1.6.0.pt \
            --token-filename ./icefall-aishell-pruned-transducer-stateless3-2022-06-20/data/lang_char/tokens.txt &

          echo "Sleep 10 seconds to wait for the server startup"
          sleep 10

      - name: Start client
        shell: bash
        run: |
          sherpa/bin/pruned_transducer_statelessX/offline_client.py \
            --server-addr localhost \
            --server-port 6006 \
            ./icefall-aishell-pruned-transducer-stateless3-2022-06-20/test_wavs/BAC009S0764W0121.wav \
            ./icefall-aishell-pruned-transducer-stateless3-2022-06-20/test_wavs/BAC009S0764W0122.wav \
            ./icefall-aishell-pruned-transducer-stateless3-2022-06-20/test_wavs/BAC009S0764W0123.wav
