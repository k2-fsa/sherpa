# Copyright      2022  Xiaomi Corp.       (author: Fangjun Kuang)

# See ../../LICENSE for clarification regarding multiple authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
name: Test aishell offline asr

on:
  push:
    branches:
      - master
    paths:
      - '.github/workflows/run-test-aishell.yaml'
      - 'CMakeLists.txt'
      - 'cmake/**'
      - 'sherpa/csrc/**'
      - 'sherpa/bin/pruned_transducer_statelessX/**'
      - 'sherpa/python/**'
  pull_request:
    types: [labeled]
    paths:
      - '.github/workflows/run-test-aishell.yaml'
      - 'CMakeLists.txt'
      - 'cmake/**'
      - 'sherpa/csrc/**'
      - 'sherpa/bin/pruned_transducer_statelessX/**'
      - 'sherpa/python/**'

concurrency:
  group: run_tests_aishell_offline_asr-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run_tests_aishell_offline_asr:
    if: github.event.label.name == 'ready' || github.event_name == 'push'
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest]
        decoding: ["greedy_search", "modified_beam_search"]
        torch: ["1.13.1"]
        torchaudio: ["0.13.1"]
        python-version: ["3.8"]

    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install PyTorch ${{ matrix.torch }}
        shell: bash
        run: |
          sudo apt-get -qq install git-lfs tree sox
          sox --version

          sudo apt-get install -y libsnappy-dev libzzip-dev zlib1g-dev libboost-all-dev

          python3 -m pip install --upgrade pip kaldi_native_io sentencepiece>=0.1.96
          python3 -m pip install wheel twine typing_extensions pytest
          python3 -m pip install torch==${{ matrix.torch }} torchaudio==${{ matrix.torchaudio }} numpy -f https://download.pytorch.org/whl/cpu/torch_stable.html

          python3 -m pip install k2==1.23.3.dev20230127+cpu.torch${{ matrix.torch }} -f https://k2-fsa.org/nightly/index.html

          python3 -m torch.utils.collect_env


      - name: Cache kaldifeat
        id: my-cache-2
        uses: actions/cache@v2
        with:
          path: |
            ~/tmp/kaldifeat
          key: cache-tmp-${{ matrix.python-version }}-${{ matrix.os }}-${{ matrix.torch }}

      - name: Install kaldifeat
        if: steps.my-cache-2.outputs.cache-hit != 'true'
        shell: bash
        run: |
          .github/scripts/install-kaldifeat.sh

      - name: Install sherpa
        shell: bash
        run: |
          export KALDIFEAT_INSTALL_PREFIX=$HOME/tmp/kaldifeat/build
          echo $KALDIFEAT_INSTALL_PREFIX
          ls -lh $KALDIFEAT_INSTALL_PREFIX

          python3 setup.py install

      - name: Download pretrained model and test-data
        shell: bash
        run: |
          git lfs install
          git clone https://huggingface.co/csukuangfj/icefall-aishell-pruned-transducer-stateless3-2022-06-20

      - name: Start server
        shell: bash
        run: |
          export PYTHONPATH=~/tmp/kaldifeat/kaldifeat/python:$PYTHONPATH
          export PYTHONPATH=~/tmp/kaldifeat/build/lib:$PYTHONPATH

          sherpa/bin/pruned_transducer_statelessX/offline_server.py \
            --decoding-method ${{ matrix.decoding }} \
            --port 6006 \
            --num-device 0 \
            --max-batch-size 10 \
            --max-wait-ms 5 \
            --feature-extractor-pool-size 5 \
            --nn-pool-size 1 \
            --nn-model-filename ./icefall-aishell-pruned-transducer-stateless3-2022-06-20/exp/cpu_jit-epoch-29-avg-5-torch-1.6.0.pt \
            --token-filename ./icefall-aishell-pruned-transducer-stateless3-2022-06-20/data/lang_char/tokens.txt &

          echo "Sleep 10 seconds to wait for the server startup"
          sleep 10

      - name: Start client
        shell: bash
        run: |
          sherpa/bin/pruned_transducer_statelessX/offline_client.py \
            --server-addr localhost \
            --server-port 6006 \
            ./icefall-aishell-pruned-transducer-stateless3-2022-06-20/test_wavs/BAC009S0764W0121.wav \
            ./icefall-aishell-pruned-transducer-stateless3-2022-06-20/test_wavs/BAC009S0764W0122.wav \
            ./icefall-aishell-pruned-transducer-stateless3-2022-06-20/test_wavs/BAC009S0764W0123.wav
