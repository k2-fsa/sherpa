# Copyright      2022  Xiaomi Corp.       (author: Fangjun Kuang)

# See ../../LICENSE for clarification regarding multiple authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
name: Run streaming conformer ASR tests

on:
  push:
    branches:
      - master
  pull_request:
    branches:
      - master

jobs:
  run_streaming_conformer_asr_tests:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-18.04, macos-10.15]
        torch: ["1.10.0", "1.6.0"]
        torchaudio: ["0.10.0", "0.6.0"]
        python-version: [3.7, 3.8]
        exclude:
          - torch: "1.10.0"
            torchaudio: "0.6.0"
          - torch: "1.6.0"
            torchaudio: "0.10.0"

    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install GCC 7
        if: startsWith(matrix.os, 'ubuntu')
        run: |
          sudo apt-get install -y gcc-7 g++-7
          echo "CC=/usr/bin/gcc-7" >> $GITHUB_ENV
          echo "CXX=/usr/bin/g++-7" >> $GITHUB_ENV

      - name: Install PyTorch ${{ matrix.torch }}
        shell: bash
        if: startsWith(matrix.os, 'ubuntu')
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install wheel twine typing_extensions websockets sentencepiece>=0.1.96
          python3 -m pip install torch==${{ matrix.torch }}+cpu numpy -f https://download.pytorch.org/whl/cpu/torch_stable.html

          if [[ ${{ matrix.torchaudio }} == "0.10.0" ]]; then
            pip install torchaudio==${{ matrix.torchaudio }}+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html
          else
            pip install torchaudio==${{ matrix.torchaudio }}
          fi

      - name: Install PyTorch ${{ matrix.torch }}
        shell: bash
        if: startsWith(matrix.os, 'macos')
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install wheel twine typing_extensions websockets sentencepiece>=0.1.96
          python3 -m pip install torch==${{ matrix.torch }} torchaudio==${{ matrix.torchaudio }} numpy -f https://download.pytorch.org/whl/cpu/torch_stable.html

      - name: Cache kaldifeat
        id: my-cache
        uses: actions/cache@v2
        with:
          path: |
            ~/tmp/kaldifeat
          key: cache-tmp-${{ matrix.python-version }}-${{ matrix.os }}-${{ matrix.torch }}

      - name: Install kaldifeat
        if: steps.my-cache.outputs.cache-hit != 'true'
        shell: bash
        run: |
          .github/scripts/install-kaldifeat.sh

      - name: Install sherpa
        shell: bash
        run: |
          python3 setup.py install

      - name: Download pretrained model and test-data
        shell: bash
        run: |
          git lfs install
          git clone https://huggingface.co/pkufool/icefall-asr-librispeech-pruned-stateless-streaming-conformer-rnnt4-2022-06-10

      - name: Start server
        shell: bash
        run: |
          export PYTHONPATH=~/tmp/kaldifeat/kaldifeat/python:$PYTHONPATH
          export PYTHONPATH=~/tmp/kaldifeat/build/lib:$PYTHONPATH

          ./sherpa/bin/streaming_conformer_rnnt/streaming_server.py \
            --port 6006 \
            --max-batch-size 50 \
            --max-wait-ms 5 \
            --nn-pool-size 1 \
            --nn-model-filename ./icefall-asr-librispeech-pruned-stateless-streaming-conformer-rnnt4-2022-06-10/exp/cpu_jit-epoch-29-avg-6_torch-${{ matrix.torch }}.pt \
            --bpe-model-filename ./icefall-asr-librispeech-pruned-stateless-streaming-conformer-rnnt4-2022-06-10/data/lang_bpe_500/bpe.model &

          echo "Sleep 10 seconds to wait for the server startup"
          sleep 10

      - name: Start client
        shell: bash
        run: |
          ./sherpa/bin/streaming_conformer_rnnt/streaming_client.py \
            --server-addr localhost \
            --server-port 6006 \
            ./icefall-asr-librispeech-pruned-stateless-streaming-conformer-rnnt4-2022-06-10/test_wavs/1221-135766-0002.wav
