<!-- see https://stackoverflow.com/questions/2454577/sphinx-restructuredtext-show-hide-code-snippets -->
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>sherpa-onnx &mdash; sherpa 1.3 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/user.define.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tutorials" href="tutorials/index.html" />
    <link rel="prev" title="FAQs" href="../ncnn/faq.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> sherpa
          </a>
              <div class="version">
                1.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pdf.html">Download pdf</a></li>
<li class="toctree-l1"><a class="reference internal" href="../social-groups.html">Social groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="../huggingface/index.html">Run Next-gen Kaldi in your browser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pretrained-models.html">Pre-trained models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../sherpa/index.html">sherpa</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-ncnn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ncnn/index.html">sherpa-ncnn</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-onnx</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">sherpa-onnx</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/index.html">Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="install/index.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="faqs/index.html">Frequently Asked Question (FAQs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="python/index.html">Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="c-api/index.html">C API</a></li>
<li class="toctree-l2"><a class="reference internal" href="java-api/index.html">Java API</a></li>
<li class="toctree-l2"><a class="reference internal" href="javascript-api/index.html">Javascript API</a></li>
<li class="toctree-l2"><a class="reference internal" href="kotlin-api/index.html">Kotlin API</a></li>
<li class="toctree-l2"><a class="reference internal" href="swift-api/index.html">Swift API</a></li>
<li class="toctree-l2"><a class="reference internal" href="go-api/index.html">Go API</a></li>
<li class="toctree-l2"><a class="reference internal" href="csharp-api/index.html">C# API</a></li>
<li class="toctree-l2"><a class="reference internal" href="pascal-api/index.html">Pascal API</a></li>
<li class="toctree-l2"><a class="reference internal" href="lazarus/index.html">Lazarus</a></li>
<li class="toctree-l2"><a class="reference internal" href="wasm/index.html">WebAssembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="android/index.html">Android</a></li>
<li class="toctree-l2"><a class="reference internal" href="harmony-os/index.html">HarmonyOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="ios/index.html">iOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="flutter/index.html">Flutter</a></li>
<li class="toctree-l2"><a class="reference internal" href="websocket/index.html">WebSocket</a></li>
<li class="toctree-l2"><a class="reference internal" href="hotwords/index.html">Hotwords (Contextual biasing)</a></li>
<li class="toctree-l2"><a class="reference internal" href="kws/index.html">Keyword spotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="punctuation/index.html">Punctuation</a></li>
<li class="toctree-l2"><a class="reference internal" href="audio-tagging/index.html">Audio tagging</a></li>
<li class="toctree-l2"><a class="reference internal" href="spoken-language-identification/index.html">Spoken language identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="vad/index.html">VAD</a></li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/index.html">Pre-trained models</a></li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/whisper/index.html">Whisper</a></li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/index.html">Moonshine</a></li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/index.html">Omnilingual ASR</a></li>
<li class="toctree-l2"><a class="reference internal" href="sense-voice/index.html">SenseVoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="funasr-nano/index.html">FunASR Nano</a></li>
<li class="toctree-l2"><a class="reference internal" href="paraformer/index.html">Paraformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="nemo/index.html">NeMo</a></li>
<li class="toctree-l2"><a class="reference internal" href="FireRedAsr/index.html">FireRedAsr</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dolphin/index.html">Dolphin</a></li>
<li class="toctree-l2"><a class="reference internal" href="homophone-replacer/index.html">æ‹¼éŸ³è¯ç»„åŒ¹é…æ›¿æ¢</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/index.html">Speaker Diarization</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-identification/index.html">Speaker Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="speech-enhancement/index.html">Speech enhancement</a></li>
<li class="toctree-l2"><a class="reference internal" href="source-separation/index.html">Source separation</a></li>
<li class="toctree-l2"><a class="reference internal" href="qnn/index.html">Qualcomm NPU (QNN, HTP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="rknn/index.html">rknn</a></li>
<li class="toctree-l2"><a class="reference internal" href="ascend/index.html">Ascend NPU (æ˜‡è…¾ NPU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tts/index.html">Text-to-speech (TTS)</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../triton/overview.html">Triton</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">sherpa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>sherpa-onnx</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/k2-fsa/sherpa/blob/master/docs/source/onnx/index.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="sherpa-onnx">
<h1>sherpa-onnx<a class="headerlink" href="#sherpa-onnx" title="Permalink to this heading">ïƒ</a></h1>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>During speech recognition, it does not need to access the Internet.
Everything is processed locally on your device.</p>
</div>
<p>We support using <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> with <a class="reference external" href="https://github.com/microsoft/onnxruntime">onnxruntime</a> to replace <a class="reference external" href="https://pytorch.org/">PyTorch</a> for neural
network computation. The code is put in a separate repository <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<p><a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a> is self-contained and everything can be compiled from source.</p>
<p>Please refer to
<a class="reference external" href="https://k2-fsa.github.io/icefall/model-export/export-onnx.html">https://k2-fsa.github.io/icefall/model-export/export-onnx.html</a>
for how to export models to <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> format.</p>
<p>In the following, we describe how to build <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a> for Linux, macOS,
Windows, embedded systems, Android, and iOS.</p>
<p>Also, we show how to use it for speech recognition with pre-trained models.</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/index.html">Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/cn.html">ä¸­æ–‡èµ„æ–™ (Chinese tutorials)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tutorials/cn.html#sherpa-java-api">2024-10-09ã€åŸºäºsherpaçš„æœ¬åœ°æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹å…¥é—¨-Java Apiç‰ˆ</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/cn.html#sherpa-onnx-cpu-docker">2024-07-03ã€ğŸ†“ èªéŸ³è¾¨è­˜å¼•æ“sherpa-onnx CPUä¸Šç¯‡ã€‘è®“æ‚¨è¼•é¬†é«”é©—èªéŸ³è¾¨è­˜åŠŸèƒ½(Dockeræ¶è¨­)</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/cn.html#sherpaonnxttsengine-android-tts">2024-06-10 SherpaOnnxTtsEngine - Android æœ¬åœ° TTS è¯­è¨€è½¬æ–‡æœ¬å¼•æ“</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/cn.html#llm100-01windows-1">2024-06-10 ç”¨LLMæ­å»º100ä¸ªåº”ç”¨ï¼ˆä¸€ï¼‰ï¼šä»0åˆ°1æ­å»ºè‡ªå·±çš„Windowsè´¾ç»´æ–¯(1)</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/cn.html#sherpa-onnx">2024-05-09 è®°å½•ä¸€ä¸‹sherpa-onnxçš„å®‰è£…åŠä½¿ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/cn.html#rv1106-rv1109-rv1126sherpa-onnx-tts">2024-04-09 rv1106&amp;rv1109&amp;rv1126ç§»æ¤sherpa-onnx å®ç°ç¦»çº¿TTSåŠŸèƒ½</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/cn.html#snowboy-kaldi-k2-fsa-sherpa-onnx">2023-08-08 snowboy+æ–°ä¸€ä»£kaldiï¼ˆk2-fsaï¼‰sherpa-onnxå®ç°ç¦»çº¿è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³åŠ©æ‰‹ã€‘</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/cn.html#k2-sherpa-onnx">2023-03-16 k2è¯­éŸ³è¯†åˆ«ï¼šå¦‚ä½•ä½¿ç”¨sherpa-onnx</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="install/index.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="install/linux.html">Linux</a><ul>
<li class="toctree-l3"><a class="reference internal" href="install/linux.html#cpu-linux-x64-or-linux-arm64">CPU (Linux x64 or Linux arm64)</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/linux.html#gpu-cuda-11-8-cudnn-8-linux-x64">GPU (CUDA 11.8, CUDNN 8, Linux x64)</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/linux.html#gpu-cuda-12-8-cudnn-9-linux-x64">GPU (CUDA 12.8, CUDNN 9, Linux x64)</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/linux.html#gpu-cuda-10-2-cudnn8-linux-arm64-e-g-jetson-nano-b01">GPU (CUDA 10.2, CUDNN8, Linux arm64, e.g., Jetson Nano B01)</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/linux.html#gpu-cuda-11-4-cudnn8-linux-arm64-e-g-jetson-orin-nx">GPU (CUDA 11.4, CUDNN8, Linux arm64, e.g., Jetson Orin NX)</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/linux.html#gpu-cuda-12-6-cudnn9-linux-arm64-e-g-jetson-orin-nano-engineering-reference-developer-kit-super-jetpack-6-2">GPU (CUDA 12.6, CUDNN9, Linux arm64, e.g., Jetson Orin Nano Engineering Reference Developer Kit Super Jetpack 6.2)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="install/macos.html">macOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="install/windows.html">Windows</a><ul>
<li class="toctree-l3"><a class="reference internal" href="install/windows/download-pre-compiled.html">Download pre-compiled libs and binaries for Windows</a><ul>
<li class="toctree-l4"><a class="reference internal" href="install/windows/generated/download/windows_x64.html">Pre-compiled executables and libraries for Windows x64</a><ul>
<li class="toctree-l5"><a class="reference internal" href="install/windows/generated/download/windows_x64.html#shared-libraries">Shared Libraries</a></li>
<li class="toctree-l5"><a class="reference internal" href="install/windows/generated/download/windows_x64.html#static-libraries">Static Libraries</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="install/windows/generated/download/windows_x86.html">Pre-compiled executables and libraries for Windows x86</a><ul>
<li class="toctree-l5"><a class="reference internal" href="install/windows/generated/download/windows_x86.html#shared-libraries">Shared Libraries</a></li>
<li class="toctree-l5"><a class="reference internal" href="install/windows/generated/download/windows_x86.html#static-libraries">Static Libraries</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="install/windows/generated/download/windows_arm64.html">Pre-compiled executables and libraries for Windows arm64</a><ul>
<li class="toctree-l5"><a class="reference internal" href="install/windows/generated/download/windows_arm64.html#shared-libraries">Shared Libraries</a></li>
<li class="toctree-l5"><a class="reference internal" href="install/windows/generated/download/windows_arm64.html#static-libraries">Static Libraries</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="install/windows/build-cpu.html">Build from source for Windows (CPU only)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html">Build sherpa-onnx on Windows (x64)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l5"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#build-configurations">Build Configurations</a><ul>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#shared-md-release">Shared + MD + Release</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#build-commands">Build commands</a></li>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#check-runtime-dependencies">Check runtime dependencies</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#shared-md-debug">Shared + MD + Debug</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id1">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#shared-md-minsizerel">Shared + MD + MinSizeRel</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id2">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#shared-md-relwithdebinfo">Shared + MD + RelWithDebInfo</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id3">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#shared-mt-release">Shared + MT + Release</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id4">Build commands</a></li>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id5">Check runtime dependencies</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#shared-mt-debug">Shared + MT + Debug</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id7">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#shared-mt-minsizerel">Shared + MT + MinSizeRel</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id8">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#shared-mt-relwithdebinfo">Shared + MT + RelWithDebInfo</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id9">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#static-md-release">Static + MD + Release</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id10">Build commands</a></li>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id11">Check runtime dependencies</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#static-md-debug">Static + MD + Debug</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id13">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#static-md-minsizerel">Static + MD + MinSizeRel</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id14">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#static-md-relwithdebinfo">Static + MD + RelWithDebInfo</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id15">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#static-mt-release">Static + MT + Release</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id16">Build commands</a></li>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id17">Check runtime dependencies</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#static-mt-debug">Static + MT + Debug</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id19">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#static-mt-minsizerel">Static + MT + MinSizeRel</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id20">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#static-mt-relwithdebinfo">Static + MT + RelWithDebInfo</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x64_cpu_build.html#id21">Build commands</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html">Build sherpa-onnx on Windows (x86)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l5"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#build-configurations">Build Configurations</a><ul>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#shared-md-release">Shared + MD + Release</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#build-commands">Build commands</a></li>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#check-runtime-dependencies">Check runtime dependencies</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#shared-md-debug">Shared + MD + Debug</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id1">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#shared-md-minsizerel">Shared + MD + MinSizeRel</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id2">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#shared-md-relwithdebinfo">Shared + MD + RelWithDebInfo</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id3">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#shared-mt-release">Shared + MT + Release</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id4">Build commands</a></li>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id5">Check runtime dependencies</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#shared-mt-debug">Shared + MT + Debug</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id7">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#shared-mt-minsizerel">Shared + MT + MinSizeRel</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id8">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#shared-mt-relwithdebinfo">Shared + MT + RelWithDebInfo</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id9">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#static-md-release">Static + MD + Release</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id10">Build commands</a></li>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id11">Check runtime dependencies</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#static-md-debug">Static + MD + Debug</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id13">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#static-md-minsizerel">Static + MD + MinSizeRel</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id14">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#static-md-relwithdebinfo">Static + MD + RelWithDebInfo</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id15">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#static-mt-release">Static + MT + Release</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id16">Build commands</a></li>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id17">Check runtime dependencies</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#static-mt-debug">Static + MT + Debug</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id19">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#static-mt-minsizerel">Static + MT + MinSizeRel</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id20">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#static-mt-relwithdebinfo">Static + MT + RelWithDebInfo</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_x86_cpu_build.html#id21">Build commands</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html">Build sherpa-onnx on Windows (ARM64)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l5"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#build-configurations">Build Configurations</a><ul>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#shared-md-release">Shared + MD + Release</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#build-commands">Build commands</a></li>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#check-runtime-dependencies">Check runtime dependencies</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#shared-md-debug">Shared + MD + Debug</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id1">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#shared-md-minsizerel">Shared + MD + MinSizeRel</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id2">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#shared-md-relwithdebinfo">Shared + MD + RelWithDebInfo</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id3">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#shared-mt-release">Shared + MT + Release</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id4">Build commands</a></li>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id5">Check runtime dependencies</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#shared-mt-debug">Shared + MT + Debug</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id7">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#shared-mt-minsizerel">Shared + MT + MinSizeRel</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id8">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#shared-mt-relwithdebinfo">Shared + MT + RelWithDebInfo</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id9">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#static-md-release">Static + MD + Release</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id10">Build commands</a></li>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id11">Check runtime dependencies</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#static-md-debug">Static + MD + Debug</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id13">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#static-md-minsizerel">Static + MD + MinSizeRel</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id14">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#static-md-relwithdebinfo">Static + MD + RelWithDebInfo</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id15">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#static-mt-release">Static + MT + Release</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id16">Build commands</a></li>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id17">Check runtime dependencies</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#static-mt-debug">Static + MT + Debug</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id19">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#static-mt-minsizerel">Static + MT + MinSizeRel</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id20">Build commands</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#static-mt-relwithdebinfo">Static + MT + RelWithDebInfo</a><ul>
<li class="toctree-l7"><a class="reference internal" href="install/windows/generated/build_cpu/windows_arm64_cpu_build.html#id21">Build commands</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="install/windows/build-cuda.html">Build from source for Windows (With NVIDIA GPU)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="install/windows/build-cuda.html#gpu-cuda-11-8">GPU (CUDA 11.8)</a></li>
<li class="toctree-l4"><a class="reference internal" href="install/windows/build-cuda.html#gpu-cuda-12-x">GPU (CUDA 12.x)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="install/aarch64-embedded-linux.html">Embedded Linux (aarch64)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="install/aarch64-embedded-linux.html#install-toolchain">Install toolchain</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/aarch64-embedded-linux.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/aarch64-embedded-linux.html#sherpa-onnx-alsa">sherpa-onnx-alsa</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/aarch64-embedded-linux.html#how-to-build-static-libraries-and-static-linked-binaries">How to build static libraries and static linked binaries</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="install/arm-embedded-linux.html">Embedded Linux (arm)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="install/arm-embedded-linux.html#install-toolchain">Install toolchain</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/arm-embedded-linux.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/arm-embedded-linux.html#how-to-build-static-libraries-and-static-linked-binaries">How to build static libraries and static linked binaries</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="install/riscv64-embedded-linux.html">Embedded Linux (riscv64)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="install/riscv64-embedded-linux.html#install-toolchain">Install toolchain</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/riscv64-embedded-linux.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="install/riscv64-embedded-linux.html#qemu">qemu</a><ul>
<li class="toctree-l4"><a class="reference internal" href="install/riscv64-embedded-linux.html#run-speech-to-text-with-qemu">Run speech-to-text with qemu</a></li>
<li class="toctree-l4"><a class="reference internal" href="install/riscv64-embedded-linux.html#run-text-to-speech-with-qemu">Run text-to-speech with qemu</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="faqs/index.html">Frequently Asked Question (FAQs)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="faqs/diff-online-offline.html">åœ¨çº¿ã€ç¦»çº¿ã€æµå¼ã€éæµå¼çš„åŒºåˆ«</a></li>
<li class="toctree-l2"><a class="reference internal" href="faqs/change-kotlin-and-java-package-name.html">How to change the package name of our kotlin and/or java API</a></li>
<li class="toctree-l2"><a class="reference internal" href="faqs/fix-libasound-module-conf-pulse.html">Cannot open shared library libasound_module_conf_pulse.so</a></li>
<li class="toctree-l2"><a class="reference internal" href="faqs/fix-tts-encoding-for-chinese-models.html">TTS ä¸­æ–‡æ¨¡å‹æ²¡æœ‰å£°éŸ³</a></li>
<li class="toctree-l2"><a class="reference internal" href="faqs/fix-libtoolize.html">./gitcompile: line 89: libtoolize: command not found</a></li>
<li class="toctree-l2"><a class="reference internal" href="faqs/static-onnxruntime-linux-x64.html">undefined reference to `std::__throw_bad_array_new_length()â€™</a></li>
<li class="toctree-l2"><a class="reference internal" href="faqs/cann.html">error while loading shared libraries: libascendcl.so</a></li>
<li class="toctree-l2"><a class="reference internal" href="faqs/index.html#oserror-portaudio-library-not-found">OSError: PortAudio library not found</a></li>
<li class="toctree-l2"><a class="reference internal" href="faqs/index.html#imports-github-com-k2-fsa-sherpa-onnx-go-linux-build-constraints-exclude-all-go-files">imports github.com/k2-fsa/sherpa-onnx-go-linux: build constraints exclude all Go files</a></li>
<li class="toctree-l2"><a class="reference internal" href="faqs/index.html#external-buffers-are-not-allowed">External buffers are not allowed</a></li>
<li class="toctree-l2"><a class="reference internal" href="faqs/index.html#the-given-version-17-is-not-supported-only-version-1-to-10-is-supported-in-this-build">The given version [17] is not supported, only version 1 to 10 is supported in this build</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="python/index.html">Python</a><ul>
<li class="toctree-l2"><a class="reference internal" href="python/install.html">Install the Python Package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python/install.html#method-1-from-pre-compiled-wheels-cpu-only">Method 1 (From pre-compiled wheels, CPU only)</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/install.html#method-2-from-pre-compiled-wheels-cpu-cuda-11-8">Method 2 (From pre-compiled wheels, CPU + CUDA 11.8)</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/install.html#method-3-from-pre-compiled-wheels-cpu-cuda-12-8-cudnn9">Method 3 (From pre-compiled wheels, CPU + CUDA 12.8 + CUDNN9)</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/install.html#method-4-from-source">Method 4 (From source)</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/install.html#method-5-for-developers">Method 5 (For developers)</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/install.html#check-your-installation">Check your installation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="python/decode-files.html">Decode files</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python/decode-files.html#streaming-zipformer">Streaming zipformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/decode-files.html#non-streaming-zipformer">Non-streaming zipformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/decode-files.html#non-streaming-paraformer">Non-streaming paraformer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="python/real-time-speech-recongition-from-a-microphone.html">Real-time speech recognition from a microphone</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python/real-time-speech-recongition-from-a-microphone.html#with-endpoint-detection">With endpoint detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/real-time-speech-recongition-from-a-microphone.html#without-endpoint-detection">Without endpoint detection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="python/speech-recognition-from-urls.html">Speech recognition from URLs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python/speech-recognition-from-urls.html#decode-a-url">Decode a URL</a></li>
<li class="toctree-l3"><a class="reference internal" href="python/speech-recognition-from-urls.html#rtmp">RTMP</a><ul>
<li class="toctree-l4"><a class="reference internal" href="python/speech-recognition-from-urls.html#install-the-server">Install the server</a></li>
<li class="toctree-l4"><a class="reference internal" href="python/speech-recognition-from-urls.html#start-the-server">Start the server</a></li>
<li class="toctree-l4"><a class="reference internal" href="python/speech-recognition-from-urls.html#start-ffmpeg-to-push-audio-stream">Start ffmpeg to push audio stream</a></li>
<li class="toctree-l4"><a class="reference internal" href="python/speech-recognition-from-urls.html#start-sherpa-onnx-to-pull-audio-stream">Start sherpa-onnx to pull audio stream</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="python/streaming-websocket-server.html">Streaming WebSocket Server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python/streaming-websocket-server.html#start-the-server">Start the server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="python/streaming-websocket-server.html#use-python-api">Use Python API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="python/streaming-websocket-server.html#send-a-file-for-decoding">Send a file for decoding</a></li>
<li class="toctree-l5"><a class="reference internal" href="python/streaming-websocket-server.html#send-audio-samples-from-a-microphone-for-decoding">Send audio samples from a microphone for decoding</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="python/streaming-websocket-server.html#use-a-browser">Use a browser</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="python/streaming-websocket-server.html#colab">colab</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="python/non-streaming-websocket-server.html">Non-Streaming WebSocket Server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python/non-streaming-websocket-server.html#non-streaming-transducer">Non-streaming transducer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="python/non-streaming-websocket-server.html#start-the-server">Start the server</a></li>
<li class="toctree-l4"><a class="reference internal" href="python/non-streaming-websocket-server.html#start-the-client">Start the client</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="python/non-streaming-websocket-server.html#non-streaming-paraformer">Non-streaming paraformer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="python/non-streaming-websocket-server.html#id1">Start the server</a></li>
<li class="toctree-l4"><a class="reference internal" href="python/non-streaming-websocket-server.html#id2">Start the client</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="python/non-streaming-websocket-server.html#non-streaming-ctc-model-from-nemo">Non-streaming CTC model from NeMo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="python/non-streaming-websocket-server.html#id3">Start the server</a></li>
<li class="toctree-l4"><a class="reference internal" href="python/non-streaming-websocket-server.html#id4">Start the client</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="python/non-streaming-websocket-server.html#non-streaming-whisper-tiny-en">Non-streaming Whisper tiny.en</a><ul>
<li class="toctree-l4"><a class="reference internal" href="python/non-streaming-websocket-server.html#id5">Start the server</a></li>
<li class="toctree-l4"><a class="reference internal" href="python/non-streaming-websocket-server.html#id6">Start the client</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="python/non-streaming-websocket-server.html#colab">colab</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="c-api/index.html">C API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="c-api/index.html#generate-required-files">Generate required files</a><ul>
<li class="toctree-l3"><a class="reference internal" href="c-api/index.html#build-shared-libraries">Build shared libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="c-api/index.html#build-static-libraries">Build static libraries</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="c-api/index.html#build-decode-file-c-api-c-with-generated-files">Build decode-file-c-api.c with generated files</a></li>
<li class="toctree-l2"><a class="reference internal" href="c-api/index.html#colab">colab</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="java-api/index.html">Java API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="java-api/non-android-java.html">Non-android Java</a><ul>
<li class="toctree-l3"><a class="reference internal" href="java-api/non-android-java.html#download-jar-files">Download jar files</a></li>
<li class="toctree-l3"><a class="reference internal" href="java-api/non-android-java.html#usage">Usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="java-api/non-android-java.html#linux-x64">Linux x64</a></li>
<li class="toctree-l4"><a class="reference internal" href="java-api/non-android-java.html#linux-arm64">Linux arm64</a></li>
<li class="toctree-l4"><a class="reference internal" href="java-api/non-android-java.html#macos-x64">macOS x64</a></li>
<li class="toctree-l4"><a class="reference internal" href="java-api/non-android-java.html#macos-arm64">macOS arm64</a></li>
<li class="toctree-l4"><a class="reference internal" href="java-api/non-android-java.html#windows-x64">Windows x64</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="java-api/non-android-java.html#colab-notebook-example">Colab notebook example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="java-api/anroid-java.html">Java for Android</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="javascript-api/index.html">Javascript API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="javascript-api/install.html">Install</a></li>
<li class="toctree-l2"><a class="reference internal" href="javascript-api/examples.html">Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="kotlin-api/index.html">Kotlin API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="kotlin-api/build-jni.html">Build JNI interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="kotlin-api/examples.html">Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="swift-api/index.html">Swift API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="swift-api/build.html">Build</a></li>
<li class="toctree-l2"><a class="reference internal" href="swift-api/examples.html">Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="go-api/index.html">Go API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="go-api/index.html#decode-files-with-non-streaming-models">Decode files with non-streaming models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="go-api/index.html#non-streaming-transducer">Non-streaming transducer</a></li>
<li class="toctree-l3"><a class="reference internal" href="go-api/index.html#non-streaming-paraformer">Non-streaming paraformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="go-api/index.html#non-streaming-ctc-model-from-nemo">Non-streaming CTC model from NeMo</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="go-api/index.html#decode-files-with-streaming-models">Decode files with streaming models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="go-api/index.html#streaming-transducer">Streaming transducer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="go-api/index.html#real-time-speech-recognition-from-microphone">Real-time speech recognition from microphone</a><ul>
<li class="toctree-l3"><a class="reference internal" href="go-api/index.html#id3">Streaming transducer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="go-api/index.html#colab">colab</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="csharp-api/index.html">C# API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="csharp-api/index.html#decode-files-with-non-streaming-models">Decode files with non-streaming models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="csharp-api/index.html#non-streaming-transducer">Non-streaming transducer</a></li>
<li class="toctree-l3"><a class="reference internal" href="csharp-api/index.html#non-streaming-paraformer">Non-streaming paraformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="csharp-api/index.html#non-streaming-ctc-model-from-nemo">Non-streaming CTC model from NeMo</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="csharp-api/index.html#decode-files-with-streaming-models">Decode files with streaming models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="csharp-api/index.html#streaming-transducer">Streaming transducer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="csharp-api/index.html#real-time-speech-recognition-from-microphone">Real-time speech recognition from microphone</a><ul>
<li class="toctree-l3"><a class="reference internal" href="csharp-api/index.html#id1">Streaming transducer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="csharp-api/index.html#colab">colab</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pascal-api/index.html">Pascal API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pascal-api/index.html#install-free-pascal">Install free pascal</a></li>
<li class="toctree-l2"><a class="reference internal" href="pascal-api/index.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
<li class="toctree-l2"><a class="reference internal" href="pascal-api/index.html#non-streaming-speech-recognition-from-files">Non-streaming speech recognition from files</a></li>
<li class="toctree-l2"><a class="reference internal" href="pascal-api/index.html#colab-notebook">Colab notebook</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lazarus/index.html">Lazarus</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lazarus/pre-built-app.html">Pre-built APPs using Lazarus</a></li>
<li class="toctree-l2"><a class="reference internal" href="lazarus/generate-subtitles.html">Generate subtitles</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lazarus/generate-subtitles.html#screenshots-on-different-platforms">Screenshots on different platforms</a></li>
<li class="toctree-l3"><a class="reference internal" href="lazarus/generate-subtitles.html#get-sherpa-onnx-libraries">Get sherpa-onnx libraries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="lazarus/generate-subtitles.html#build-sherpa-onnx-from-source">1. Build sherpa-onnx from source</a></li>
<li class="toctree-l4"><a class="reference internal" href="lazarus/generate-subtitles.html#download-pre-built-libraries">2. Download pre-built libraries</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="lazarus/generate-subtitles.html#build-the-generate-subtitles-project">Build the generate_subtitles project</a></li>
<li class="toctree-l3"><a class="reference internal" href="lazarus/generate-subtitles.html#download-models">Download models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="lazarus/generate-subtitles.html#download-the-vad-model">Download the VAD model</a></li>
<li class="toctree-l4"><a class="reference internal" href="lazarus/generate-subtitles.html#download-a-speech-recognition-model">Download a speech recognition model</a></li>
<li class="toctree-l4"><a class="reference internal" href="lazarus/generate-subtitles.html#wisper">1. Wisper</a></li>
<li class="toctree-l4"><a class="reference internal" href="lazarus/generate-subtitles.html#zipformer-transducer">2. Zipformer transducer</a></li>
<li class="toctree-l4"><a class="reference internal" href="lazarus/generate-subtitles.html#nemo-transducer">3. NeMo transducer</a></li>
<li class="toctree-l4"><a class="reference internal" href="lazarus/generate-subtitles.html#sensevoice">4. SenseVoice</a></li>
<li class="toctree-l4"><a class="reference internal" href="lazarus/generate-subtitles.html#paraformer">5. Paraformer</a></li>
<li class="toctree-l4"><a class="reference internal" href="lazarus/generate-subtitles.html#telespeech">6. TeleSpeech</a></li>
<li class="toctree-l4"><a class="reference internal" href="lazarus/generate-subtitles.html#moonshine">7. Moonshine</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="lazarus/generate-subtitles.html#for-the-more-curious">For the more curious</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="wasm/index.html">WebAssembly</a><ul>
<li class="toctree-l2"><a class="reference internal" href="wasm/install-emscripten.html">Install Emscripten</a></li>
<li class="toctree-l2"><a class="reference internal" href="wasm/build.html">Build</a></li>
<li class="toctree-l2"><a class="reference internal" href="wasm/hf-spaces.html">Huggingface Spaces (WebAssembly)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="wasm/hf-spaces.html#english-only-zipformer">English only (Zipformer)</a></li>
<li class="toctree-l3"><a class="reference internal" href="wasm/hf-spaces.html#chinese-english-zipformer">Chinese + English (Zipformer)</a></li>
<li class="toctree-l3"><a class="reference internal" href="wasm/hf-spaces.html#chinese-english-paraformer">Chinese + English (Paraformer)</a></li>
<li class="toctree-l3"><a class="reference internal" href="wasm/hf-spaces.html#chinese-english-cantonese-paraformer">Chinese + English + Cantonese (Paraformer)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="android/index.html">Android</a><ul>
<li class="toctree-l2"><a class="reference internal" href="android/prebuilt-apk.html">Pre-built APKs</a></li>
<li class="toctree-l2"><a class="reference internal" href="android/build-sherpa-onnx.html">Build sherpa-onnx for Android</a><ul>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#install-android-studio">Install Android Studio</a></li>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#download-sherpa-onnx">Download sherpa-onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#install-ndk">Install NDK</a></li>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#build-sherpa-onnx-c-code">Build sherpa-onnx (C++ code)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="android/build-sherpa-onnx.html#build-for-arm64-v8a">Build for arm64-v8a</a></li>
<li class="toctree-l4"><a class="reference internal" href="android/build-sherpa-onnx.html#build-for-armv7-eabi">Build for armv7-eabi</a></li>
<li class="toctree-l4"><a class="reference internal" href="android/build-sherpa-onnx.html#build-for-x86-64">Build for x86_64</a></li>
<li class="toctree-l4"><a class="reference internal" href="android/build-sherpa-onnx.html#build-for-x86">Build for x86</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#download-pre-trained-models">Download pre-trained models</a></li>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#generate-apk">Generate APK</a></li>
<li class="toctree-l3"><a class="reference internal" href="android/build-sherpa-onnx.html#analyze-the-apk">Analyze the APK</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="harmony-os/index.html">HarmonyOS</a><ul>
<li class="toctree-l2"><a class="reference internal" href="harmony-os/prebuilt-hap.html">Pre-built HAPs</a></li>
<li class="toctree-l2"><a class="reference internal" href="harmony-os/speaker-identification.html">On-device speaker identification (æœ¬åœ°è¯´è¯äººè¯†åˆ«)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="harmony-os/speaker-identification.html#open-the-project-with-deveco-studio">Open the project with DevEco Studio</a></li>
<li class="toctree-l3"><a class="reference internal" href="harmony-os/speaker-identification.html#select-a-model">Select a model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="harmony-os/speaker-identification.html#use-3dspeaker-speech-eres2net-base-200k-sv-zh-cn-16k-common-onnx">Use 3dspeaker_speech_eres2net_base_200k_sv_zh-cn_16k-common.onnx</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="harmony-os/tts.html">On-device text-to-speech (TTS, æœ¬åœ°è¯­éŸ³åˆæˆ)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="harmony-os/tts.html#open-the-project-with-deveco-studio">Open the project with DevEco Studio</a></li>
<li class="toctree-l3"><a class="reference internal" href="harmony-os/tts.html#select-a-text-to-speech-model">Select a text-to-speech model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="harmony-os/tts.html#use-vits-melo-tts-zh-en">Use vits-melo-tts-zh_en</a></li>
<li class="toctree-l4"><a class="reference internal" href="harmony-os/tts.html#use-vits-piper-en-us-libritts-r-medium">Use vits-piper-en_US-libritts_r-medium</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="harmony-os/vad-asr.html">On-device VAD + ASR (æœ¬åœ°éæµå¼è¯­éŸ³è¯†åˆ«)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="harmony-os/vad-asr.html#open-the-project-with-deveco-studio">Open the project with DevEco Studio</a></li>
<li class="toctree-l3"><a class="reference internal" href="harmony-os/vad-asr.html#download-a-vad-model">Download a VAD model</a></li>
<li class="toctree-l3"><a class="reference internal" href="harmony-os/vad-asr.html#select-a-non-streaming-asr-model">Select a non-streaming ASR model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="harmony-os/vad-asr.html#use-sherpa-onnx-moonshine-tiny-en-int8">Use sherpa-onnx-moonshine-tiny-en-int8</a></li>
<li class="toctree-l4"><a class="reference internal" href="harmony-os/vad-asr.html#use-sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17">Use sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="harmony-os/how-to-build-har.html">How to build sherpa_onnx.har</a><ul>
<li class="toctree-l3"><a class="reference internal" href="harmony-os/how-to-build-har.html#download-commandline-tools">Download commandline-tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="harmony-os/how-to-build-har.html#build-sherpa-onnx-for-harmonyos">Build sherpa-onnx for HarmonyOS</a></li>
<li class="toctree-l3"><a class="reference internal" href="harmony-os/how-to-build-har.html#build-sherpa-onnx-har">Build sherpa_onnx.har</a><ul>
<li class="toctree-l4"><a class="reference internal" href="harmony-os/how-to-build-har.html#from-the-command-line">From the command-line</a></li>
<li class="toctree-l4"><a class="reference internal" href="harmony-os/how-to-build-har.html#use-deveco-studio">Use DevEco Studio</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="harmony-os/how-to-build-har.html#use-sherpa-onnx-har-in-your-project">Use sherpa_onnx.har in your project</a></li>
<li class="toctree-l3"><a class="reference internal" href="harmony-os/how-to-build-har.html#colab-demo">Colab demo</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ios/index.html">iOS</a><ul>
<li class="toctree-l2"><a class="reference internal" href="ios/build-sherpa-onnx-swift.html">Build sherpa-onnx for iOS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ios/build-sherpa-onnx-swift.html#requirement">Requirement</a></li>
<li class="toctree-l3"><a class="reference internal" href="ios/build-sherpa-onnx-swift.html#download-sherpa-onnx">Download sherpa-onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="ios/build-sherpa-onnx-swift.html#build-sherpa-onnx-in-commandline-c-part">Build sherpa-onnx (in commandline, C++ Part)</a></li>
<li class="toctree-l3"><a class="reference internal" href="ios/build-sherpa-onnx-swift.html#build-sherpa-onnx-in-xcode">Build sherpa-onnx (in Xcode)</a></li>
<li class="toctree-l3"><a class="reference internal" href="ios/build-sherpa-onnx-swift.html#run-sherpa-onnx-on-your-iphone-ipad">Run sherpa-onnx on your iPhone/iPad</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="flutter/index.html">Flutter</a><ul>
<li class="toctree-l2"><a class="reference internal" href="flutter/pre-built-app.html">Pre-built Flutter Apps</a><ul>
<li class="toctree-l3"><a class="reference internal" href="flutter/pre-built-app.html#text-to-speech-tts-speech-synthesis">Text to speech (TTS, Speech synthesis)</a></li>
<li class="toctree-l3"><a class="reference internal" href="flutter/pre-built-app.html#streaming-speech-recognition-stt-asr">Streaming Speech recognition (STT, ASR)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="websocket/index.html">WebSocket</a><ul>
<li class="toctree-l2"><a class="reference internal" href="websocket/online-websocket.html">Streaming WebSocket server and client</a><ul>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#build-sherpa-onnx-with-websocket-support">Build <cite>sherpa-onnx</cite> with WebSocket support</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#view-the-server-usage">View the server usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#start-the-server">Start the server</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#view-the-usage-of-the-client-c">View the usage of the client (C++)</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#start-the-client-c">Start the client (C++)</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#view-the-usage-of-the-client-python">View the usage of the client (Python)</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#start-the-client-python">Start the client (Python)</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/online-websocket.html#start-the-client-python-with-microphone">Start the client (Python, with microphone)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="websocket/offline-websocket.html">Non-streaming WebSocket server and client</a><ul>
<li class="toctree-l3"><a class="reference internal" href="websocket/offline-websocket.html#build-sherpa-onnx-with-websocket-support">Build <cite>sherpa-onnx</cite> with WebSocket support</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/offline-websocket.html#view-the-server-usage">View the server usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket/offline-websocket.html#start-the-server">Start the server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="websocket/offline-websocket.html#start-the-server-with-a-transducer-model">Start the server with a transducer model</a></li>
<li class="toctree-l4"><a class="reference internal" href="websocket/offline-websocket.html#start-the-server-with-a-paraformer-model">Start the server with a paraformer model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="websocket/offline-websocket.html#start-the-client-python">Start the client (Python)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="websocket/offline-websocket.html#id1">offline-websocket-client-decode-files-paralell.py</a></li>
<li class="toctree-l4"><a class="reference internal" href="websocket/offline-websocket.html#id2">offline-websocket-client-decode-files-sequential.py</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hotwords/index.html">Hotwords (Contextual biasing)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="hotwords/index.html#what-are-hotwords">What are hotwords</a></li>
<li class="toctree-l2"><a class="reference internal" href="hotwords/index.html#how-do-we-implement-it-with-an-aho-corasick">How do we implement it with an Aho-corasick</a></li>
<li class="toctree-l2"><a class="reference internal" href="hotwords/index.html#how-to-use-hotwords-in-sherpa-onnx">How to use hotwords in sherpa-onnx</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hotwords/index.html#modeling-unit-is-bpe">Modeling unit is bpe</a><ul>
<li class="toctree-l4"><a class="reference internal" href="hotwords/index.html#c-api">C++ api</a></li>
<li class="toctree-l4"><a class="reference internal" href="hotwords/index.html#python-api">Python api</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="hotwords/index.html#modeling-unit-is-cjkchar">Modeling unit is cjkchar</a><ul>
<li class="toctree-l4"><a class="reference internal" href="hotwords/index.html#id1">C++ api</a></li>
<li class="toctree-l4"><a class="reference internal" href="hotwords/index.html#id2">Python api</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="hotwords/index.html#modeling-unit-is-cjkchar-bpe">Modeling unit is cjkchar+bpe</a><ul>
<li class="toctree-l4"><a class="reference internal" href="hotwords/index.html#id3">C++ api</a></li>
<li class="toctree-l4"><a class="reference internal" href="hotwords/index.html#id4">Python api</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="kws/index.html">Keyword spotting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="kws/index.html#what-is-open-vocabulary-keyword-spotting">What is open vocabulary keyword spotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="kws/index.html#decoder-for-open-vocabulary-keyword-spotting">Decoder for open vocabulary keyword spotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="kws/index.html#keywords-file">Keywords file</a></li>
<li class="toctree-l2"><a class="reference internal" href="kws/index.html#how-to-use-keyword-spotting-in-sherpa-onnx">How to use keyword spotting in sherpa-onnx</a><ul>
<li class="toctree-l3"><a class="reference internal" href="kws/index.html#command-line-tool">command-line tool</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="kws/index.html#android-application">Android application</a></li>
<li class="toctree-l2"><a class="reference internal" href="kws/index.html#pretrained-models">Pretrained models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="kws/pretrained_models/index.html">sherpa-onnx-kws-zipformer-zh-en-3M-2025-12-20 (Chinese &amp; English)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kws/pretrained_models/index.html#download-the-model">Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="kws/pretrained_models/index.html#test-the-model">Test the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="kws/pretrained_models/index.html#customize-your-own-keywords">Customize your own keywords</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="kws/pretrained_models/index.html#sherpa-onnx-kws-zipformer-wenetspeech-3-3m-2024-01-01-chinese">sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01 (Chinese)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kws/pretrained_models/index.html#id1">Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="kws/pretrained_models/index.html#id2">Test the model</a><ul>
<li class="toctree-l5"><a class="reference internal" href="kws/pretrained_models/index.html#fp32">fp32</a></li>
<li class="toctree-l5"><a class="reference internal" href="kws/pretrained_models/index.html#int8">int8</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="kws/pretrained_models/index.html#id3">Customize your own keywords</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="kws/pretrained_models/index.html#sherpa-onnx-kws-zipformer-gigaspeech-3-3m-2024-01-01-english">sherpa-onnx-kws-zipformer-gigaspeech-3.3M-2024-01-01 (English)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="kws/pretrained_models/index.html#id5">Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="kws/pretrained_models/index.html#id6">Test the model</a><ul>
<li class="toctree-l5"><a class="reference internal" href="kws/pretrained_models/index.html#id7">fp32</a></li>
<li class="toctree-l5"><a class="reference internal" href="kws/pretrained_models/index.html#id8">int8</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="kws/pretrained_models/index.html#id9">Customize your own keywords</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="punctuation/index.html">Punctuation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="punctuation/pretrained_models.html">Pre-trained models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="punctuation/pretrained_models.html#sherpa-onnx-online-punct-en-2024-08-06">sherpa-onnx-online-punct-en-2024-08-06</a><ul>
<li class="toctree-l4"><a class="reference internal" href="punctuation/pretrained_models.html#download-the-model">Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="punctuation/pretrained_models.html#c-binary-examples">C++ binary examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="punctuation/pretrained_models.html#sherpa-onnx-punct-ct-transformer-zh-en-vocab272727-2024-04-12-int8">sherpa-onnx-punct-ct-transformer-zh-en-vocab272727-2024-04-12-int8</a><ul>
<li class="toctree-l4"><a class="reference internal" href="punctuation/pretrained_models.html#id1">Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="punctuation/pretrained_models.html#id2">C++ binary examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="punctuation/pretrained_models.html#sherpa-onnx-punct-ct-transformer-zh-en-vocab272727-2024-04-12">sherpa-onnx-punct-ct-transformer-zh-en-vocab272727-2024-04-12</a><ul>
<li class="toctree-l4"><a class="reference internal" href="punctuation/pretrained_models.html#id4">Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="punctuation/pretrained_models.html#id5">C++ binary examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="punctuation/pretrained_models.html#python-api-examples">Python API examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="punctuation/pretrained_models.html#huggingface-space-examples">Huggingface space examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="punctuation/pretrained_models.html#video-demos">Video demos</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="audio-tagging/index.html">Audio tagging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="audio-tagging/pretrained_models.html">Pre-trained models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="audio-tagging/pretrained_models.html#sherpa-onnx-zipformer-small-audio-tagging-2024-04-15">sherpa-onnx-zipformer-small-audio-tagging-2024-04-15</a><ul>
<li class="toctree-l4"><a class="reference internal" href="audio-tagging/pretrained_models.html#download-the-model">Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="audio-tagging/pretrained_models.html#c-binary-examples">C++ binary examples</a><ul>
<li class="toctree-l5"><a class="reference internal" href="audio-tagging/pretrained_models.html#cat">Cat</a></li>
<li class="toctree-l5"><a class="reference internal" href="audio-tagging/pretrained_models.html#whistle">Whistle</a></li>
<li class="toctree-l5"><a class="reference internal" href="audio-tagging/pretrained_models.html#music">Music</a></li>
<li class="toctree-l5"><a class="reference internal" href="audio-tagging/pretrained_models.html#laughter">Laughter</a></li>
<li class="toctree-l5"><a class="reference internal" href="audio-tagging/pretrained_models.html#finger-snapping">Finger snapping</a></li>
<li class="toctree-l5"><a class="reference internal" href="audio-tagging/pretrained_models.html#baby-cry">Baby cry</a></li>
<li class="toctree-l5"><a class="reference internal" href="audio-tagging/pretrained_models.html#smoke-alarm">Smoke alarm</a></li>
<li class="toctree-l5"><a class="reference internal" href="audio-tagging/pretrained_models.html#siren">Siren</a></li>
<li class="toctree-l5"><a class="reference internal" href="audio-tagging/pretrained_models.html#stream-water">Stream water</a></li>
<li class="toctree-l5"><a class="reference internal" href="audio-tagging/pretrained_models.html#meow">Meow</a></li>
<li class="toctree-l5"><a class="reference internal" href="audio-tagging/pretrained_models.html#dog-bark">Dog bark</a></li>
<li class="toctree-l5"><a class="reference internal" href="audio-tagging/pretrained_models.html#oink-pig">Oink (pig)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="audio-tagging/pretrained_models.html#python-api-examples">Python API examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="audio-tagging/pretrained_models.html#huggingface-space">Huggingface space</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="audio-tagging/android.html">Android</a></li>
<li class="toctree-l2"><a class="reference internal" href="audio-tagging/wearos.html">WearOS</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="spoken-language-identification/index.html">Spoken language identification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="spoken-language-identification/pretrained_models.html">Pre-trained models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="spoken-language-identification/pretrained_models.html#whisper">whisper</a><ul>
<li class="toctree-l4"><a class="reference internal" href="spoken-language-identification/pretrained_models.html#download-the-model">Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="spoken-language-identification/pretrained_models.html#download-test-waves">Download test waves</a></li>
<li class="toctree-l4"><a class="reference internal" href="spoken-language-identification/pretrained_models.html#test-with-python-apis">Test with Python APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="spoken-language-identification/pretrained_models.html#android-apks">Android APKs</a></li>
<li class="toctree-l4"><a class="reference internal" href="spoken-language-identification/pretrained_models.html#huggingface-space">Huggingface space</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="vad/index.html">VAD</a><ul>
<li class="toctree-l2"><a class="reference internal" href="vad/silero-vad.html">silero-vad</a><ul>
<li class="toctree-l3"><a class="reference internal" href="vad/silero-vad.html#download-models-files">Download models files</a></li>
<li class="toctree-l3"><a class="reference internal" href="vad/silero-vad.html#android-examples">Android examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="vad/silero-vad.html#webassembly-examples">WebAssembly examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="vad/silero-vad.html#c-api-examples">C API examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="vad/ten-vad.html">ten-vad</a><ul>
<li class="toctree-l3"><a class="reference internal" href="vad/ten-vad.html#download-models-files">Download models files</a></li>
<li class="toctree-l3"><a class="reference internal" href="vad/ten-vad.html#android-examples">Android examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="vad/ten-vad.html#webassembly-examples">WebAssembly examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="vad/ten-vad.html#c-api-examples">C API examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pretrained_models/index.html">Pre-trained models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/online-transducer/index.html">Online transducer models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html">Zipformer-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-bn-vosk-2026-02-09-bengali">sherpa-onnx-streaming-zipformer-bn-vosk-2026-02-09 (Bengali)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#decode-a-single-wave-file">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#real-time-speech-recognition-from-a-microphone">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-zh-xlarge-int8-2025-06-30-chinese">sherpa-onnx-streaming-zipformer-zh-xlarge-int8-2025-06-30 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id2">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id3">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-zh-int8-2025-06-30-chinese">sherpa-onnx-streaming-zipformer-zh-int8-2025-06-30 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id4">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id5">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id6">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-korean-2024-06-16-korean">sherpa-onnx-streaming-zipformer-korean-2024-06-16 (Korean)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id7">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id8">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#fp32">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#int8">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id9">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-multi-zh-hans-2023-12-12-chinese">sherpa-onnx-streaming-zipformer-multi-zh-hans-2023-12-12 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id10">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id11">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id12">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id13">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id14">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#k2-fsa-icefall-asr-zipformer-wenetspeech-streaming-small-chinese">k2-fsa/icefall-asr-zipformer-wenetspeech-streaming-small (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id15">Download the model</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#k2-fsa-icefall-asr-zipformer-wenetspeech-streaming-large-chinese">k2-fsa/icefall-asr-zipformer-wenetspeech-streaming-large (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id16">Download the model</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#pkufool-icefall-asr-zipformer-streaming-wenetspeech-20230615-chinese">pkufool/icefall-asr-zipformer-streaming-wenetspeech-20230615 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id17">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id18">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id19">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id20">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id21">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-en-2023-06-26-english">csukuangfj/sherpa-onnx-streaming-zipformer-en-2023-06-26 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id22">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id23">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id24">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id25">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id26">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-en-2023-06-21-english">csukuangfj/sherpa-onnx-streaming-zipformer-en-2023-06-21 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id27">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id28">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id29">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id30">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id31">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-en-2023-02-21-english">csukuangfj/sherpa-onnx-streaming-zipformer-en-2023-02-21 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id32">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id33">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id34">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id35">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id36">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english">csukuangfj/sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20 (Bilingual, Chinese + English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id37">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id38">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id39">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id40">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id41">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#shaojieli-sherpa-onnx-streaming-zipformer-fr-2023-04-14-french">shaojieli/sherpa-onnx-streaming-zipformer-fr-2023-04-14 (French)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id42">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id43">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id44">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id45">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id46">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16-bilingual-chinese-english">sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16 (Bilingual, Chinese + English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id47">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id48">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id49">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id50">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id51">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-zh-14m-2023-02-23-chinese">csukuangfj/sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id52">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id53">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id54">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id55">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id56">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-en-20m-2023-02-17-english">csukuangfj/sherpa-onnx-streaming-zipformer-en-20M-2023-02-17 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id57">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id58">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id59">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id60">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/zipformer-transducer-models.html#id61">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/online-transducer/conformer-transducer-models.html">Conformer-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/conformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-conformer-zh-2023-05-23-chinese">csukuangfj/sherpa-onnx-streaming-conformer-zh-2023-05-23 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/conformer-transducer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/conformer-transducer-models.html#decode-a-single-wave-file">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/conformer-transducer-models.html#fp32">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/conformer-transducer-models.html#int8">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/conformer-transducer-models.html#real-time-speech-recognition-from-a-microphone">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html">LSTM-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#csukuangfj-sherpa-onnx-lstm-en-2023-02-17-english">csukuangfj/sherpa-onnx-lstm-en-2023-02-17 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#decode-a-single-wave-file">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#fp32">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#int8">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#real-time-speech-recognition-from-a-microphone">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#csukuangfj-sherpa-onnx-lstm-zh-2023-02-20-chinese">csukuangfj/sherpa-onnx-lstm-zh-2023-02-20 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#id2">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#id3">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#id4">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-transducer/lstm-transducer-models.html#id5">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/online-paraformer/index.html">Online paraformer models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html">Paraformer models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-streaming-paraformer-bilingual-zh-en-chinese-english">csukuangfj/sherpa-onnx-streaming-paraformer-bilingual-zh-en (Chinese + English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#decode-a-single-wave-file">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#fp32">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#int8">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#real-time-speech-recognition-from-a-microphone">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-streaming-paraformer-trilingual-zh-cantonese-en-chinese-cantonese-english">csukuangfj/sherpa-onnx-streaming-paraformer-trilingual-zh-cantonese-en (Chinese + Cantonese + English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#id2">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#id3">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#id4">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#id5">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/online-ctc/index.html">Online CTC models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html">Zipformer-CTC-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#sherpa-onnx-streaming-zipformer-ctc-zh-xlarge-int8-2025-06-30-chinese">sherpa-onnx-streaming-zipformer-ctc-zh-xlarge-int8-2025-06-30 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#decode-a-single-wave-file">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#real-time-speech-recognition-from-a-microphone">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#sherpa-onnx-streaming-zipformer-ctc-zh-int8-2025-06-30-chinese">sherpa-onnx-streaming-zipformer-ctc-zh-int8-2025-06-30 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#id2">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#id3">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#sherpa-onnx-streaming-zipformer-small-ctc-zh-int8-2025-04-01-chinese">sherpa-onnx-streaming-zipformer-small-ctc-zh-int8-2025-04-01 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#id4">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#id5">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#id6">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#sherpa-onnx-streaming-zipformer-small-ctc-zh-2025-04-01-chinese">sherpa-onnx-streaming-zipformer-small-ctc-zh-2025-04-01 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#id8">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#id9">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#id10">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#sherpa-onnx-streaming-zipformer-ctc-multi-zh-hans-2023-12-13-chinese">sherpa-onnx-streaming-zipformer-ctc-multi-zh-hans-2023-12-13 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#id11">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#id12">Decode a single wave file</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#fp32">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#int8">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/zipformer-ctc-models.html#id13">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/online-ctc/t-one-ctc-models.html">T-one CTC-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-ctc/t-one-ctc-models.html#sherpa-onnx-streaming-t-one-russian-2025-09-08-russian">sherpa-onnx-streaming-t-one-russian-2025-09-08 (Russian, ä¿„è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/t-one-ctc-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/t-one-ctc-models.html#decode-a-single-wave-file">Decode a single wave file</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/t-one-ctc-models.html#real-time-speech-recognition-from-a-microphone">Real-time speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-ctc/t-one-ctc-models.html#huggingface-space">Huggingface space</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/offline-transducer/index.html">Offline transducer models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html">Zipformer-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-vi-30m-int8-2026-02-09-vietnamese">sherpa-onnx-zipformer-vi-30M-int8-2026-02-09 (Vietnamese, è¶Šå—è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#real-time-streaming-speech-recognition-from-a-microphone-with-vad">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-vi-2025-04-20-vietnamese">sherpa-onnx-zipformer-vi-2025-04-20 (Vietnamese, è¶Šå—è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id2">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id3">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id4">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id5">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-vi-int8-2025-04-20-vietnamese">sherpa-onnx-zipformer-vi-int8-2025-04-20 (Vietnamese, è¶Šå—è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id7">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id8">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id9">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id10">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id11">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-zh-en-2023-11-22-chinese-english">sherpa-onnx-zipformer-zh-en-2023-11-22 (Chinese+English, ä¸­è‹±åŒè¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id12">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id13">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#fp32">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#int8">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id14">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id15">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id16">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-ru-2024-09-18-russian">sherpa-onnx-zipformer-ru-2024-09-18 (Russian, ä¿„è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id17">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id18">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id19">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id20">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id21">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id22">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id23">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-small-zipformer-ru-2024-09-18-russian">sherpa-onnx-small-zipformer-ru-2024-09-18 (Russian, ä¿„è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id25">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id26">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id27">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id28">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id29">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id30">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id31">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01-japanese">sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01 (Japanese, æ—¥è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id32">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id33">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id34">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id35">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id36">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id37">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id38">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-korean-2024-06-24-korean">sherpa-onnx-zipformer-korean-2024-06-24 (Korean, éŸ©è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id39">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id40">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id41">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id42">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id43">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id44">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-thai-2024-06-20-thai">sherpa-onnx-zipformer-thai-2024-06-20 (Thai, æ³°è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id45">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id46">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id47">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id48">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id49">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-cantonese-2024-03-13-cantonese">sherpa-onnx-zipformer-cantonese-2024-03-13 (Cantonese, ç²¤è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id50">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id51">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id52">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id53">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id54">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-gigaspeech-2023-12-12-english">sherpa-onnx-zipformer-gigaspeech-2023-12-12 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id55">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id56">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id57">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id58">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id59">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id60">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#zrjin-sherpa-onnx-zipformer-multi-zh-hans-2023-9-2-chinese">zrjin/sherpa-onnx-zipformer-multi-zh-hans-2023-9-2 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id61">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id62">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id63">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id64">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id65">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#yfyeung-icefall-asr-cv-corpus-13-0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17-english">yfyeung/icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id66">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id67">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id68">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id69">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id70">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#k2-fsa-icefall-asr-zipformer-wenetspeech-small-chinese">k2-fsa/icefall-asr-zipformer-wenetspeech-small (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id71">Download the model</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#k2-fsa-icefall-asr-zipformer-wenetspeech-large-chinese">k2-fsa/icefall-asr-zipformer-wenetspeech-large (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id72">Download the model</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#pkufool-icefall-asr-zipformer-wenetspeech-20230615-chinese">pkufool/icefall-asr-zipformer-wenetspeech-20230615 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id73">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id74">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id75">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id76">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id77">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-large-en-2023-06-26-english">csukuangfj/sherpa-onnx-zipformer-large-en-2023-06-26 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id78">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id79">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id80">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id81">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id82">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-small-en-2023-06-26-english">csukuangfj/sherpa-onnx-zipformer-small-en-2023-06-26 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id84">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id85">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id86">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id87">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id88">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-en-2023-06-26-english">csukuangfj/sherpa-onnx-zipformer-en-2023-06-26 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id90">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id91">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id92">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id93">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id94">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#icefall-asr-multidataset-pruned-transducer-stateless7-2023-05-04-english">icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id96">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id97">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id98">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id99">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id100">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-en-2023-04-01-english">csukuangfj/sherpa-onnx-zipformer-en-2023-04-01 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id101">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id102">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id103">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id104">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id105">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-zipformer-en-2023-03-30-english">csukuangfj/sherpa-onnx-zipformer-en-2023-03-30 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id106">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id107">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id108">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id109">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/zipformer-transducer-models.html#id110">Speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html">Conformer-transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#csukuangfj-sherpa-onnx-conformer-zh-stateless2-2023-05-23-chinese">csukuangfj/sherpa-onnx-conformer-zh-stateless2-2023-05-23 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#decode-wave-files">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#fp32">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#int8">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#csukuangfj-sherpa-onnx-conformer-zh-2023-05-23-chinese">csukuangfj/sherpa-onnx-conformer-zh-2023-05-23 (Chinese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id2">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id3">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id4">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id5">Speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#csukuangfj-sherpa-onnx-conformer-en-2023-03-18-english">csukuangfj/sherpa-onnx-conformer-en-2023-03-18 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id6">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id7">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id8">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id9">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/conformer-transducer-models.html#id10">Speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html">NeMo transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-parakeet-tdt-0-6b-v3-int8-25-european-languages">sherpa-onnx-nemo-parakeet-tdt-0.6b-v3-int8 (25 European Languages)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#colab">Colab</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#huggingface-space">Huggingface space</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#real-time-streaming-speech-recognition-from-a-microphone-with-vad">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-parakeet-tdt-0-6b-v2-int8-english">sherpa-onnx-nemo-parakeet-tdt-0.6b-v2-int8 (English, è‹±è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id2">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id3">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id4">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id5">Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#rtf-on-rk3588-with-cortex-a76-cpu">RTF on RK3588 with Cortex A76 CPU</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-transducer-giga-am-v2-russian-2025-04-19-russian">sherpa-onnx-nemo-transducer-giga-am-v2-russian-2025-04-19 (Russian, ä¿„è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id6">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id7">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id8">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id9">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id10">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24-russian">sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24 (Russian, ä¿„è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id12">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id13">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id14">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id15">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id16">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/offline-paraformer/index.html">Offline paraformer models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html">Paraformer models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#sherpa-onnx-paraformer-zh-int8-2025-10-07">sherpa-onnx-paraformer-zh-int8-2025-10-07 (å››å·è¯ã€é‡åº†è¯ã€å·æ¸æ–¹è¨€)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#huggingface-space">Huggingface space</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#android-apks">Android APKs</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#download">Download</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#wav">1.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id2">2.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id3">3.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id4">4.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id5">5.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id6">6.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id7">7.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id8">8.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id9">9.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id10">10.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id11">11.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id12">12.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id13">13.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id14">14.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id15">15.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id16">16.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#real-time-speech-recognition-from-a-microphone-with-vad">Real-time speech recognition from a microphone with VAD</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-trilingual-zh-cantonese-en-chinese-english-cantonese">csukuangfj/sherpa-onnx-paraformer-trilingual-zh-cantonese-en (Chinese + English + Cantonese ç²¤è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#fp32">fp32</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#int8">int8</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-en-2024-03-09-english">csukuangfj/sherpa-onnx-paraformer-en-2024-03-09 (English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id17">fp32</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id18">int8</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-small-2024-03-09-chinese-english">csukuangfj/sherpa-onnx-paraformer-zh-small-2024-03-09 (Chinese + English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id19">int8</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2024-03-09-chinese-english">csukuangfj/sherpa-onnx-paraformer-zh-2024-03-09 (Chinese + English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id20">fp32</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id21">int8</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2023-03-28-chinese-english">csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28 (Chinese + English)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id22">fp32</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id23">int8</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2023-09-14-chinese-english">csukuangfj/sherpa-onnx-paraformer-zh-2023-09-14 (Chinese + English))</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id24">int8</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/offline-ctc/index.html">Offline CTC models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-ctc/icefall/index.html">icefall</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/icefall/zipformer.html">Zipformer CTC models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/icefall/zipformer.html#sherpa-onnx-zipformer-ctc-zh-int8-2025-07-03-chinese">sherpa-onnx-zipformer-ctc-zh-int8-2025-07-03 (Chinese)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/icefall/zipformer.html#pre-built-android-apk">Pre-built Android APK</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/icefall/zipformer.html#webassembly-example-asr-from-a-microphone">WebAssembly example (ASR from a microphone)</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/icefall/zipformer.html#huggingface-space-decode-a-file">Huggingface space (Decode a file)</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/icefall/zipformer.html#download-the-model">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/icefall/zipformer.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/icefall/zipformer.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/icefall/zipformer.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/index.html">NeMo CTC-based models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html">How to export models from NeMo to sherpa-onnx</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html#step-1-export-model-onnx">Step 1: Export model.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html#step-2-add-metadata">Step 2: Add metadata</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html#step-3-obtain-model-int8-onnx">Step 3: Obtain model.int8.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html#step-4-obtain-tokens-txt">Step 4: Obtain tokens.txt</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html">English</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#sherpa-onnx-nemo-parakeet-tdt-ctc-110m-en-36000-int8-english">sherpa-onnx-nemo-parakeet_tdt_ctc_110m-en-36000-int8 (English, è‹±è¯­)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#download-the-model">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#stt-en-citrinet-512">stt_en_citrinet_512</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id1">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id2">Decode wave files</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#stt-en-conformer-ctc-small">stt_en_conformer_ctc_small</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id3">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id4">Decode wave files</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#stt-en-conformer-ctc-medium">stt_en_conformer_ctc_medium</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id5">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id6">Decode wave files</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#stt-en-conformer-ctc-large">stt_en_conformer_ctc_large</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id7">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id8">Decode wave files</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html">Russian</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#sherpa-onnx-nemo-ctc-giga-am-v2-russian-2025-04-19">sherpa-onnx-nemo-ctc-giga-am-v2-russian-2025-04-19</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#download-the-model">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24">sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#id2">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#id3">Decode wave files</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#id4">Speech recognition from a microphone</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#id5">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/japanese.html">Japanese</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/japanese.html#sherpa-onnx-nemo-parakeet-tdt-ctc-0-6b-ja-35000-int8-japanese">sherpa-onnx-nemo-parakeet-tdt_ctc-0.6b-ja-35000-int8 (Japanese, æ—¥è¯­)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/japanese.html#download-the-model">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/japanese.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/japanese.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/japanese.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html">WeNet CTC-based models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03">sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03 (å´è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#huggingface-space">Huggingface space</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#android-apks">Android APKs</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#download">Download</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#real-time-streaming-speech-recognition-from-a-microphone-with-vad">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#decode-wave-files">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#wav">1.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id2">2.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id3">3.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id4">4.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id5">5.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id6">6.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id7">7.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id8">8.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id9">9.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id10">10.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id11">11.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id12">12.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id13">13.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id14">14.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id15">15.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id16">16.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id17">17.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id18">18.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id19">19.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id20">20.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id21">21.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id22">22.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id23">23.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id24">24.wav</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10-cantonese">sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10 (Cantonese, ç²¤è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id25">Huggingface space</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id27">Android APKs</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id29">Download</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id30">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#id31">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-0-wav">yue-0.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-1-wav">yue-1.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-2-wav">yue-2.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-3-wav">yue-3.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-4-wav">yue-4.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-5-wav">yue-5.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-6-wav">yue-6.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-7-wav">yue-7.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-8-wav">yue-8.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-9-wav">yue-9.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-10-wav">yue-10.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-11-wav">yue-11.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-12-wav">yue-12.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-13-wav">yue-13.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-14-wav">yue-14.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-15-wav">yue-15.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-16-wav">yue-16.wav</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/wenet/index.html#yue-17-wav">yue-17.wav</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-ctc/yesno/index.html">yesno</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/yesno/index.html#decode-wave-files">Decode wave files</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/telespeech/index.html">TeleSpeech</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/telespeech/how-to-export.html">How to export models from Tele-AI/TeleSpeech-ASR to sherpa-onnx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/telespeech/how-to-export.html#step-1-export-model-onnx">Step 1: Export model.onnx</a></li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/telespeech/how-to-export.html#step-2-add-metadata">Step 2: Add metadata</a></li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/telespeech/how-to-export.html#step-3-obtain-tokens-txt">Step 3: Obtain tokens.txt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/telespeech/models.html">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/telespeech/models.html#sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04">sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04 (æ”¯æŒéå¸¸å¤šç§æ–¹è¨€)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/telespeech/models.html#decode-wave-files">Decode wave files</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/whisper/index.html">Whisper</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html">Export Whisper to ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html#available-models">Available models</a></li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html#export-to-onnx">Export to onnx</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html#example-1-export-tiny-en">Example 1: Export tiny.en</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html#example-2-export-large-v3">Example 2: Export large-v3</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/tiny.en.html">tiny.en</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/tiny.en.html#real-time-factor-rtf-on-raspberry-pi-4-model-b">Real-time factor (RTF) on Raspberry Pi 4 Model B</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/large-v3.html">large-v3</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/large-v3.html#run-with-cpu-float32">Run with CPU (float32)</a></li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/large-v3.html#run-with-cpu-int8">Run with CPU (int8)</a></li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/large-v3.html#run-with-gpu-float32">Run with GPU (float32)</a></li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/large-v3.html#run-with-gpu-int8">Run with GPU (int8)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/whisper/large-v3.html#fix-issues-about-running-on-gpu">Fix issues about running on GPU</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/large-v3.html#colab">colab</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/colab.html">colab</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/colab.html#non-large-models">Non-large models</a></li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/colab.html#large-models">Large models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/huggingface.html">Huggingface space</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/wenet/index.html">WeNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/wenet/how-to-export.html">How to export models from WeNet to sherpa-onnx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/wenet/how-to-export.html#export-for-non-streaming-inference">Export for non-streaming inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/wenet/how-to-export.html#export-for-streaming-inference">Export for streaming inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/wenet/how-to-export.html#faqs">FAQs</a></li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/wenet/how-to-export.html#sherpa-onnx-csrc-online-wenet-ctc-model-cc-init-144-head-does-not-exist-in-the-metadata">sherpa-onnx/csrc/online-wenet-ctc-model.cc:Init:144 head does not exist in the metadata</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/wenet/all-models.html">All models from WeNet</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/wenet/all-models.html#colab">Colab</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/small-online-models.html">Small models</a></li>
<li class="toctree-l2"><a class="reference internal" href="sense-voice/index.html">SenseVoice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/huggingface-space.html">Huggingface space</a></li>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/export.html">Export SenseVoice to sherpa-onnx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/export.html#the-code">The code</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/export.html#test-the-exported-model">Test the exported model</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/export.html#where-to-find-exported-models">Where to find exported models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/pretrained.html">Pre-trained Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17-int8-chinese-english-japanese-korean-cantonese">sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17-int8 (Chinese, English, Japanese, Korean, Cantonese, ä¸­è‹±æ—¥éŸ©ç²¤è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#huggingface-space">Huggingface space</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#android-apks">Android APKs</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#download">Download</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#decode-a-file-with-model-int8-onnx">Decode a file with model.int8.onnx</a><ul>
<li class="toctree-l6"><a class="reference internal" href="sense-voice/pretrained.html#without-inverse-text-normalization">Without inverse text normalization</a></li>
<li class="toctree-l6"><a class="reference internal" href="sense-voice/pretrained.html#with-inverse-text-normalization">With inverse text normalization</a></li>
<li class="toctree-l6"><a class="reference internal" href="sense-voice/pretrained.html#specify-a-language">Specify a language</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#real-time-streaming-speech-recognition-from-a-microphone-with-vad">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#speed-test-on-rk3588-cpu">Speed test on RK3588 CPU</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09-chinese-english-japanese-korean-cantonese">sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09 (Chinese, English, Japanese, Korean, Cantonese, ä¸­è‹±æ—¥éŸ©ç²¤è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#id1">Huggingface space</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#id3">Android APKs</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#id6">Download</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-0-wav">yue-0.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-1-wav">yue-1.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-2-wav">yue-2.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-3-wav">yue-3.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-4-wav">yue-4.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-5-wav">yue-5.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-6-wav">yue-6.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-7-wav">yue-7.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-8-wav">yue-8.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-9-wav">yue-9.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-10-wav">yue-10.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-11-wav">yue-11.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-12-wav">yue-12.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-13-wav">yue-13.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-14-wav">yue-14.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-15-wav">yue-15.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-16-wav">yue-16.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#yue-17-wav">yue-17.wav</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/c-api.html">C API for SenseVoice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/c-api.html#explanations">Explanations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/c-api.html#download-sherpa-onnx">1. Download sherpa-onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/c-api.html#download-the-model">2. Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/c-api.html#build-sherpa-onnx">3. Build sherpa-onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/c-api.html#view-the-build-result">4. View the build result</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/c-api.html#build-the-c-api-example">5. Build the C API example</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/c-api.html#run-it">6. Run it</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/c-api.html#where-to-find-sense-voice-c-api-c">7. Where to find sense-voice-c-api.c</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/dart-api.html">Dart API for SenseVoice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/dart-api.html#explanations">Explanations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/dart-api.html#download-the-code">1. Download the code</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/dart-api.html#download-the-sherpa-onnx-package">2. Download the sherpa-onnx package</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/dart-api.html#run-it">3. Run it</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/python-api.html">Python API for SenseVoice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/python-api.html#decode-a-file">Decode a file</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/python-api.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/python-api.html#generate-subtitles">Generate subtitles</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/python-api.html#chinese">Chinese</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/python-api.html#english">English</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/python-api.html#websocket-server-and-client-example">WebSocket server and client example</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/python-api.html#start-the-server">1. Start the server</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/python-api.html#start-the-client-decode-files-sequentially">2. Start the client (decode files sequentially)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/python-api.html#start-the-client-decode-files-in-parallel">3. Start the client (decode files in parallel)</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/python-api.html#start-the-web-browser-client">4. Start the  Web browser client</a><ul>
<li class="toctree-l6"><a class="reference internal" href="sense-voice/python-api.html#upload-a-file-for-recognition">Upload a file for recognition</a></li>
<li class="toctree-l6"><a class="reference internal" href="sense-voice/python-api.html#record-your-speech-with-a-microphone-for-recognition">Record your speech with a microphone for recognition</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pretrained_models/whisper/index.html">Whisper</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html">Export Whisper to ONNX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html#available-models">Available models</a></li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html#export-to-onnx">Export to onnx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html#example-1-export-tiny-en">Example 1: Export tiny.en</a></li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/export-onnx.html#example-2-export-large-v3">Example 2: Export large-v3</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/whisper/tiny.en.html">tiny.en</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/tiny.en.html#real-time-factor-rtf-on-raspberry-pi-4-model-b">Real-time factor (RTF) on Raspberry Pi 4 Model B</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/whisper/large-v3.html">large-v3</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/large-v3.html#run-with-cpu-float32">Run with CPU (float32)</a></li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/large-v3.html#run-with-cpu-int8">Run with CPU (int8)</a></li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/large-v3.html#run-with-gpu-float32">Run with GPU (float32)</a></li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/large-v3.html#run-with-gpu-int8">Run with GPU (int8)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/whisper/large-v3.html#fix-issues-about-running-on-gpu">Fix issues about running on GPU</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/large-v3.html#colab">colab</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/whisper/colab.html">colab</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/colab.html#non-large-models">Non-large models</a></li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/whisper/colab.html#large-models">Large models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pretrained_models/whisper/huggingface.html">Huggingface space</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="moonshine/index.html">Moonshine</a><ul>
<li class="toctree-l2"><a class="reference internal" href="moonshine/huggingface-space.html">Huggingface space</a></li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/models.html">Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="moonshine/models.html#sherpa-onnx-moonshine-tiny-en-int8">sherpa-onnx-moonshine-tiny-en-int8</a><ul>
<li class="toctree-l4"><a class="reference internal" href="moonshine/models.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l4"><a class="reference internal" href="moonshine/models.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l4"><a class="reference internal" href="moonshine/models.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="moonshine/models.html#sherpa-onnx-moonshine-base-en-int8">sherpa-onnx-moonshine-base-en-int8</a><ul>
<li class="toctree-l4"><a class="reference internal" href="moonshine/models.html#id2">Decode wave files</a></li>
<li class="toctree-l4"><a class="reference internal" href="moonshine/models.html#id3">Speech recognition from a microphone</a></li>
<li class="toctree-l4"><a class="reference internal" href="moonshine/models.html#id4">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/android.html">Android APKs for Moonshine</a></li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/c.html">C API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/csharp.html">C# API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/dart.html">Dart API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/go.html">Go API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/java.html">Java API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/javascript.html">JavaScript API examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="moonshine/javascript.html#webassembly-based-npm-package">WebAssembly based npm package</a></li>
<li class="toctree-l3"><a class="reference internal" href="moonshine/javascript.html#node-addon-based-npm-package">node-addon based npm package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/kotlin.html">Kotlin API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/pascal.html">Pascal API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/python.html">Python API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="moonshine/swift.html">Swift API examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="omnilingual-asr/index.html">Omnilingual ASR</a><ul>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/huggingface-space.html">Huggingface space</a></li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/export.html">Export to ONNX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="omnilingual-asr/export.html#where-to-find-the-export-code">Where to find the export code</a></li>
<li class="toctree-l3"><a class="reference internal" href="omnilingual-asr/export.html#where-to-find-test-code">Where to find test code</a></li>
<li class="toctree-l3"><a class="reference internal" href="omnilingual-asr/export.html#github-actions">GitHub Actions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/models.html">Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="omnilingual-asr/models.html#sherpa-onnx-omnilingual-asr-1600-languages-300m-ctc-int8-2025-11-12-1600-languages">sherpa-onnx-omnilingual-asr-1600-languages-300M-ctc-int8-2025-11-12 (1600+ languages)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="omnilingual-asr/models.html#download-the-model">Download the model</a><ul>
<li class="toctree-l5"><a class="reference internal" href="omnilingual-asr/models.html#decode-wave-files">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="omnilingual-asr/models.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l6"><a class="reference internal" href="omnilingual-asr/models.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/android.html">Android APKs for Omnilingual ASR</a></li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/c.html">C API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/csharp.html">C# API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/dart.html">Dart API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/go.html">Go API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/java.html">Java API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/javascript.html">JavaScript API examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="omnilingual-asr/javascript.html#webassembly-based-npm-package">WebAssembly based npm package</a></li>
<li class="toctree-l3"><a class="reference internal" href="omnilingual-asr/javascript.html#node-addon-based-npm-package">node-addon based npm package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/kotlin.html">Kotlin API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/pascal.html">Pascal API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/python.html">Python API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="omnilingual-asr/swift.html">Swift API examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sense-voice/index.html">SenseVoice</a><ul>
<li class="toctree-l2"><a class="reference internal" href="sense-voice/huggingface-space.html">Huggingface space</a></li>
<li class="toctree-l2"><a class="reference internal" href="sense-voice/export.html">Export SenseVoice to sherpa-onnx</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/export.html#the-code">The code</a></li>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/export.html#test-the-exported-model">Test the exported model</a></li>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/export.html#where-to-find-exported-models">Where to find exported models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sense-voice/pretrained.html">Pre-trained Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/pretrained.html#sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17-int8-chinese-english-japanese-korean-cantonese">sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17-int8 (Chinese, English, Japanese, Korean, Cantonese, ä¸­è‹±æ—¥éŸ©ç²¤è¯­)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#huggingface-space">Huggingface space</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#android-apks">Android APKs</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#download">Download</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#decode-a-file-with-model-int8-onnx">Decode a file with model.int8.onnx</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#without-inverse-text-normalization">Without inverse text normalization</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#with-inverse-text-normalization">With inverse text normalization</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/pretrained.html#specify-a-language">Specify a language</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#real-time-streaming-speech-recognition-from-a-microphone-with-vad">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#speed-test-on-rk3588-cpu">Speed test on RK3588 CPU</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/pretrained.html#sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09-chinese-english-japanese-korean-cantonese">sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09 (Chinese, English, Japanese, Korean, Cantonese, ä¸­è‹±æ—¥éŸ©ç²¤è¯­)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#id1">Huggingface space</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#id3">Android APKs</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#id6">Download</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-0-wav">yue-0.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-1-wav">yue-1.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-2-wav">yue-2.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-3-wav">yue-3.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-4-wav">yue-4.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-5-wav">yue-5.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-6-wav">yue-6.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-7-wav">yue-7.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-8-wav">yue-8.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-9-wav">yue-9.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-10-wav">yue-10.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-11-wav">yue-11.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-12-wav">yue-12.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-13-wav">yue-13.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-14-wav">yue-14.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-15-wav">yue-15.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-16-wav">yue-16.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/pretrained.html#yue-17-wav">yue-17.wav</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sense-voice/c-api.html">C API for SenseVoice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/c-api.html#explanations">Explanations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/c-api.html#download-sherpa-onnx">1. Download sherpa-onnx</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/c-api.html#download-the-model">2. Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/c-api.html#build-sherpa-onnx">3. Build sherpa-onnx</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/c-api.html#view-the-build-result">4. View the build result</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/c-api.html#build-the-c-api-example">5. Build the C API example</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/c-api.html#run-it">6. Run it</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/c-api.html#where-to-find-sense-voice-c-api-c">7. Where to find sense-voice-c-api.c</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sense-voice/dart-api.html">Dart API for SenseVoice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/dart-api.html#explanations">Explanations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/dart-api.html#download-the-code">1. Download the code</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/dart-api.html#download-the-sherpa-onnx-package">2. Download the sherpa-onnx package</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/dart-api.html#run-it">3. Run it</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sense-voice/python-api.html">Python API for SenseVoice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/python-api.html#decode-a-file">Decode a file</a></li>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/python-api.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/python-api.html#generate-subtitles">Generate subtitles</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/python-api.html#chinese">Chinese</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/python-api.html#english">English</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sense-voice/python-api.html#websocket-server-and-client-example">WebSocket server and client example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/python-api.html#start-the-server">1. Start the server</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/python-api.html#start-the-client-decode-files-sequentially">2. Start the client (decode files sequentially)</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/python-api.html#start-the-client-decode-files-in-parallel">3. Start the client (decode files in parallel)</a></li>
<li class="toctree-l4"><a class="reference internal" href="sense-voice/python-api.html#start-the-web-browser-client">4. Start the  Web browser client</a><ul>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/python-api.html#upload-a-file-for-recognition">Upload a file for recognition</a></li>
<li class="toctree-l5"><a class="reference internal" href="sense-voice/python-api.html#record-your-speech-with-a-microphone-for-recognition">Record your speech with a microphone for recognition</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="funasr-nano/index.html">FunASR Nano</a><ul>
<li class="toctree-l2"><a class="reference internal" href="funasr-nano/index.html#fun-asr-nano-2512">Fun-ASR-Nano-2512</a><ul>
<li class="toctree-l3"><a class="reference internal" href="funasr-nano/huggingface-space.html">Huggingface space</a></li>
<li class="toctree-l3"><a class="reference internal" href="funasr-nano/export.html">Export FunASR Nano to sherpa-onnx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="funasr-nano/export.html#the-code">The code</a></li>
<li class="toctree-l4"><a class="reference internal" href="funasr-nano/export.html#where-to-find-exported-models">Where to find exported models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="funasr-nano/pretrained.html">Pre-trained Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="funasr-nano/pretrained.html#sherpa-onnx-funasr-nano-int8-2025-12-30-chinese-english-japanese">sherpa-onnx-funasr-nano-int8-2025-12-30 (Chinese, English, Japanese)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#huggingface-space">Huggingface space</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#android-apks">Android APKs</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#download">Download</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#dia-hunan-wav">dia_hunan.wav (æ¹–å—æ–¹è¨€)</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#dia-minnan-wav">dia_minnan.wav (é—½å—è¯­)</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#dia-sh-wav">dia_sh.wav (ä¸Šæµ·è¯)</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#dia-yue-wav">dia_yue.wav (ç²¤è¯­ï¼Œå¹¿ä¸œè¯)</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#lyrics-wav-1">lyrics.wav (ä¸­æ–‡æ­Œæ›²-1)</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#lyrics-2-wav-2">lyrics_2.wav (ä¸­æ–‡æ­Œæ›²-2)</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#lyrics-3-wav-3">lyrics_3.wav (ä¸­æ–‡æ­Œæ›²-3)</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#lyrics-en-1-wav-1">lyrics_en_1.wav (è‹±æ–‡æ­Œæ›²-1)</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#lyrics-en-2-wav-2">lyrics_en_2.wav (è‹±æ–‡æ­Œæ›²-2)</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#lyrics-en-3-wav-3">lyrics_en_3.wav (è‹±æ–‡æ­Œæ›²-3)</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#noise-en-wav-3">noise_en.wav (è‹±æ–‡æ­Œæ›²-3)</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#far-2-wav">far_2.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#far-3-wav">far_3.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#far-4-wav">far_4.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#far-5-wav">far_5.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#rag-chemistry-wav">rag_chemistry.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#rag-history-wav">rag_history.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#rag-math-wav">rag_math.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#rag-medical-wav">rag_medical.wav</a></li>
<li class="toctree-l5"><a class="reference internal" href="funasr-nano/pretrained.html#rag-physics-wav">rag_physics.wav</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="paraformer/index.html">Paraformer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="paraformer/index.html#non-streaming-paraformer">Non-streaming Paraformer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-paraformer/index.html">Offline paraformer models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html">Paraformer models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#sherpa-onnx-paraformer-zh-int8-2025-10-07">sherpa-onnx-paraformer-zh-int8-2025-10-07 (å››å·è¯ã€é‡åº†è¯ã€å·æ¸æ–¹è¨€)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#huggingface-space">Huggingface space</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#android-apks">Android APKs</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#download">Download</a><ul>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#wav">1.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id2">2.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id3">3.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id4">4.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id5">5.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id6">6.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id7">7.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id8">8.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id9">9.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id10">10.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id11">11.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id12">12.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id13">13.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id14">14.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id15">15.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id16">16.wav</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#real-time-speech-recognition-from-a-microphone-with-vad">Real-time speech recognition from a microphone with VAD</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-trilingual-zh-cantonese-en-chinese-english-cantonese">csukuangfj/sherpa-onnx-paraformer-trilingual-zh-cantonese-en (Chinese + English + Cantonese ç²¤è¯­)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#fp32">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#int8">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-en-2024-03-09-english">csukuangfj/sherpa-onnx-paraformer-en-2024-03-09 (English)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id17">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id18">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-small-2024-03-09-chinese-english">csukuangfj/sherpa-onnx-paraformer-zh-small-2024-03-09 (Chinese + English)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id19">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2024-03-09-chinese-english">csukuangfj/sherpa-onnx-paraformer-zh-2024-03-09 (Chinese + English)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id20">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id21">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2023-03-28-chinese-english">csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28 (Chinese + English)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id22">fp32</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id23">int8</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2023-09-14-chinese-english">csukuangfj/sherpa-onnx-paraformer-zh-2023-09-14 (Chinese + English))</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-paraformer/paraformer-models.html#id24">int8</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="paraformer/index.html#streaming-paraformer">Streaming Paraformer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/online-paraformer/index.html">Online paraformer models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html">Paraformer models</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-streaming-paraformer-bilingual-zh-en-chinese-english">csukuangfj/sherpa-onnx-streaming-paraformer-bilingual-zh-en (Chinese + English)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#decode-a-single-wave-file">Decode a single wave file</a><ul>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#fp32">fp32</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#int8">int8</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#real-time-speech-recognition-from-a-microphone">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-streaming-paraformer-trilingual-zh-cantonese-en-chinese-cantonese-english">csukuangfj/sherpa-onnx-streaming-paraformer-trilingual-zh-cantonese-en (Chinese + Cantonese + English)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#id1">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#id2">Decode a single wave file</a><ul>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#id3">fp32</a></li>
<li class="toctree-l7"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#id4">int8</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/online-paraformer/paraformer-models.html#id5">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nemo/index.html">NeMo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nemo/index.html#speech-recognition-models">Speech Recognition models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/index.html">NeMo CTC-based models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html">How to export models from NeMo to sherpa-onnx</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html#step-1-export-model-onnx">Step 1: Export model.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html#step-2-add-metadata">Step 2: Add metadata</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html#step-3-obtain-model-int8-onnx">Step 3: Obtain model.int8.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/how-to-export.html#step-4-obtain-tokens-txt">Step 4: Obtain tokens.txt</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html">English</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#sherpa-onnx-nemo-parakeet-tdt-ctc-110m-en-36000-int8-english">sherpa-onnx-nemo-parakeet_tdt_ctc_110m-en-36000-int8 (English, è‹±è¯­)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#download-the-model">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#stt-en-citrinet-512">stt_en_citrinet_512</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id1">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id2">Decode wave files</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#stt-en-conformer-ctc-small">stt_en_conformer_ctc_small</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id3">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id4">Decode wave files</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#stt-en-conformer-ctc-medium">stt_en_conformer_ctc_medium</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id5">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id6">Decode wave files</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#stt-en-conformer-ctc-large">stt_en_conformer_ctc_large</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id7">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/english.html#id8">Decode wave files</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html">Russian</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#sherpa-onnx-nemo-ctc-giga-am-v2-russian-2025-04-19">sherpa-onnx-nemo-ctc-giga-am-v2-russian-2025-04-19</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#download-the-model">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24">sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#id2">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#id3">Decode wave files</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#id4">Speech recognition from a microphone</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/russian.html#id5">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/japanese.html">Japanese</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/japanese.html#sherpa-onnx-nemo-parakeet-tdt-ctc-0-6b-ja-35000-int8-japanese">sherpa-onnx-nemo-parakeet-tdt_ctc-0.6b-ja-35000-int8 (Japanese, æ—¥è¯­)</a><ul>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/japanese.html#download-the-model">Download the model</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/japanese.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/japanese.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l6"><a class="reference internal" href="pretrained_models/offline-ctc/nemo/japanese.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html">NeMo transducer-based Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-parakeet-tdt-0-6b-v3-int8-25-european-languages">sherpa-onnx-nemo-parakeet-tdt-0.6b-v3-int8 (25 European Languages)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#colab">Colab</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#huggingface-space">Huggingface space</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#decode-wave-files">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#real-time-streaming-speech-recognition-from-a-microphone-with-vad">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#speech-recognition-from-a-microphone">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#speech-recognition-from-a-microphone-with-vad">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-parakeet-tdt-0-6b-v2-int8-english">sherpa-onnx-nemo-parakeet-tdt-0.6b-v2-int8 (English, è‹±è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id2">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id3">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id4">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id5">Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#rtf-on-rk3588-with-cortex-a76-cpu">RTF on RK3588 with Cortex A76 CPU</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-transducer-giga-am-v2-russian-2025-04-19-russian">sherpa-onnx-nemo-transducer-giga-am-v2-russian-2025-04-19 (Russian, ä¿„è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id6">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id7">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id8">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id9">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id10">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24-russian">sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24 (Russian, ä¿„è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id12">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id13">Decode wave files</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id14">Real-time/Streaming Speech recognition from a microphone with VAD</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id15">Speech recognition from a microphone</a></li>
<li class="toctree-l5"><a class="reference internal" href="pretrained_models/offline-transducer/nemo-transducer-models.html#id16">Speech recognition from a microphone with VAD</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nemo/canary.html">Non-streaming Canary models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nemo/canary.html#sherpa-onnx-nemo-canary-180m-flash-en-es-de-fr-int8-english-spanish-german-french">sherpa-onnx-nemo-canary-180m-flash-en-es-de-fr-int8 (English + Spanish + German + French, è‹±è¯­+è¥¿ç­ç‰™è¯­+å¾·è¯­+æ³•è¯­)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="nemo/canary.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="nemo/canary.html#decode-wave-files">Decode wave files</a><ul>
<li class="toctree-l6"><a class="reference internal" href="nemo/canary.html#input-english-output-english">Input English, output English</a></li>
<li class="toctree-l6"><a class="reference internal" href="nemo/canary.html#input-english-output-german">Input English, output German</a></li>
<li class="toctree-l6"><a class="reference internal" href="nemo/canary.html#input-english-output-spanish">Input English, output Spanish</a></li>
<li class="toctree-l6"><a class="reference internal" href="nemo/canary.html#input-english-output-french">Input English, output French</a></li>
<li class="toctree-l6"><a class="reference internal" href="nemo/canary.html#input-german-output-english">Input German, output English</a></li>
<li class="toctree-l6"><a class="reference internal" href="nemo/canary.html#input-german-output-german">Input German, output German</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="nemo/canary.html#python-api-examples">Python API examples</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nemo/index.html#speaker-embedding-models">Speaker Embedding models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="FireRedAsr/index.html">FireRedAsr</a><ul>
<li class="toctree-l2"><a class="reference internal" href="FireRedAsr/huggingface-space.html">Huggingface space</a></li>
<li class="toctree-l2"><a class="reference internal" href="FireRedAsr/pretrained.html">Pre-trained Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="FireRedAsr/pretrained.html#sherpa-onnx-fire-red-asr-large-zh-en-2025-02-16-chinese-english">sherpa-onnx-fire-red-asr-large-zh_en-2025-02-16 (Chinese + English, æ™®é€šè¯ã€å››å·è¯ã€æ²³å—è¯ç­‰)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="FireRedAsr/pretrained.html#download">Download</a></li>
<li class="toctree-l4"><a class="reference internal" href="FireRedAsr/pretrained.html#decode-a-file">Decode a file</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Dolphin/index.html">Dolphin</a><ul>
<li class="toctree-l2"><a class="reference internal" href="Dolphin/huggingface-space.html">Huggingface space</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dolphin/pretrained.html">Pre-trained Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="Dolphin/pretrained.html#sherpa-onnx-dolphin-base-ctc-multi-lang-int8-2025-04-02">sherpa-onnx-dolphin-base-ctc-multi-lang-int8-2025-04-02</a><ul>
<li class="toctree-l4"><a class="reference internal" href="Dolphin/pretrained.html#download">Download</a></li>
<li class="toctree-l4"><a class="reference internal" href="Dolphin/pretrained.html#decode-a-file">Decode a file</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="Dolphin/pretrained.html#sherpa-onnx-dolphin-base-ctc-multi-lang-2025-04-02">sherpa-onnx-dolphin-base-ctc-multi-lang-2025-04-02</a><ul>
<li class="toctree-l4"><a class="reference internal" href="Dolphin/pretrained.html#id2">Download</a></li>
<li class="toctree-l4"><a class="reference internal" href="Dolphin/pretrained.html#id3">Decode a file</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="Dolphin/pretrained.html#sherpa-onnx-dolphin-small-ctc-multi-lang-int8-2025-04-02">sherpa-onnx-dolphin-small-ctc-multi-lang-int8-2025-04-02</a><ul>
<li class="toctree-l4"><a class="reference internal" href="Dolphin/pretrained.html#id4">Download</a></li>
<li class="toctree-l4"><a class="reference internal" href="Dolphin/pretrained.html#id5">Decode a file</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="Dolphin/pretrained.html#sherpa-onnx-dolphin-small-ctc-multi-lang-2025-04-02">sherpa-onnx-dolphin-small-ctc-multi-lang-2025-04-02</a><ul>
<li class="toctree-l4"><a class="reference internal" href="Dolphin/pretrained.html#id7">Download</a></li>
<li class="toctree-l4"><a class="reference internal" href="Dolphin/pretrained.html#id8">Decode a file</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="homophone-replacer/index.html">æ‹¼éŸ³è¯ç»„åŒ¹é…æ›¿æ¢</a><ul>
<li class="toctree-l2"><a class="reference internal" href="homophone-replacer/index.html#id2">ä½¿ç”¨åœºæ™¯</a></li>
<li class="toctree-l2"><a class="reference internal" href="homophone-replacer/index.html#id3">ä½¿ç”¨é™åˆ¶</a></li>
<li class="toctree-l2"><a class="reference internal" href="homophone-replacer/index.html#id4">ä½¿ç”¨æ–¹æ³•</a><ul>
<li class="toctree-l3"><a class="reference internal" href="homophone-replacer/index.html#replace-fst">ç”Ÿæˆreplace.fst</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="homophone-replacer/index.html#id6">æµ‹è¯•</a><ul>
<li class="toctree-l3"><a class="reference internal" href="homophone-replacer/index.html#id8">(1) ä¸ä½¿ç”¨æœ¬æ–‡çš„æ–¹æ³•</a></li>
<li class="toctree-l3"><a class="reference internal" href="homophone-replacer/index.html#id9">(2) ä½¿ç”¨æœ¬æ–‡çš„æ–¹æ³•</a></li>
<li class="toctree-l3"><a class="reference internal" href="homophone-replacer/index.html#id11">(3) ç»“æœæ¯”è¾ƒ</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="homophone-replacer/index.html#id12">è°ƒè¯•</a></li>
<li class="toctree-l2"><a class="reference internal" href="homophone-replacer/index.html#id13">è§†é¢‘æ¼”ç¤º</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Speaker diarization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="speaker-diarization/index.html">Speaker Diarization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/models.html">Pre-trained models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speaker-diarization/models.html#colab-notebook">Colab notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="speaker-diarization/models.html#sherpa-onnx-pyannote-segmentation-3-0">sherpa-onnx-pyannote-segmentation-3-0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speaker-diarization/models.html#download-the-model">Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="speaker-diarization/models.html#usage-for-speaker-diarization">Usage for speaker diarization</a><ul>
<li class="toctree-l5"><a class="reference internal" href="speaker-diarization/models.html#d-speaker-model-onnx">3D-Speaker + model.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="speaker-diarization/models.html#d-speaker-model-int8-onnx">3D-Speaker + model.int8.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="speaker-diarization/models.html#nemo-model-onnx">NeMo + model.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="speaker-diarization/models.html#nemo-model-int8-onnx">NeMo + model.int8.onnx</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speaker-diarization/models.html#sherpa-onnx-reverb-diarization-v1">sherpa-onnx-reverb-diarization-v1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speaker-diarization/models.html#id3">Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="speaker-diarization/models.html#id4">Usage for speaker diarization</a><ul>
<li class="toctree-l5"><a class="reference internal" href="speaker-diarization/models.html#id6">3D-Speaker + model.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="speaker-diarization/models.html#id7">3D-Speaker + model.int8.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="speaker-diarization/models.html#id8">NeMo + model.onnx</a></li>
<li class="toctree-l5"><a class="reference internal" href="speaker-diarization/models.html#id9">NeMo + model.int8.onnx</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/hf.html">Hugginface space for speaker diarization</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/android.html">Android APKs for speaker diarization</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/c.html">C API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/cpp.html">C++ API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/csharp.html">C# API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/dart.html">Dart API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/go.html">Go API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/java.html">Java API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/javascript.html">JavaScript API examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speaker-diarization/javascript.html#webassembly-based-npm-package">WebAssembly based npm package</a></li>
<li class="toctree-l3"><a class="reference internal" href="speaker-diarization/javascript.html#node-addon-based-npm-package">node-addon based npm package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/kotlin.html">Kotlin API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/pascal.html">Pascal API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/python.html">Python API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/rust.html">Rust API examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="speaker-diarization/swift.html">Swift API examples</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Speaker Identification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="speaker-identification/index.html">Speaker Identification</a></li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Speech enhancement</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="speech-enhancement/index.html">Speech enhancement</a><ul>
<li class="toctree-l2"><a class="reference internal" href="speech-enhancement/models.html">Pre-trained models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speech-enhancement/models.html#gtcrn-simple">gtcrn_simple</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speech-enhancement/models.html#download-the-model">Download the model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speech-enhancement/hf.html">Hugginface space for speech enhancement</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Source separation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="source-separation/index.html">Source separation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="source-separation/hf.html">Hugginface space for source separation</a></li>
<li class="toctree-l2"><a class="reference internal" href="source-separation/models.html">Source separation models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="source-separation/models.html#spleeter">Spleeter</a><ul>
<li class="toctree-l4"><a class="reference internal" href="source-separation/models.html#download-the-model">Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="source-separation/models.html#download-test-files">Download test files</a></li>
<li class="toctree-l4"><a class="reference internal" href="source-separation/models.html#example-1-2-with-qi-feng-le-zh-wav">Example 1/2 with qi-feng-le-zh.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="source-separation/models.html#example-2-2-with-audio-example-wav">Example 2/2 with audio_example.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="source-separation/models.html#rtf-on-rk3588">RTF on RK3588</a></li>
<li class="toctree-l4"><a class="reference internal" href="source-separation/models.html#python-example">Python example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="source-separation/models.html#uvr">UVR</a><ul>
<li class="toctree-l4"><a class="reference internal" href="source-separation/models.html#id4">Download the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="source-separation/models.html#id5">Download test files</a></li>
<li class="toctree-l4"><a class="reference internal" href="source-separation/models.html#id6">Example 1/2 with qi-feng-le-zh.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="source-separation/models.html#id7">Example 2/2 with audio_example.wav</a></li>
<li class="toctree-l4"><a class="reference internal" href="source-separation/models.html#id8">Python example</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Qualcomm NPU (qnn, HTP)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="qnn/index.html">Qualcomm NPU (QNN, HTP)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="qnn/download-qnn.html">Download QNN SDK</a><ul>
<li class="toctree-l3"><a class="reference internal" href="qnn/download-qnn.html#qnn-sdk-root">QNN_SDK_ROOT</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="qnn/build.html">Build sherpa-onnx for Qualcomm NPU</a><ul>
<li class="toctree-l3"><a class="reference internal" href="qnn/build.html#shared-libraries">Shared libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="qnn/build.html#executable-files">Executable files</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="qnn/run-executables-on-your-phone-binary.html">Run executables on your phone with adb (using model.bin)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="qnn/run-executables-on-your-phone-binary.html#download-a-qnn-model">Download a QNN model</a></li>
<li class="toctree-l3"><a class="reference internal" href="qnn/run-executables-on-your-phone-binary.html#copy-files-to-your-phone">Copy files to your phone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone-binary.html#copy-model-files">Copy model files</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone-binary.html#copy-sherpa-onnx-executable-files">Copy sherpa-onnx executable files</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone-binary.html#copy-sherpa-onnx-library-files">Copy sherpa-onnx library files</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone-binary.html#copy-qnn-library-files">Copy QNN library files</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="qnn/run-executables-on-your-phone-binary.html#run-it">Run it !</a><ul>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone-binary.html#check-files">Check files</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone-binary.html#set-environment-variable-adsp-library-path">Set environment variable ADSP_LIBRARY_PATH</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone-binary.html#run-sherpa-onnx-offline">Run sherpa-onnx-offline</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="qnn/run-executables-on-your-phone-binary.html#congratulations">Congratulations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="qnn/run-executables-on-your-phone.html">Run executables on your phone with adb (using libmodel.so)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#download-a-qnn-model">Download a QNN model</a></li>
<li class="toctree-l3"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#copy-files-to-your-phone">Copy files to your phone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#copy-model-files">Copy model files</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#copy-sherpa-onnx-executable-files">Copy sherpa-onnx executable files</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#copy-sherpa-onnx-library-files">Copy sherpa-onnx library files</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#copy-qnn-library-files">Copy QNN library files</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#run-it">Run it !</a><ul>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#check-files">Check files</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#set-environment-variable-adsp-library-path">Set environment variable ADSP_LIBRARY_PATH</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#run-sherpa-onnx-offline">Run sherpa-onnx-offline</a><ul>
<li class="toctree-l5"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#log-of-the-first-run">Log of the first run</a></li>
<li class="toctree-l5"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#log-of-later-runs">Log of later runs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="qnn/run-executables-on-your-phone.html#congratulations">Congratulations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="qnn/build-android-demo.html">Build Android examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="qnn/build-android-demo.html#pre-built-apks">Pre-built APKs</a></li>
<li class="toctree-l3"><a class="reference internal" href="qnn/build-android-demo.html#how-to-build-android-examples">How to build Android examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="qnn/build-android-demo.html#build-shared-libraries">1. Build shared libraries</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/build-android-demo.html#copy-qnn-libs">2. Copy QNN libs</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/build-android-demo.html#download-model-files">3. Download model files</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/build-android-demo.html#change-the-code-to-use-our-selected-model">4. Change the code to use our selected model</a></li>
<li class="toctree-l4"><a class="reference internal" href="qnn/build-android-demo.html#build-the-demo">5. Build the demo</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="qnn/models.html">Models for QNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="qnn/models.html#sherpa-onnx-qnn-sm8850-binary-5-seconds-zipformer-ctc-zh-2025-12-22-int8-chinese">sherpa-onnx-qnn-SM8850-binary-5-seconds-zipformer-ctc-zh-2025-12-22-int8 (Chinese)</a></li>
<li class="toctree-l3"><a class="reference internal" href="qnn/models.html#sherpa-onnx-qnn-sm8850-binary-5-seconds-zipformer-ctc-zh-2025-07-03-int8-chinese">sherpa-onnx-qnn-SM8850-binary-5-seconds-zipformer-ctc-zh-2025-07-03-int8 (Chinese)</a></li>
<li class="toctree-l3"><a class="reference internal" href="qnn/models.html#sherpa-onnx-qnn-sm8850-binary-5-seconds-sense-voice-zh-en-ja-ko-yue-2024-07-17-int8-chinese-english-japanese-korean-cantonese">sherpa-onnx-qnn-SM8850-binary-5-seconds-sense-voice-zh-en-ja-ko-yue-2024-07-17-int8 (Chinese, English, Japanese, Korean, Cantonese, ä¸­è‹±æ—¥éŸ©ç²¤è¯­)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">RKNN</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="rknn/index.html">rknn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="rknn/tutorials.html">Tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rknn/tutorials.html#zipformer-on-lubancat">Zipformer on LubanCat</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rknn/install.html">Install</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rknn/install.html#from-pre-built-wheels-using-pip-install">From pre-built wheels using pip install</a></li>
<li class="toctree-l3"><a class="reference internal" href="rknn/install.html#download-pre-compiled-binaries">Download pre-compiled binaries</a></li>
<li class="toctree-l3"><a class="reference internal" href="rknn/install.html#build-sherpa-onnx-directly-on-your-board">Build sherpa-onnx directly on your board</a></li>
<li class="toctree-l3"><a class="reference internal" href="rknn/install.html#cross-compiling">Cross-compiling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="rknn/install.html#dynamic-link">Dynamic link</a></li>
<li class="toctree-l4"><a class="reference internal" href="rknn/install.html#static-link">Static link</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rknn/models.html">Pre-trained models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rknn/models.html#sherpa-onnx-rk3588-streaming-zipformer-small-bilingual-zh-en-2023-02-16">sherpa-onnx-rk3588-streaming-zipformer-small-bilingual-zh-en-2023-02-16</a><ul>
<li class="toctree-l4"><a class="reference internal" href="rknn/models.html#decode-files">Decode files</a></li>
<li class="toctree-l4"><a class="reference internal" href="rknn/models.html#real-time-speech-recognition-from-a-microphone">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="rknn/models.html#sherpa-onnx-rk3588-streaming-zipformer-bilingual-zh-en-2023-02-20">sherpa-onnx-rk3588-streaming-zipformer-bilingual-zh-en-2023-02-20</a><ul>
<li class="toctree-l4"><a class="reference internal" href="rknn/models.html#id1">Decode files</a></li>
<li class="toctree-l4"><a class="reference internal" href="rknn/models.html#id3">Real-time speech recognition from a microphone</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="rknn/models.html#sherpa-onnx-rk3588-20-seconds-sense-voice-zh-en-ja-ko-yue-2024-07-17-chinese-english-japanese-korean-cantonese">sherpa-onnx-rk3588-20-seconds-sense-voice-zh-en-ja-ko-yue-2024-07-17 (Chinese, English, Japanese, Korean, Cantonese, ä¸­è‹±æ—¥éŸ©ç²¤è¯­)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="rknn/models.html#decode-long-files-with-a-vad">Decode long files with a VAD</a></li>
<li class="toctree-l4"><a class="reference internal" href="rknn/models.html#decode-a-short-file">Decode a short file</a></li>
<li class="toctree-l4"><a class="reference internal" href="rknn/models.html#speed-test">Speed test</a><ul>
<li class="toctree-l5"><a class="reference internal" href="rknn/models.html#sense-voice-int8-onnx-model-on-1-cortex-a55-cpu">Sense-voice <code class="docutils literal notranslate"><span class="pre">int8</span></code> ONNX model on 1 Cortex A55 CPU</a></li>
<li class="toctree-l5"><a class="reference internal" href="rknn/models.html#sense-voice-int8-onnx-model-on-1-cortex-a76-cpu">Sense-voice <code class="docutils literal notranslate"><span class="pre">int8</span></code> ONNX model on 1 Cortex A76 CPU</a></li>
<li class="toctree-l5"><a class="reference internal" href="rknn/models.html#sense-voice-rknn-model-on-1-rk3588-npu">Sense-voice RKNN model on 1 RK3588 NPU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="rknn/models.html#sherpa-onnx-rk3588-20-seconds-sense-voice-zh-en-ja-ko-yue-2025-09-09-chinese-english-japanese-korean-cantonese">sherpa-onnx-rk3588-20-seconds-sense-voice-zh-en-ja-ko-yue-2025-09-09 (Chinese, English, Japanese, Korean, Cantonese, ä¸­è‹±æ—¥éŸ©ç²¤è¯­)</a></li>
<li class="toctree-l3"><a class="reference internal" href="rknn/models.html#sherpa-onnx-rk3588-15-seconds-paraformer-zh-2025-10-07">sherpa-onnx-rk3588-15-seconds-paraformer-zh-2025-10-07</a><ul>
<li class="toctree-l4"><a class="reference internal" href="rknn/models.html#id6">Decode files</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Ascend NPU</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="ascend/index.html">Ascend NPU (æ˜‡è…¾ NPU)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="ascend/install.html">Install</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ascend/install.html#install-cann">Install CANN</a></li>
<li class="toctree-l3"><a class="reference internal" href="ascend/install.html#build-sherpa-onnx">Build sherpa-onnx</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ascend/export.html">Export models to Ascend NPU</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ascend/export.html#export-sensevoice">Export SenseVoice</a></li>
<li class="toctree-l3"><a class="reference internal" href="ascend/export.html#export-paraformer">Export Paraformer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ascend/models.html">Pre-trained models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ascend/models.html#sherpa-onnx-ascend-910b-cann-8-0-sense-voice-zh-en-ja-ko-yue-2024-07-17-chinese-english-japanese-korean-cantonese">sherpa-onnx-ascend-910B-cann-8.0-sense-voice-zh-en-ja-ko-yue-2024-07-17 (Chinese, English, Japanese, Korean, Cantonese, ä¸­è‹±æ—¥éŸ©ç²¤è¯­)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ascend/models.html#decode-long-files-with-a-vad">Decode long files with a VAD</a></li>
<li class="toctree-l4"><a class="reference internal" href="ascend/models.html#decode-a-short-file">Decode a short file</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ascend/models.html#sherpa-onnx-ascend-910b-cann-8-0-sense-voice-zh-en-ja-ko-yue-2025-09-09-chinese-english-japanese-korean-cantonese">sherpa-onnx-ascend-910B-cann-8.0-sense-voice-zh-en-ja-ko-yue-2025-09-09 (Chinese, English, Japanese, Korean, Cantonese, ä¸­è‹±æ—¥éŸ©ç²¤è¯­)</a></li>
<li class="toctree-l3"><a class="reference internal" href="ascend/models.html#sherpa-onnx-ascend-910b-cann-8-0-paraformer-zh-2023-03-28-chinese-english">sherpa-onnx-ascend-910B-cann-8.0-paraformer-zh-2023-03-28 (Chinese + English)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ascend/models.html#id3">Decode long files with a VAD</a></li>
<li class="toctree-l4"><a class="reference internal" href="ascend/models.html#id5">Decode a short file</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ascend/models.html#sherpa-onnx-ascend-910b2-cann-8-0-paraformer-zh-2025-10-07">sherpa-onnx-ascend-910B2-cann-8.0-paraformer-zh-2025-10-07 (å››å·è¯ã€é‡åº†è¯ã€å·æ¸æ–¹è¨€)</a></li>
<li class="toctree-l3"><a class="reference internal" href="ascend/models.html#sherpa-onnx-ascend-910b-cann-7-0-5-seconds-zipformer-ctc-zh-2025-07-03">sherpa-onnx-ascend-910B-cann-7.0-5-seconds-zipformer-ctc-zh-2025-07-03 (ä¸­æ–‡)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ascend/models.html#id11">Decode a short file</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">tts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tts/index.html">Text-to-speech (TTS)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tts/all-in-one.html">All-in-one</a></li>
<li class="toctree-l2"><a class="reference internal" href="tts/hf-space.html">Huggingface space</a></li>
<li class="toctree-l2"><a class="reference internal" href="tts/pretrained_models/index.html">Pre-trained models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tts/pretrained_models/rtf.html">RTF of pre-trained models</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/pretrained_models/matcha.html">Matcha</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/matcha.html#matcha-icefall-en-us-ljspeech-american-english-1-female-speaker">matcha-icefall-en_US-ljspeech (American English, 1 female speaker)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/matcha.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/matcha.html#generate-speech-with-executables-compiled-from-c">Generate speech with executables compiled from C++</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/matcha.html#generate-speech-with-python-script">Generate speech with Python script</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/matcha.html#rtf-on-raspberry-pi-4-model-b-rev-1-5">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/matcha.html#matcha-icefall-zh-baker-chinese-1-female-speaker">matcha-icefall-zh-baker (Chinese, 1 female speaker)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/matcha.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/matcha.html#id6">Generate speech with executables compiled from C++</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/matcha.html#id7">Generate speech with Python script</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/matcha.html#id8">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tts/pretrained_models/kokoro.html">Kokoro</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/kokoro.html#kokoro-multi-lang-v1-1-chinese-english-103-speakers">kokoro-multi-lang-v1_1 (Chinese + English, 103 speakers)</a></li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/kokoro.html#kokoro-multi-lang-v1-0-chinese-english-53-speakers">kokoro-multi-lang-v1_0 (Chinese + English, 53 speakers)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kokoro.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kokoro.html#map-between-speaker-id-and-speaker-name">Map between speaker ID and speaker name</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kokoro.html#generate-speech-with-executables-compiled-from-c">Generate speech with executables compiled from C++</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kokoro.html#generate-speech-with-python-script">Generate speech with Python script</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kokoro.html#rtf-on-raspberry-pi-4-model-b-rev-1-5">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/kokoro.html#kokoro-en-v0-19-english-11-speakers">kokoro-en-v0_19 (English, 11 speakers)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kokoro.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kokoro.html#id2">Map between speaker ID and speaker name</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kokoro.html#id3">Generate speech with executables compiled from C++</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kokoro.html#id4">Generate speech with Python script</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kokoro.html#id5">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tts/pretrained_models/kitten.html">KittenTTS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/kitten.html#kitten-nano-en-v0-1-fp16">kitten-nano-en-v0_1-fp16</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#huggingface-space">Huggingface space</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#android-tts-engine-apk">Android TTS Engine APK</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#c-api-example">1. C++ API example</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#python-api-example">2. Python API example</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#id1">3. C API example</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#go-api-example">4. Go API example</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#id2">5. C# API example</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#dart-api-example">6. Dart API example</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#swift-api-example">7. Swift API example</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#kotlin-api-example">8. Kotlin API example</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#java-api-example">9. Java API example</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#javascript-api-example-nodejs-webassembly">10. JavaScript API example (nodejs + WebAssembly)</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#javascript-api-example-nodejs-node-addon">11. JavaScript API example (nodejs + node-addon)</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/kitten.html#pascal-api-example">12. Pascal API example</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/kitten.html#kitten-nano-en-v0-2-fp16">kitten-nano-en-v0_2-fp16</a></li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/kitten.html#kitten-mini-en-v0-1-fp16">kitten-mini-en-v0_1-fp16</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tts/pretrained_models/vits.html">vits</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#all-models-in-a-single-table">All models in a single table</a></li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#vits-melo-tts-zh-en-chinese-english-1-speaker">vits-melo-tts-zh_en (Chinese + English, 1 speaker)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#download-the-model">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#generate-speech-with-executables-compiled-from-c">Generate speech with executables compiled from C++</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#generate-speech-with-python-script">Generate speech with Python script</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#rtf-on-raspberry-pi-4-model-b-rev-1-5">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#vits-piper-en-us-glados-english-1-speaker">vits-piper-en_US-glados (English, 1 speaker)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id1">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id2">Generate speech with executables compiled from C++</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id3">Generate speech with Python script</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id4">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#vits-piper-en-us-libritts-r-medium-english-904-speakers">vits-piper-en_US-libritts_r-medium (English, 904 speakers)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id5">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id6">Generate speech with executables compiled from C++</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id7">Generate speech with Python script</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id8">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#ljspeech-english-single-speaker">ljspeech (English, single-speaker)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id9">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id10">Generate speech with executables compiled from C++</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id11">Generate speech with Python script</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id12">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#vctk-english-multi-speaker-109-speakers">VCTK (English, multi-speaker, 109 speakers)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id14">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id15">Generate speech with executables compiled from C++</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id16">Generate speech with Python script</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id17">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#csukuangfj-sherpa-onnx-vits-zh-ll-chinese-5-speakers">csukuangfj/sherpa-onnx-vits-zh-ll (Chinese, 5 speakers)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id18">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#csukuangfj-vits-zh-hf-fanchen-c-chinese-187-speakers">csukuangfj/vits-zh-hf-fanchen-C (Chinese, 187 speakers)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id19">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#csukuangfj-vits-zh-hf-fanchen-wnj-chinese-1-male">csukuangfj/vits-zh-hf-fanchen-wnj (Chinese, 1 male)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id20">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#csukuangfj-vits-zh-hf-theresa-chinese-804-speakers">csukuangfj/vits-zh-hf-theresa (Chinese, 804 speakers)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id21">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#csukuangfj-vits-zh-hf-eula-chinese-804-speakers">csukuangfj/vits-zh-hf-eula (Chinese, 804 speakers)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id22">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#aishell3-chinese-multi-speaker-174-speakers">aishell3 (Chinese, multi-speaker, 174 speakers)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id23">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id24">Generate speech with executables compiled from C++</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id25">Generate speech with Python script</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id26">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tts/pretrained_models/vits.html#en-us-lessac-medium-english-single-speaker">en_US-lessac-medium (English, single-speaker)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id27">Download the model</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id28">Generate speech with executables compiled from C++</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id29">Generate speech with Python script</a></li>
<li class="toctree-l5"><a class="reference internal" href="tts/pretrained_models/vits.html#id30">RTF on Raspberry Pi 4 Model B Rev 1.5</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tts/wasm/index.html">WebAssembly</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tts/wasm/install-emscripten.html">Install Emscripten</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/wasm/build.html">Build</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/wasm/hf-spaces.html">Huggingface Spaces (WebAssembly)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tts/wasm/hf-spaces.html#english-tts">English TTS</a></li>
<li class="toctree-l4"><a class="reference internal" href="tts/wasm/hf-spaces.html#german-tts">German TTS</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tts/piper.html">Piper</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tts/piper.html#install-dependencies">Install dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/piper.html#find-the-pre-trained-model-from-piper">Find the pre-trained model from piper</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/piper.html#download-the-pre-trained-model">Download the pre-trained model</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/piper.html#add-meta-data-to-the-onnx-model">Add meta data to the onnx model</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/piper.html#download-espeak-ng-data">Download espeak-ng-data</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/piper.html#test-your-converted-model">Test your converted model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tts/mms.html">MMS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tts/mms.html#install-dependencies">Install dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/mms.html#download-the-model-file">Download the model file</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/mms.html#download-mms-source-code">Download MMS source code</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/mms.html#convert-the-model">Convert the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/mms.html#use-the-converted-model">Use the converted model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tts/faq.html">Frequently Asked Question (FAQs)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tts/faq.html#is-there-a-colab-notebook">Is there a colab notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/faq.html#how-to-enable-utf-8-on-windows">How to enable UTF-8 on Windows</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/faq.html#how-to-install-sherpa-onnx-for-tts">How to install sherpa-onnx for TTS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tts/faq.html#for-python-users">For Python users</a></li>
<li class="toctree-l4"><a class="reference internal" href="tts/faq.html#build-from-source">Build from source</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tts/faq.html#where-to-get-pre-trained-tts-models">Where to get pre-trained TTS models</a></li>
<li class="toctree-l3"><a class="reference internal" href="tts/faq.html#how-to-handle-oovs">How to handle OOVs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../ncnn/faq.html" class="btn btn-neutral float-left" title="FAQs" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="tutorials/index.html" class="btn btn-neutral float-right" title="Tutorials" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022-2026, sherpa development team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>