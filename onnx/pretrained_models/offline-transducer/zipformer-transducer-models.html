<!-- see https://stackoverflow.com/questions/2454577/sphinx-restructuredtext-show-hide-code-snippets -->
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Zipformer-transducer-based Models &mdash; sherpa 1.3 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/user.define.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Conformer-transducer-based Models" href="conformer-transducer-models.html" />
    <link rel="prev" title="Offline transducer models" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> sherpa
          </a>
              <div class="version">
                1.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pdf.html">Download pdf</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../social-groups.html">Social groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../huggingface/index.html">Run Next-gen Kaldi in your browser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pretrained-models.html">Pre-trained models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../sherpa/index.html">sherpa</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-ncnn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../ncnn/index.html">sherpa-ncnn</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-onnx</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">sherpa-onnx</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/index.html">Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../faqs/index.html">Frequently Asked Question (FAQs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python/index.html">Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c-api/index.html">C API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../java-api/index.html">Java API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../javascript-api/index.html">Javascript API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kotlin-api/index.html">Kotlin API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../swift-api/index.html">Swift API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../go-api/index.html">Go API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../csharp-api/index.html">C# API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pascal-api/index.html">Pascal API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../lazarus/index.html">Lazarus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../wasm/index.html">WebAssembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../android/index.html">Android</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../harmony-os/index.html">HarmonyOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ios/index.html">iOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../flutter/index.html">Flutter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websocket/index.html">WebSocket</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hotwords/index.html">Hotwords (Contextual biasing)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kws/index.html">Keyword spotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../punctuation/index.html">Punctuation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../audio-tagging/index.html">Audio tagging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../spoken-language-identification/index.html">Spoken language identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../vad/index.html">VAD</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">Pre-trained models</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../online-transducer/index.html">Online transducer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../online-paraformer/index.html">Online paraformer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../online-ctc/index.html">Online CTC models</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="index.html">Offline transducer models</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">Zipformer-transducer-based Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="conformer-transducer-models.html">Conformer-transducer-based Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="nemo-transducer-models.html">NeMo transducer-based Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../offline-paraformer/index.html">Offline paraformer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../offline-ctc/index.html">Offline CTC models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../telespeech/index.html">TeleSpeech</a></li>
<li class="toctree-l3"><a class="reference internal" href="../whisper/index.html">Whisper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../wenet/index.html">WeNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../small-online-models.html">Small models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../sense-voice/index.html">SenseVoice</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../moonshine/index.html">Moonshine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sense-voice/index.html">SenseVoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../paraformer/index.html">Paraformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nemo/index.html">NeMo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../FireRedAsr/index.html">FireRedAsr</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Dolphin/index.html">Dolphin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../homophone-replacer/index.html">拼音词组匹配替换</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../speaker-diarization/index.html">Speaker Diarization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../speaker-identification/index.html">Speaker Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../speech-enhancment/index.html">Speech enhancement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../source-separation/index.html">Source separation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rknn/index.html">rknn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ascend/index.html">Ascend NPU (昇腾 NPU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tts/index.html">Text-to-speech (TTS)</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../triton/overview.html">Triton</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">sherpa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">sherpa-onnx</a> &raquo;</li>
          <li><a href="../index.html">Pre-trained models</a> &raquo;</li>
          <li><a href="index.html">Offline transducer models</a> &raquo;</li>
      <li>Zipformer-transducer-based Models</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/k2-fsa/sherpa/blob/master/docs/source/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="zipformer-transducer-based-models">
<span id="sherpa-onnx-offline-zipformer-transducer-models"></span><h1>Zipformer-transducer-based Models<a class="headerlink" href="#zipformer-transducer-based-models" title="Permalink to this heading"></a></h1>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Please refer to <a class="reference internal" href="../../install/index.html#install-sherpa-onnx"><span class="std std-ref">Installation</span></a> to install <cite>sherpa-onnx</cite>
before you read this section.</p>
</div>
<section id="sherpa-onnx-zipformer-vi-2025-04-20-vietnamese">
<h2>sherpa-onnx-zipformer-vi-2025-04-20 (Vietnamese, 越南语)<a class="headerlink" href="#sherpa-onnx-zipformer-vi-2025-04-20-vietnamese" title="Permalink to this heading"></a></h2>
<p>This model is from <a class="reference external" href="https://huggingface.co/zzasdf/viet_iter3_pseudo_label">https://huggingface.co/zzasdf/viet_iter3_pseudo_label</a>, which is
trained on about 70k hours of data.</p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="download-the-model">
<h3>Download the model<a class="headerlink" href="#download-the-model" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-vi-2025-04-20.tar.bz2
tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-zipformer-vi-2025-04-20.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-vi-2025-04-20.tar.bz2
</pre></div>
</div>
<p>You should see something like below after downloading:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ls</span> <span class="o">-</span><span class="n">lh</span> <span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">zipformer</span><span class="o">-</span><span class="n">vi</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">04</span><span class="o">-</span><span class="mi">20</span>

<span class="n">total</span> <span class="mi">259</span><span class="n">M</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="mi">1001</span> <span class="mi">118</span> <span class="mi">265</span><span class="n">K</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">49</span> <span class="n">bpe</span><span class="o">.</span><span class="n">model</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="mi">1001</span> <span class="mi">118</span> <span class="mf">5.0</span><span class="n">M</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">49</span> <span class="n">decoder</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">8.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="mi">1001</span> <span class="mi">118</span> <span class="mi">249</span><span class="n">M</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">49</span> <span class="n">encoder</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">8.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="mi">1001</span> <span class="mi">118</span> <span class="mf">4.0</span><span class="n">M</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">49</span> <span class="n">joiner</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">8.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="mi">1001</span> <span class="mi">118</span>  <span class="mi">149</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">49</span> <span class="n">README</span><span class="o">.</span><span class="n">md</span>
<span class="n">drwxr</span><span class="o">-</span><span class="n">xr</span><span class="o">-</span><span class="n">x</span> <span class="mi">2</span> <span class="mi">1001</span> <span class="mi">118</span> <span class="mf">4.0</span><span class="n">K</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">49</span> <span class="n">test_wavs</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="mi">1001</span> <span class="mi">118</span>  <span class="mi">26</span><span class="n">K</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">49</span> <span class="n">tokens</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
</section>
<section id="decode-wave-files">
<h3>Decode wave files<a class="headerlink" href="#decode-wave-files" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">float32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-vi-2025-04-20/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-vi-2025-04-20/encoder-epoch-12-avg-8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-vi-2025-04-20/decoder-epoch-12-avg-8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-vi-2025-04-20/joiner-epoch-12-avg-8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-vi-2025-04-20/test_wavs/0.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/project/sherpa-onnx/csrc/parse-options.cc:Read:375 sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-vi-2025-04-20/tokens.txt --encoder=./sherpa-onnx-zipformer-vi-2025-04-20/encoder-epoch-12-avg-8.onnx --decoder=./sherpa-onnx-zipformer-vi-2025-04-20/decoder-epoch-12-avg-8.onnx --joiner=./sherpa-onnx-zipformer-vi-2025-04-20/joiner-epoch-12-avg-8.onnx --num-threads=1 ./sherpa-onnx-zipformer-vi-2025-04-20/test_wavs/0.wav

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-vi-2025-04-20/encoder-epoch-12-avg-8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-vi-2025-04-20/decoder-epoch-12-avg-8.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-vi-2025-04-20/joiner-epoch-12-avg-8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-zipformer-vi-2025-04-20/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-vi-2025-04-20/test_wavs/0.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot; RỒI CŨNG HỖ TRỢ CHO LÂU LÂU CŨNG CHO GẠO CHO NÀY KIA&quot;, &quot;timestamps&quot;: [0.00, 0.20, 0.52, 0.76, 1.00, 1.28, 1.52, 1.76, 1.96, 2.28, 2.60, 2.92, 3.28], &quot;tokens&quot;:[&quot; RỒI&quot;, &quot; CŨNG&quot;, &quot; HỖ&quot;, &quot; TRỢ&quot;, &quot; CHO&quot;, &quot; LÂU&quot;, &quot; LÂU&quot;, &quot; CŨNG&quot;, &quot; CHO&quot;, &quot; GẠO&quot;, &quot; CHO&quot;, &quot; NÀY&quot;, &quot; KIA&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.237 s
Real time factor (RTF): 0.237 / 3.740 = 0.063
</pre></div>
</div>
</section>
<section id="speech-recognition-from-a-microphone">
<h3>Speech recognition from a microphone<a class="headerlink" href="#speech-recognition-from-a-microphone" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-vi-2025-04-20/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-vi-2025-04-20/encoder-epoch-12-avg-8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-vi-2025-04-20/decoder-epoch-12-avg-8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-vi-2025-04-20/joiner-epoch-12-avg-8.onnx
</pre></div>
</div>
</section>
<section id="speech-recognition-from-a-microphone-with-vad">
<h3>Speech recognition from a microphone with VAD<a class="headerlink" href="#speech-recognition-from-a-microphone-with-vad" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silero_vad.onnx

./build/bin/sherpa-onnx-vad-microphone-offline-asr<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--silero-vad-model<span class="o">=</span>./silero_vad.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-vi-2025-04-20/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-vi-2025-04-20/encoder-epoch-12-avg-8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-vi-2025-04-20/decoder-epoch-12-avg-8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-vi-2025-04-20/joiner-epoch-12-avg-8.onnx
</pre></div>
</div>
</section>
</section>
<section id="sherpa-onnx-zipformer-vi-int8-2025-04-20-vietnamese">
<h2>sherpa-onnx-zipformer-vi-int8-2025-04-20 (Vietnamese, 越南语)<a class="headerlink" href="#sherpa-onnx-zipformer-vi-int8-2025-04-20-vietnamese" title="Permalink to this heading"></a></h2>
<p>This model is from <a class="reference external" href="https://huggingface.co/zzasdf/viet_iter3_pseudo_label">https://huggingface.co/zzasdf/viet_iter3_pseudo_label</a>, which is
trained on about 70k hours of data.</p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id2">
<h3>Download the model<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-vi-int8-2025-04-20.tar.bz2
tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-zipformer-vi-int8-2025-04-20.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-vi-int8-2025-04-20.tar.bz2
</pre></div>
</div>
<p>You should see something like below after downloading:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ls</span> <span class="o">-</span><span class="n">lh</span> <span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">zipformer</span><span class="o">-</span><span class="n">vi</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">04</span><span class="o">-</span><span class="mi">20</span>

<span class="n">total</span> <span class="mi">74</span><span class="n">M</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="mi">1001</span> <span class="mi">118</span>  <span class="mi">265</span><span class="n">K</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">50</span> <span class="n">bpe</span><span class="o">.</span><span class="n">model</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="mi">1001</span> <span class="mi">118</span>  <span class="mf">5.0</span><span class="n">M</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">50</span> <span class="n">decoder</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">8.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="mi">1001</span> <span class="mi">118</span>   <span class="mi">68</span><span class="n">M</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">50</span> <span class="n">encoder</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">8.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="mi">1001</span> <span class="mi">118</span> <span class="mi">1010</span><span class="n">K</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">50</span> <span class="n">joiner</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">8.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="mi">1001</span> <span class="mi">118</span>   <span class="mi">149</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">50</span> <span class="n">README</span><span class="o">.</span><span class="n">md</span>
<span class="n">drwxr</span><span class="o">-</span><span class="n">xr</span><span class="o">-</span><span class="n">x</span> <span class="mi">2</span> <span class="mi">1001</span> <span class="mi">118</span>  <span class="mf">4.0</span><span class="n">K</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">49</span> <span class="n">test_wavs</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span> <span class="mi">1</span> <span class="mi">1001</span> <span class="mi">118</span>   <span class="mi">26</span><span class="n">K</span> <span class="n">Apr</span> <span class="mi">20</span> <span class="mi">15</span><span class="p">:</span><span class="mi">50</span> <span class="n">tokens</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
</section>
<section id="id3">
<h3>Decode wave files<a class="headerlink" href="#id3" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/encoder-epoch-12-avg-8.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/decoder-epoch-12-avg-8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/joiner-epoch-12-avg-8.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/test_wavs/0.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/project/sherpa-onnx/csrc/parse-options.cc:Read:375 sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-vi-int8-2025-04-20/tokens.txt --encoder=./sherpa-onnx-zipformer-vi-int8-2025-04-20/encoder-epoch-12-avg-8.int8.onnx --decoder=./sherpa-onnx-zipformer-vi-int8-2025-04-20/decoder-epoch-12-avg-8.onnx --joiner=./sherpa-onnx-zipformer-vi-int8-2025-04-20/joiner-epoch-12-avg-8.int8.onnx --num-threads=1 ./sherpa-onnx-zipformer-vi-int8-2025-04-20/test_wavs/0.wav

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-vi-int8-2025-04-20/encoder-epoch-12-avg-8.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-vi-int8-2025-04-20/decoder-epoch-12-avg-8.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-vi-int8-2025-04-20/joiner-epoch-12-avg-8.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-zipformer-vi-int8-2025-04-20/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-vi-int8-2025-04-20/test_wavs/0.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot; RỒI CŨNG HỖ TRỢ CHO LÂU LÂU CŨNG CHO GẠO CHO NÀY KIA&quot;, &quot;timestamps&quot;: [0.00, 0.20, 0.52, 0.76, 1.00, 1.28, 1.52, 1.76, 1.96, 2.28, 2.60, 2.92, 3.28], &quot;tokens&quot;:[&quot; RỒI&quot;, &quot; CŨNG&quot;, &quot; HỖ&quot;, &quot; TRỢ&quot;, &quot; CHO&quot;, &quot; LÂU&quot;, &quot; LÂU&quot;, &quot; CŨNG&quot;, &quot; CHO&quot;, &quot; GẠO&quot;, &quot; CHO&quot;, &quot; NÀY&quot;, &quot; KIA&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.229 s
Real time factor (RTF): 0.229 / 3.740 = 0.061
</pre></div>
</div>
</section>
<section id="id4">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id4" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/encoder-epoch-12-avg-8.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/decoder-epoch-12-avg-8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/joiner-epoch-12-avg-8.int8.onnx
</pre></div>
</div>
</section>
<section id="id5">
<h3>Speech recognition from a microphone with VAD<a class="headerlink" href="#id5" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silero_vad.onnx

./build/bin/sherpa-onnx-vad-microphone-offline-asr<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--silero-vad-model<span class="o">=</span>./silero_vad.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/encoder-epoch-12-avg-8.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/decoder-epoch-12-avg-8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-vi-int8-2025-04-20/joiner-epoch-12-avg-8.int8.onnx
</pre></div>
</div>
</section>
</section>
<section id="sherpa-onnx-zipformer-zh-en-2023-11-22-chinese-english">
<h2>sherpa-onnx-zipformer-zh-en-2023-11-22 (Chinese+English, 中英双语)<a class="headerlink" href="#sherpa-onnx-zipformer-zh-en-2023-11-22-chinese-english" title="Permalink to this heading"></a></h2>
<p>This model is from <a class="reference external" href="https://huggingface.co/zrjin/icefall-asr-zipformer-multi-zh-en-2023-11-22">https://huggingface.co/zrjin/icefall-asr-zipformer-multi-zh-en-2023-11-22</a>.</p>
<p>See <a class="reference external" href="https://github.com/k2-fsa/icefall/pull/1265">https://github.com/k2-fsa/icefall/pull/1265</a> if you want to learn
how the model is trained.</p>
<p>Note that this model uses byte-level BPE.</p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id6">
<h3>Download the model<a class="headerlink" href="#id6" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-zh-en-2023-11-22.tar.bz2
tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-zipformer-zh-en-2023-11-22.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-zh-en-2023-11-22.tar.bz2
</pre></div>
</div>
<p>You should see something like below after downloading:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ls</span> <span class="o">-</span><span class="n">lh</span> <span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">zipformer</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">en</span><span class="o">-</span><span class="mi">2023</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">22</span>
<span class="n">total</span> <span class="mi">710824</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">264</span><span class="n">K</span> <span class="n">Nov</span> <span class="mi">22</span>  <span class="mi">2023</span> <span class="n">bbpe</span><span class="o">.</span><span class="n">model</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mf">4.9</span><span class="n">M</span> <span class="n">Nov</span> <span class="mi">22</span>  <span class="mi">2023</span> <span class="n">decoder</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">34</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">19.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>    <span class="mi">66</span><span class="n">M</span> <span class="n">Nov</span> <span class="mi">22</span>  <span class="mi">2023</span> <span class="n">encoder</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">34</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">19.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">248</span><span class="n">M</span> <span class="n">Nov</span> <span class="mi">22</span>  <span class="mi">2023</span> <span class="n">encoder</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">34</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">19.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mf">1.0</span><span class="n">M</span> <span class="n">Nov</span> <span class="mi">22</span>  <span class="mi">2023</span> <span class="n">joiner</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">34</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">19.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mf">3.9</span><span class="n">M</span> <span class="n">Nov</span> <span class="mi">22</span>  <span class="mi">2023</span> <span class="n">joiner</span><span class="o">-</span><span class="n">epoch</span><span class="o">-</span><span class="mi">34</span><span class="o">-</span><span class="n">avg</span><span class="o">-</span><span class="mf">19.</span><span class="n">onnx</span>
<span class="n">drwxr</span><span class="o">-</span><span class="n">xr</span><span class="o">-</span><span class="n">x</span>  <span class="mi">5</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">160</span><span class="n">B</span> <span class="n">Dec</span> <span class="mi">24</span> <span class="mi">15</span><span class="p">:</span><span class="mi">50</span> <span class="n">test_wavs</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>    <span class="mi">25</span><span class="n">K</span> <span class="n">Dec</span> <span class="mi">24</span> <span class="mi">15</span><span class="p">:</span><span class="mi">49</span> <span class="n">tokens</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
</section>
<section id="id7">
<h3>Decode wave files<a class="headerlink" href="#id7" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="fp32">
<h4>fp32<a class="headerlink" href="#fp32" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/encoder-epoch-34-avg-19.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/decoder-epoch-34-avg-19.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/joiner-epoch-34-avg-19.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-zh-en-2023-11-22/test_wavs/0.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:375 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-zh-en-2023-11-22/tokens.txt --encoder=./sherpa-onnx-zipformer-zh-en-2023-11-22/encoder-epoch-34-avg-19.onnx --decoder=./sherpa-onnx-zipformer-zh-en-2023-11-22/decoder-epoch-34-avg-19.onnx --joiner=./sherpa-onnx-zipformer-zh-en-2023-11-22/joiner-epoch-34-avg-19.onnx --num-threads=1 ./sherpa-onnx-zipformer-zh-en-2023-11-22/test_wavs/0.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-zh-en-2023-11-22/encoder-epoch-34-avg-19.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-zh-en-2023-11-22/decoder-epoch-34-avg-19.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-zh-en-2023-11-22/joiner-epoch-34-avg-19.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-zipformer-zh-en-2023-11-22/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-zh-en-2023-11-22/test_wavs/0.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;SPEND ON 在什么上面花费它不光是时间也可以是金钱&quot;, &quot;timestamps&quot;: [0.00, 0.04, 0.32, 0.48, 0.64, 0.72, 0.88, 1.00, 1.24, 1.36, 1.60, 1.80, 1.96, 2.12, 2.32, 2.44, 2.60, 2.72, 2.80, 2.88, 3.00, 3.20], &quot;tokens&quot;:[&quot;▁SP&quot;, &quot;END&quot;, &quot;▁ON&quot;, &quot;▁ƌŁŎ&quot;, &quot;▁Ƌšġ&quot;, &quot;▁Ƌşĩ&quot;, &quot;▁ƋŞī&quot;, &quot;▁ƐłŇ&quot;, &quot;▁Əīŗ&quot;, &quot;▁ƏŚş&quot;, &quot;▁ƌŔĤ&quot;, &quot;▁ƋŞĮ&quot;, &quot;▁ƌĦĪ&quot;, &quot;▁ƍĻŕ&quot;, &quot;▁ƍĺŜ&quot;, &quot;▁ƐĺŚ&quot;, &quot;▁Ƌşń&quot;, &quot;▁ƌİŕ&quot;, &quot;▁Ƌšŋ&quot;, &quot;▁ƍĻŕ&quot;, &quot;▁ƐĨĴ&quot;, &quot;▁Ɛĵŗ&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.183 s
Real time factor (RTF): 0.183 / 3.380 = 0.054
</pre></div>
</div>
</section>
<section id="int8">
<h4>int8<a class="headerlink" href="#int8" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/encoder-epoch-34-avg-19.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/decoder-epoch-34-avg-19.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/joiner-epoch-34-avg-19.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-zh-en-2023-11-22/test_wavs/0.wav
</pre></div>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:375 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-zh-en-2023-11-22/tokens.txt --encoder=./sherpa-onnx-zipformer-zh-en-2023-11-22/encoder-epoch-34-avg-19.int8.onnx --decoder=./sherpa-onnx-zipformer-zh-en-2023-11-22/decoder-epoch-34-avg-19.onnx --joiner=./sherpa-onnx-zipformer-zh-en-2023-11-22/joiner-epoch-34-avg-19.int8.onnx --num-threads=1 ./sherpa-onnx-zipformer-zh-en-2023-11-22/test_wavs/0.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-zh-en-2023-11-22/encoder-epoch-34-avg-19.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-zh-en-2023-11-22/decoder-epoch-34-avg-19.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-zh-en-2023-11-22/joiner-epoch-34-avg-19.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-zipformer-zh-en-2023-11-22/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-zh-en-2023-11-22/test_wavs/0.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;SPEND ON 在什么上面花费它不光是时间也可以是金钱&quot;, &quot;timestamps&quot;: [0.00, 0.04, 0.32, 0.48, 0.64, 0.72, 0.88, 1.00, 1.24, 1.36, 1.60, 1.80, 1.96, 2.12, 2.32, 2.44, 2.60, 2.72, 2.80, 2.88, 3.00, 3.20], &quot;tokens&quot;:[&quot;▁SP&quot;, &quot;END&quot;, &quot;▁ON&quot;, &quot;▁ƌŁŎ&quot;, &quot;▁Ƌšġ&quot;, &quot;▁Ƌşĩ&quot;, &quot;▁ƋŞī&quot;, &quot;▁ƐłŇ&quot;, &quot;▁Əīŗ&quot;, &quot;▁ƏŚş&quot;, &quot;▁ƌŔĤ&quot;, &quot;▁ƋŞĮ&quot;, &quot;▁ƌĦĪ&quot;, &quot;▁ƍĻŕ&quot;, &quot;▁ƍĺŜ&quot;, &quot;▁ƐĺŚ&quot;, &quot;▁Ƌşń&quot;, &quot;▁ƌİŕ&quot;, &quot;▁Ƌšŋ&quot;, &quot;▁ƍĻŕ&quot;, &quot;▁ƐĨĴ&quot;, &quot;▁Ɛĵŗ&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.162 s
Real time factor (RTF): 0.162 / 3.380 = 0.048
</pre></div>
</div>
</section>
</section>
<section id="id8">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id8" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/encoder-epoch-34-avg-19.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/decoder-epoch-34-avg-19.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/joiner-epoch-34-avg-19.onnx
</pre></div>
</div>
</section>
<section id="id9">
<h3>Speech recognition from a microphone with VAD<a class="headerlink" href="#id9" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silero_vad.onnx

./build/bin/sherpa-onnx-vad-microphone-offline-asr<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--silero-vad-model<span class="o">=</span>./silero_vad.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/encoder-epoch-34-avg-19.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/decoder-epoch-34-avg-19.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-zh-en-2023-11-22/joiner-epoch-34-avg-19.onnx
</pre></div>
</div>
</section>
</section>
<section id="sherpa-onnx-zipformer-ru-2024-09-18-russian">
<h2>sherpa-onnx-zipformer-ru-2024-09-18 (Russian, 俄语)<a class="headerlink" href="#sherpa-onnx-zipformer-ru-2024-09-18-russian" title="Permalink to this heading"></a></h2>
<p>This model is from <a class="reference external" href="https://huggingface.co/alphacep/vosk-model-ru/tree/main">https://huggingface.co/alphacep/vosk-model-ru/tree/main</a>.</p>
<p>You can find the export script at <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx/blob/master/.github/workflows/export-russian-onnx-models.yaml">https://github.com/k2-fsa/sherpa-onnx/blob/master/.github/workflows/export-russian-onnx-models.yaml</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id10">
<h3>Download the model<a class="headerlink" href="#id10" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ru-2024-09-18.tar.bz2
tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-zipformer-ru-2024-09-18.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-ru-2024-09-18.tar.bz2
</pre></div>
</div>
<p>You should see something like below after downloading:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ls</span> <span class="o">-</span><span class="n">lh</span> <span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">zipformer</span><span class="o">-</span><span class="n">ru</span><span class="o">-</span><span class="mi">2024</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">18</span>
<span class="n">total</span> <span class="mi">700352</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">240</span><span class="n">K</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">01</span> <span class="n">bpe</span><span class="o">.</span><span class="n">model</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mf">1.2</span><span class="n">M</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">01</span> <span class="n">decoder</span><span class="o">.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mf">2.0</span><span class="n">M</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">01</span> <span class="n">decoder</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>    <span class="mi">65</span><span class="n">M</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">01</span> <span class="n">encoder</span><span class="o">.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">247</span><span class="n">M</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">01</span> <span class="n">encoder</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">253</span><span class="n">K</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">01</span> <span class="n">joiner</span><span class="o">.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mf">1.0</span><span class="n">M</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">01</span> <span class="n">joiner</span><span class="o">.</span><span class="n">onnx</span>
<span class="n">drwxr</span><span class="o">-</span><span class="n">xr</span><span class="o">-</span><span class="n">x</span>  <span class="mi">4</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">128</span><span class="n">B</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">01</span> <span class="n">test_wavs</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mf">6.2</span><span class="n">K</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">01</span> <span class="n">tokens</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>An updated version can be found at:</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ru-2025-04-20.tar.bz2">sherpa-onnx-zipformer-ru-2025-04-20.tar.bz2</a></p></li>
<li><p><a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ru-int8-2025-04-20.tar.bz2">sherpa-onnx-zipformer-ru-int8-2025-04-20.tar.bz2</a></p></li>
</ul>
</div></blockquote>
</div>
</section>
<section id="id11">
<h3>Decode wave files<a class="headerlink" href="#id11" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id12">
<h4>fp32<a class="headerlink" href="#id12" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/encoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/decoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/joiner.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-ru-2024-09-18/test_wavs/1.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:375 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-ru-2024-09-18/tokens.txt --encoder=./sherpa-onnx-zipformer-ru-2024-09-18/encoder.onnx --decoder=./sherpa-onnx-zipformer-ru-2024-09-18/decoder.onnx --joiner=./sherpa-onnx-zipformer-ru-2024-09-18/joiner.onnx --num-threads=1 ./sherpa-onnx-zipformer-ru-2024-09-18/test_wavs/1.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-ru-2024-09-18/encoder.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-ru-2024-09-18/decoder.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-ru-2024-09-18/joiner.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-zipformer-ru-2024-09-18/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-ru-2024-09-18/test_wavs/1.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot; родион потапыч высчитывал каждый новый вершок углубления и давно определил про себя&quot;, &quot;timestamps&quot;: [0.00, 0.16, 0.28, 0.52, 0.68, 0.84, 0.96, 1.12, 1.44, 1.64, 1.76, 1.92, 2.08, 2.16, 2.36, 2.48, 2.60, 2.80, 2.96, 3.04, 3.20, 3.40, 3.44, 3.56, 3.68, 3.80, 3.88, 4.00, 4.16, 4.20, 4.64, 4.88, 5.08, 5.20, 5.44, 5.64, 5.68, 5.92, 6.32, 6.56], &quot;tokens&quot;:[&quot; ро&quot;, &quot;ди&quot;, &quot;он&quot;, &quot; по&quot;, &quot;та&quot;, &quot;п&quot;, &quot;ы&quot;, &quot;ч&quot;, &quot; вы&quot;, &quot;с&quot;, &quot;чи&quot;, &quot;ты&quot;, &quot;ва&quot;, &quot;л&quot;, &quot; ка&quot;, &quot;жд&quot;, &quot;ый&quot;, &quot; но&quot;, &quot;в&quot;, &quot;ый&quot;, &quot; вер&quot;, &quot;ш&quot;, &quot;о&quot;, &quot;к&quot;, &quot; у&quot;, &quot;г&quot;, &quot;лу&quot;, &quot;б&quot;, &quot;л&quot;, &quot;ения&quot;, &quot; и&quot;, &quot; да&quot;, &quot;в&quot;, &quot;но&quot;, &quot; оп&quot;, &quot;ре&quot;, &quot;дел&quot;, &quot;ил&quot;, &quot; про&quot;, &quot; себя&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.336 s
Real time factor (RTF): 0.336 / 7.080 = 0.047
</pre></div>
</div>
</section>
<section id="id13">
<h4>int8<a class="headerlink" href="#id13" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/encoder.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/decoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/joiner.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-ru-2024-09-18/test_wavs/1.wav
</pre></div>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:375 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-ru-2024-09-18/tokens.txt --encoder=./sherpa-onnx-zipformer-ru-2024-09-18/encoder.int8.onnx --decoder=./sherpa-onnx-zipformer-ru-2024-09-18/decoder.onnx --joiner=./sherpa-onnx-zipformer-ru-2024-09-18/joiner.int8.onnx --num-threads=1 ./sherpa-onnx-zipformer-ru-2024-09-18/test_wavs/1.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-ru-2024-09-18/encoder.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-ru-2024-09-18/decoder.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-ru-2024-09-18/joiner.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-zipformer-ru-2024-09-18/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-ru-2024-09-18/test_wavs/1.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot; родион потапыч высчитывал каждый новый вершок углубления и давно определил про себя&quot;, &quot;timestamps&quot;: [0.00, 0.16, 0.28, 0.52, 0.68, 0.84, 0.96, 1.12, 1.44, 1.64, 1.76, 1.92, 2.08, 2.16, 2.36, 2.52, 2.60, 2.80, 2.96, 3.04, 3.20, 3.40, 3.44, 3.60, 3.68, 3.80, 3.88, 4.00, 4.16, 4.20, 4.68, 4.88, 5.08, 5.20, 5.44, 5.64, 5.68, 5.88, 6.32, 6.56], &quot;tokens&quot;:[&quot; ро&quot;, &quot;ди&quot;, &quot;он&quot;, &quot; по&quot;, &quot;та&quot;, &quot;п&quot;, &quot;ы&quot;, &quot;ч&quot;, &quot; вы&quot;, &quot;с&quot;, &quot;чи&quot;, &quot;ты&quot;, &quot;ва&quot;, &quot;л&quot;, &quot; ка&quot;, &quot;жд&quot;, &quot;ый&quot;, &quot; но&quot;, &quot;в&quot;, &quot;ый&quot;, &quot; вер&quot;, &quot;ш&quot;, &quot;о&quot;, &quot;к&quot;, &quot; у&quot;, &quot;г&quot;, &quot;лу&quot;, &quot;б&quot;, &quot;л&quot;, &quot;ения&quot;, &quot; и&quot;, &quot; да&quot;, &quot;в&quot;, &quot;но&quot;, &quot; оп&quot;, &quot;ре&quot;, &quot;дел&quot;, &quot;ил&quot;, &quot; про&quot;, &quot; себя&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.280 s
Real time factor (RTF): 0.280 / 7.080 = 0.040
</pre></div>
</div>
</section>
</section>
<section id="id14">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id14" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/encoder.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/decoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/joiner.int8.onnx
</pre></div>
</div>
</section>
<section id="id15">
<h3>Speech recognition from a microphone with VAD<a class="headerlink" href="#id15" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silero_vad.onnx

./build/bin/sherpa-onnx-vad-microphone-offline-asr<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--silero-vad-model<span class="o">=</span>./silero_vad.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/encoder.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/decoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-ru-2024-09-18/joiner.int8.onnx
</pre></div>
</div>
</section>
</section>
<section id="sherpa-onnx-small-zipformer-ru-2024-09-18-russian">
<h2>sherpa-onnx-small-zipformer-ru-2024-09-18 (Russian, 俄语)<a class="headerlink" href="#sherpa-onnx-small-zipformer-ru-2024-09-18-russian" title="Permalink to this heading"></a></h2>
<p>This model is from <a class="reference external" href="https://huggingface.co/alphacep/vosk-model-small-ru/tree/main">https://huggingface.co/alphacep/vosk-model-small-ru/tree/main</a>.</p>
<p>You can find the export script at <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx/blob/master/.github/workflows/export-russian-onnx-models.yaml">https://github.com/k2-fsa/sherpa-onnx/blob/master/.github/workflows/export-russian-onnx-models.yaml</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id17">
<h3>Download the model<a class="headerlink" href="#id17" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-small-zipformer-ru-2024-09-18.tar.bz2
tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-small-zipformer-ru-2024-09-18.tar.bz2
rm<span class="w"> </span>sherpa-onnx-small-zipformer-ru-2024-09-18.tar.bz2
</pre></div>
</div>
<p>You should see something like below after downloading:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ls</span> <span class="o">-</span><span class="n">lh</span>  <span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">small</span><span class="o">-</span><span class="n">zipformer</span><span class="o">-</span><span class="n">ru</span><span class="o">-</span><span class="mi">2024</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">18</span><span class="o">/</span>
<span class="n">total</span> <span class="mi">257992</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">240</span><span class="n">K</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">02</span> <span class="n">bpe</span><span class="o">.</span><span class="n">model</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mf">1.2</span><span class="n">M</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">02</span> <span class="n">decoder</span><span class="o">.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mf">2.0</span><span class="n">M</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">02</span> <span class="n">decoder</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>    <span class="mi">24</span><span class="n">M</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">02</span> <span class="n">encoder</span><span class="o">.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>    <span class="mi">86</span><span class="n">M</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">02</span> <span class="n">encoder</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">253</span><span class="n">K</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">02</span> <span class="n">joiner</span><span class="o">.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mf">1.0</span><span class="n">M</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">02</span> <span class="n">joiner</span><span class="o">.</span><span class="n">onnx</span>
<span class="n">drwxr</span><span class="o">-</span><span class="n">xr</span><span class="o">-</span><span class="n">x</span>  <span class="mi">4</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">128</span><span class="n">B</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">02</span> <span class="n">test_wavs</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mf">6.2</span><span class="n">K</span> <span class="n">Sep</span> <span class="mi">18</span> <span class="mi">12</span><span class="p">:</span><span class="mi">02</span> <span class="n">tokens</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
</section>
<section id="id18">
<h3>Decode wave files<a class="headerlink" href="#id18" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id19">
<h4>fp32<a class="headerlink" href="#id19" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/encoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/decoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/joiner.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-small-zipformer-ru-2024-09-18/test_wavs/1.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:375 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-small-zipformer-ru-2024-09-18/tokens.txt --encoder=./sherpa-onnx-small-zipformer-ru-2024-09-18/encoder.onnx --decoder=./sherpa-onnx-small-zipformer-ru-2024-09-18/decoder.onnx --joiner=./sherpa-onnx-small-zipformer-ru-2024-09-18/joiner.onnx --num-threads=1 ./sherpa-onnx-small-zipformer-ru-2024-09-18/test_wavs/1.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-small-zipformer-ru-2024-09-18/encoder.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-small-zipformer-ru-2024-09-18/decoder.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-small-zipformer-ru-2024-09-18/joiner.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-small-zipformer-ru-2024-09-18/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-small-zipformer-ru-2024-09-18/test_wavs/1.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot; родион потапыч высчитывал каждый новый вершок углубления и давно определил про себя&quot;, &quot;timestamps&quot;: [0.00, 0.20, 0.28, 0.48, 0.68, 0.84, 0.92, 1.04, 1.48, 1.64, 1.76, 1.92, 2.08, 2.16, 2.40, 2.52, 2.60, 2.84, 3.00, 3.04, 3.20, 3.40, 3.48, 3.60, 3.68, 3.80, 3.88, 4.00, 4.12, 4.16, 4.72, 4.92, 5.12, 5.20, 5.48, 5.60, 5.68, 5.92, 6.28, 6.48], &quot;tokens&quot;:[&quot; ро&quot;, &quot;ди&quot;, &quot;он&quot;, &quot; по&quot;, &quot;та&quot;, &quot;п&quot;, &quot;ы&quot;, &quot;ч&quot;, &quot; вы&quot;, &quot;с&quot;, &quot;чи&quot;, &quot;ты&quot;, &quot;ва&quot;, &quot;л&quot;, &quot; ка&quot;, &quot;жд&quot;, &quot;ый&quot;, &quot; но&quot;, &quot;в&quot;, &quot;ый&quot;, &quot; вер&quot;, &quot;ш&quot;, &quot;о&quot;, &quot;к&quot;, &quot; у&quot;, &quot;г&quot;, &quot;лу&quot;, &quot;б&quot;, &quot;л&quot;, &quot;ения&quot;, &quot; и&quot;, &quot; да&quot;, &quot;в&quot;, &quot;но&quot;, &quot; оп&quot;, &quot;ре&quot;, &quot;дел&quot;, &quot;ил&quot;, &quot; про&quot;, &quot; себя&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.228 s
Real time factor (RTF): 0.228 / 7.080 = 0.032
</pre></div>
</div>
</section>
<section id="id20">
<h4>int8<a class="headerlink" href="#id20" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/encoder.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/decoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/joiner.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-small-zipformer-ru-2024-09-18/test_wavs/1.wav
</pre></div>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:375 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-small-zipformer-ru-2024-09-18/tokens.txt --encoder=./sherpa-onnx-small-zipformer-ru-2024-09-18/encoder.int8.onnx --decoder=./sherpa-onnx-small-zipformer-ru-2024-09-18/decoder.onnx --joiner=./sherpa-onnx-small-zipformer-ru-2024-09-18/joiner.int8.onnx --num-threads=1 ./sherpa-onnx-small-zipformer-ru-2024-09-18/test_wavs/1.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-small-zipformer-ru-2024-09-18/encoder.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-small-zipformer-ru-2024-09-18/decoder.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-small-zipformer-ru-2024-09-18/joiner.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-small-zipformer-ru-2024-09-18/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-small-zipformer-ru-2024-09-18/test_wavs/1.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot; родион потапыч высчитывал каждый новый вершок углубления и давно определил про себя&quot;, &quot;timestamps&quot;: [0.00, 0.20, 0.28, 0.48, 0.68, 0.84, 0.92, 1.04, 1.48, 1.64, 1.76, 1.92, 2.08, 2.16, 2.40, 2.52, 2.60, 2.84, 3.00, 3.04, 3.20, 3.40, 3.48, 3.60, 3.68, 3.80, 3.88, 4.00, 4.12, 4.16, 4.72, 4.92, 5.12, 5.20, 5.48, 5.60, 5.68, 5.92, 6.28, 6.48], &quot;tokens&quot;:[&quot; ро&quot;, &quot;ди&quot;, &quot;он&quot;, &quot; по&quot;, &quot;та&quot;, &quot;п&quot;, &quot;ы&quot;, &quot;ч&quot;, &quot; вы&quot;, &quot;с&quot;, &quot;чи&quot;, &quot;ты&quot;, &quot;ва&quot;, &quot;л&quot;, &quot; ка&quot;, &quot;жд&quot;, &quot;ый&quot;, &quot; но&quot;, &quot;в&quot;, &quot;ый&quot;, &quot; вер&quot;, &quot;ш&quot;, &quot;о&quot;, &quot;к&quot;, &quot; у&quot;, &quot;г&quot;, &quot;лу&quot;, &quot;б&quot;, &quot;л&quot;, &quot;ения&quot;, &quot; и&quot;, &quot; да&quot;, &quot;в&quot;, &quot;но&quot;, &quot; оп&quot;, &quot;ре&quot;, &quot;дел&quot;, &quot;ил&quot;, &quot; про&quot;, &quot; себя&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.183 s
Real time factor (RTF): 0.183 / 7.080 = 0.026
</pre></div>
</div>
</section>
</section>
<section id="id21">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id21" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/encoder.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/decoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/joiner.int8.onnx
</pre></div>
</div>
</section>
<section id="id22">
<h3>Speech recognition from a microphone with VAD<a class="headerlink" href="#id22" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silero_vad.onnx

./build/bin/sherpa-onnx-vad-microphone-offline-asr<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--silero-vad-model<span class="o">=</span>./silero_vad.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/encoder.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/decoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-small-zipformer-ru-2024-09-18/joiner.int8.onnx
</pre></div>
</div>
</section>
</section>
<section id="sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01-japanese">
<h2>sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01 (Japanese, 日语)<a class="headerlink" href="#sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01-japanese" title="Permalink to this heading"></a></h2>
<p>This model is from <a class="reference external" href="https://github.com/reazon-research/ReazonSpeech">ReazonSpeech</a> and supports only Japanese.
It is trained by 35k hours of data.</p>
<p>The code for training the model can be found at
<a class="reference external" href="https://github.com/k2-fsa/icefall/tree/master/egs/reazonspeech/ASR">https://github.com/k2-fsa/icefall/tree/master/egs/reazonspeech/ASR</a></p>
<p>Paper about the dataset is <a class="reference external" href="https://research.reazon.jp/_static/reazonspeech_nlp2023.pdf">https://research.reazon.jp/_static/reazonspeech_nlp2023.pdf</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>The original onnx model is from</p>
<blockquote>
<div><p><a class="reference external" href="https://huggingface.co/reazon-research/reazonspeech-k2-v2">https://huggingface.co/reazon-research/reazonspeech-k2-v2</a></p>
</div></blockquote>
</div>
<section id="id23">
<h3>Download the model<a class="headerlink" href="#id23" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01.tar.bz2

ls<span class="w"> </span>-lh<span class="w"> </span>sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01
</pre></div>
</div>
<p>You should see the following output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.2K<span class="w"> </span>Aug<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">18</span>:32<span class="w"> </span>README.md
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.8M<span class="w"> </span>Aug<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">18</span>:32<span class="w"> </span>decoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>11M<span class="w"> </span>Aug<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">18</span>:32<span class="w"> </span>decoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>148M<span class="w"> </span>Aug<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">18</span>:32<span class="w"> </span>encoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>565M<span class="w"> </span>Aug<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">18</span>:32<span class="w"> </span>encoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.6M<span class="w"> </span>Aug<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">18</span>:32<span class="w"> </span>joiner-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>10M<span class="w"> </span>Aug<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">18</span>:32<span class="w"> </span>joiner-epoch-99-avg-1.onnx
drwxr-xr-x<span class="w">  </span><span class="m">8</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>256B<span class="w"> </span>Aug<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">18</span>:31<span class="w"> </span>test_wavs
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>45K<span class="w"> </span>Aug<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">18</span>:32<span class="w"> </span>tokens.txt
</pre></div>
</div>
</section>
<section id="id24">
<h3>Decode wave files<a class="headerlink" href="#id24" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id25">
<h4>fp32<a class="headerlink" href="#id25" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/joiner-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/test_wavs/1.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:375 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/tokens.txt --encoder=./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/encoder-epoch-99-avg-1.onnx --decoder=./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/joiner-epoch-99-avg-1.onnx --num-threads=1 ./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/test_wavs/1.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/encoder-epoch-99-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/joiner-epoch-99-avg-1.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/test_wavs/1.wav
{&quot;text&quot;: &quot;気象庁は雪や路面の凍結による交通への影響暴風雪や高波に警戒するとともに雪崩や屋根からの落雪にも十分注意するよう呼びかけています&quot;, &quot;timestamps&quot;: [0.00, 0.48, 0.64, 0.88, 1.24, 1.44, 1.80, 2.00, 2.12, 2.40, 2.56, 2.80, 2.96, 3.04, 3.44, 3.60, 3.88, 4.00, 4.28, 4.40, 4.76, 4.96, 5.20, 5.40, 5.72, 5.92, 6.16, 6.48, 6.64, 6.88, 6.96, 7.08, 7.28, 7.48, 7.64, 8.00, 8.16, 8.36, 8.68, 8.80, 9.04, 9.12, 9.28, 9.64, 9.80, 10.00, 10.16, 10.44, 10.64, 10.92, 11.04, 11.24, 11.36, 11.52, 11.64, 11.88, 11.92, 12.16, 12.28, 12.44, 12.64, 13.16, 13.20], &quot;tokens&quot;:[&quot;気&quot;, &quot;象&quot;, &quot;庁&quot;, &quot;は&quot;, &quot;雪&quot;, &quot;や&quot;, &quot;路&quot;, &quot;面&quot;, &quot;の&quot;, &quot;凍&quot;, &quot;結&quot;, &quot;に&quot;, &quot;よ&quot;, &quot;る&quot;, &quot;交&quot;, &quot;通&quot;, &quot;へ&quot;, &quot;の&quot;, &quot;影&quot;, &quot;響&quot;, &quot;暴&quot;, &quot;風&quot;, &quot;雪&quot;, &quot;や&quot;, &quot;高&quot;, &quot;波&quot;, &quot;に&quot;, &quot;警&quot;, &quot;戒&quot;, &quot;す&quot;, &quot;る&quot;, &quot;と&quot;, &quot;と&quot;, &quot;も&quot;, &quot;に&quot;, &quot;雪&quot;, &quot;崩&quot;, &quot;や&quot;, &quot;屋&quot;, &quot;根&quot;, &quot;か&quot;, &quot;ら&quot;, &quot;の&quot;, &quot;落&quot;, &quot;雪&quot;, &quot;に&quot;, &quot;も&quot;, &quot;十&quot;, &quot;分&quot;, &quot;注&quot;, &quot;意&quot;, &quot;す&quot;, &quot;る&quot;, &quot;よ&quot;, &quot;う&quot;, &quot;呼&quot;, &quot;び&quot;, &quot;か&quot;, &quot;け&quot;, &quot;て&quot;, &quot;い&quot;, &quot;ま&quot;, &quot;す&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 1.101 s
Real time factor (RTF): 1.101 / 13.433 = 0.082
</pre></div>
</div>
</section>
<section id="id26">
<h4>int8<a class="headerlink" href="#id26" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/joiner-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/test_wavs/1.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:375 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/tokens.txt --encoder=./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/encoder-epoch-99-avg-1.int8.onnx --decoder=./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/joiner-epoch-99-avg-1.int8.onnx --num-threads=1 ./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/test_wavs/1.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/encoder-epoch-99-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/joiner-epoch-99-avg-1.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/test_wavs/1.wav
{&quot;text&quot;: &quot;気象庁は雪や路面の凍結による交通への影響暴風雪や高波に警戒するとともに雪崩や屋根からの落雪にも十分注意するよう呼びかけています&quot;, &quot;timestamps&quot;: [0.00, 0.48, 0.64, 0.88, 1.24, 1.44, 1.80, 2.00, 2.12, 2.40, 2.56, 2.80, 2.96, 3.04, 3.44, 3.60, 3.88, 4.00, 4.28, 4.40, 4.76, 4.96, 5.20, 5.40, 5.72, 5.92, 6.20, 6.48, 6.64, 6.88, 6.96, 7.08, 7.28, 7.48, 7.64, 8.00, 8.16, 8.36, 8.68, 8.80, 9.04, 9.12, 9.28, 9.64, 9.80, 10.00, 10.16, 10.44, 10.64, 10.92, 11.04, 11.24, 11.36, 11.52, 11.60, 11.88, 11.92, 12.16, 12.28, 12.44, 12.64, 13.16, 13.20], &quot;tokens&quot;:[&quot;気&quot;, &quot;象&quot;, &quot;庁&quot;, &quot;は&quot;, &quot;雪&quot;, &quot;や&quot;, &quot;路&quot;, &quot;面&quot;, &quot;の&quot;, &quot;凍&quot;, &quot;結&quot;, &quot;に&quot;, &quot;よ&quot;, &quot;る&quot;, &quot;交&quot;, &quot;通&quot;, &quot;へ&quot;, &quot;の&quot;, &quot;影&quot;, &quot;響&quot;, &quot;暴&quot;, &quot;風&quot;, &quot;雪&quot;, &quot;や&quot;, &quot;高&quot;, &quot;波&quot;, &quot;に&quot;, &quot;警&quot;, &quot;戒&quot;, &quot;す&quot;, &quot;る&quot;, &quot;と&quot;, &quot;と&quot;, &quot;も&quot;, &quot;に&quot;, &quot;雪&quot;, &quot;崩&quot;, &quot;や&quot;, &quot;屋&quot;, &quot;根&quot;, &quot;か&quot;, &quot;ら&quot;, &quot;の&quot;, &quot;落&quot;, &quot;雪&quot;, &quot;に&quot;, &quot;も&quot;, &quot;十&quot;, &quot;分&quot;, &quot;注&quot;, &quot;意&quot;, &quot;す&quot;, &quot;る&quot;, &quot;よ&quot;, &quot;う&quot;, &quot;呼&quot;, &quot;び&quot;, &quot;か&quot;, &quot;け&quot;, &quot;て&quot;, &quot;い&quot;, &quot;ま&quot;, &quot;す&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.719 s
Real time factor (RTF): 0.719 / 13.433 = 0.054
</pre></div>
</div>
</section>
</section>
<section id="id27">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id27" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/joiner-epoch-99-avg-1.int8.onnx
</pre></div>
</div>
</section>
<section id="id28">
<h3>Speech recognition from a microphone with VAD<a class="headerlink" href="#id28" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silero_vad.onnx

./build/bin/sherpa-onnx-vad-microphone-offline-asr<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--silero-vad-model<span class="o">=</span>./silero_vad.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01/joiner-epoch-99-avg-1.int8.onnx
</pre></div>
</div>
</section>
</section>
<section id="sherpa-onnx-zipformer-korean-2024-06-24-korean">
<h2>sherpa-onnx-zipformer-korean-2024-06-24 (Korean, 韩语)<a class="headerlink" href="#sherpa-onnx-zipformer-korean-2024-06-24-korean" title="Permalink to this heading"></a></h2>
<p>PyTorch checkpoints of this model can be found at
<a class="reference external" href="https://huggingface.co/johnBamma/icefall-asr-ksponspeech-zipformer-2024-06-24">https://huggingface.co/johnBamma/icefall-asr-ksponspeech-zipformer-2024-06-24</a>.</p>
<p>The training dataset can be found at <a class="reference external" href="https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&amp;topMenu=100&amp;aihubDataSe=realm&amp;dataSetSn=123">https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&amp;topMenu=100&amp;aihubDataSe=realm&amp;dataSetSn=123</a>.</p>
<p>Paper about the dataset is <a class="reference external" href="https://www.mdpi.com/2076-3417/10/19/6936">https://www.mdpi.com/2076-3417/10/19/6936</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id29">
<h3>Download the model<a class="headerlink" href="#id29" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-korean-2024-06-24.tar.bz2

tar<span class="w"> </span>xf<span class="w"> </span>sherpa-onnx-zipformer-korean-2024-06-24.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-korean-2024-06-24.tar.bz2

ls<span class="w"> </span>-lh<span class="w"> </span>sherpa-onnx-zipformer-korean-2024-06-24
</pre></div>
</div>
<p>You should see the following output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>307K<span class="w"> </span>Jun<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">15</span>:33<span class="w"> </span>bpe.model
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.7M<span class="w"> </span>Jun<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">15</span>:33<span class="w"> </span>decoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>11M<span class="w"> </span>Jun<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">15</span>:33<span class="w"> </span>decoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>68M<span class="w"> </span>Jun<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">15</span>:33<span class="w"> </span>encoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>249M<span class="w"> </span>Jun<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">15</span>:33<span class="w"> </span>encoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.5M<span class="w"> </span>Jun<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">15</span>:33<span class="w"> </span>joiner-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">9</span>.8M<span class="w"> </span>Jun<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">15</span>:33<span class="w"> </span>joiner-epoch-99-avg-1.onnx
drwxr-xr-x<span class="w">  </span><span class="m">7</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>224B<span class="w"> </span>Jun<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">15</span>:32<span class="w"> </span>test_wavs
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>59K<span class="w"> </span>Jun<span class="w"> </span><span class="m">24</span><span class="w"> </span><span class="m">15</span>:33<span class="w"> </span>tokens.txt
</pre></div>
</div>
</section>
<section id="id30">
<h3>Decode wave files<a class="headerlink" href="#id30" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id31">
<h4>fp32<a class="headerlink" href="#id31" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-korean-2024-06-24/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-korean-2024-06-24/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-korean-2024-06-24/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-korean-2024-06-24/joiner-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-korean-2024-06-24/test_wavs/0.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:360 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-korean-2024-06-24/tokens.txt --encoder=./sherpa-onnx-zipformer-korean-2024-06-24/encoder-epoch-99-avg-1.onnx --decoder=./sherpa-onnx-zipformer-korean-2024-06-24/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-zipformer-korean-2024-06-24/joiner-epoch-99-avg-1.onnx ./sherpa-onnx-zipformer-korean-2024-06-24/test_wavs/0.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-korean-2024-06-24/encoder-epoch-99-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-korean-2024-06-24/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-korean-2024-06-24/joiner-epoch-99-avg-1.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-zipformer-korean-2024-06-24/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-korean-2024-06-24/test_wavs/0.wav
{&quot;text&quot;: &quot; 그는 괜찮은 척하려고 애쓰는 것 같았다.&quot;, &quot;timestamps&quot;: [0.12, 0.24, 0.56, 1.00, 1.20, 1.32, 2.00, 2.16, 2.32, 2.52, 2.68, 2.80, 3.08, 3.28], &quot;tokens&quot;:[&quot; 그&quot;, &quot;는&quot;, &quot; 괜찮은&quot;, &quot; 척&quot;, &quot;하&quot;, &quot;려고&quot;, &quot; 애&quot;, &quot;쓰&quot;, &quot;는&quot;, &quot; 것&quot;, &quot; 같&quot;, &quot;았&quot;, &quot;다&quot;, &quot;.&quot;], &quot;words&quot;: []}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.119 s
Real time factor (RTF): 0.119 / 3.526 = 0.034
</pre></div>
</div>
</section>
<section id="id32">
<h4>int8<a class="headerlink" href="#id32" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-korean-2024-06-24/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-korean-2024-06-24/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-korean-2024-06-24/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-korean-2024-06-24/joiner-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-korean-2024-06-24/test_wavs/0.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:360 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-korean-2024-06-24/tokens.txt --encoder=./sherpa-onnx-zipformer-korean-2024-06-24/encoder-epoch-99-avg-1.int8.onnx --decoder=./sherpa-onnx-zipformer-korean-2024-06-24/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-zipformer-korean-2024-06-24/joiner-epoch-99-avg-1.int8.onnx ./sherpa-onnx-zipformer-korean-2024-06-24/test_wavs/0.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-korean-2024-06-24/encoder-epoch-99-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-korean-2024-06-24/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-korean-2024-06-24/joiner-epoch-99-avg-1.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-zipformer-korean-2024-06-24/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-korean-2024-06-24/test_wavs/0.wav
{&quot;text&quot;: &quot; 그는 괜찮은 척하려고 애쓰는 것 같았다.&quot;, &quot;timestamps&quot;: [0.12, 0.24, 0.56, 1.00, 1.20, 1.32, 2.00, 2.16, 2.32, 2.52, 2.68, 2.84, 3.08, 3.28], &quot;tokens&quot;:[&quot; 그&quot;, &quot;는&quot;, &quot; 괜찮은&quot;, &quot; 척&quot;, &quot;하&quot;, &quot;려고&quot;, &quot; 애&quot;, &quot;쓰&quot;, &quot;는&quot;, &quot; 것&quot;, &quot; 같&quot;, &quot;았&quot;, &quot;다&quot;, &quot;.&quot;], &quot;words&quot;: []}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.092 s
Real time factor (RTF): 0.092 / 3.526 = 0.026
</pre></div>
</div>
</section>
</section>
<section id="id33">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id33" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-korean-2024-06-24/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-korean-2024-06-24/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-korean-2024-06-24/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-korean-2024-06-24/joiner-epoch-99-avg-1.int8.onnx
</pre></div>
</div>
</section>
</section>
<section id="sherpa-onnx-zipformer-thai-2024-06-20-thai">
<h2>sherpa-onnx-zipformer-thai-2024-06-20 (Thai, 泰语)<a class="headerlink" href="#sherpa-onnx-zipformer-thai-2024-06-20-thai" title="Permalink to this heading"></a></h2>
<p>PyTorch checkpoints of this model can be found at
<a class="reference external" href="https://huggingface.co/yfyeung/icefall-asr-gigaspeech2-th-zipformer-2024-06-20">https://huggingface.co/yfyeung/icefall-asr-gigaspeech2-th-zipformer-2024-06-20</a>.</p>
<p>The training dataset can be found at <a class="reference external" href="https://github.com/SpeechColab/GigaSpeech2">https://github.com/SpeechColab/GigaSpeech2</a>.</p>
<p>The paper about the dataset is <a class="reference external" href="https://arxiv.org/pdf/2406.11546">https://arxiv.org/pdf/2406.11546</a>.</p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id34">
<h3>Download the model<a class="headerlink" href="#id34" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-thai-2024-06-20.tar.bz2

tar<span class="w"> </span>xf<span class="w"> </span>sherpa-onnx-zipformer-thai-2024-06-20.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-thai-2024-06-20.tar.bz2

ls<span class="w"> </span>-lh<span class="w"> </span>sherpa-onnx-zipformer-thai-2024-06-20
</pre></div>
</div>
<p>You should see the following output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>277K<span class="w"> </span>Jun<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="m">16</span>:47<span class="w"> </span>bpe.model
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.2M<span class="w"> </span>Jun<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="m">16</span>:47<span class="w"> </span>decoder-epoch-12-avg-5.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">4</span>.9M<span class="w"> </span>Jun<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="m">16</span>:47<span class="w"> </span>decoder-epoch-12-avg-5.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>148M<span class="w"> </span>Jun<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="m">16</span>:47<span class="w"> </span>encoder-epoch-12-avg-5.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>565M<span class="w"> </span>Jun<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="m">16</span>:47<span class="w"> </span>encoder-epoch-12-avg-5.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.0M<span class="w"> </span>Jun<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="m">16</span>:47<span class="w"> </span>joiner-epoch-12-avg-5.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">3</span>.9M<span class="w"> </span>Jun<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="m">16</span>:47<span class="w"> </span>joiner-epoch-12-avg-5.onnx
drwxr-xr-x<span class="w">  </span><span class="m">6</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>192B<span class="w"> </span>Jun<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="m">16</span>:46<span class="w"> </span>test_wavs
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>38K<span class="w"> </span>Jun<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="m">16</span>:47<span class="w"> </span>tokens.txt
</pre></div>
</div>
</section>
<section id="id35">
<h3>Decode wave files<a class="headerlink" href="#id35" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id36">
<h4>fp32<a class="headerlink" href="#id36" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-thai-2024-06-20/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-thai-2024-06-20/encoder-epoch-12-avg-5.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-thai-2024-06-20/decoder-epoch-12-avg-5.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-thai-2024-06-20/joiner-epoch-12-avg-5.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-thai-2024-06-20/test_wavs/0.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:360 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-thai-2024-06-20/tokens.txt --encoder=./sherpa-onnx-zipformer-thai-2024-06-20/encoder-epoch-12-avg-5.onnx --decoder=./sherpa-onnx-zipformer-thai-2024-06-20/decoder-epoch-12-avg-5.onnx --joiner=./sherpa-onnx-zipformer-thai-2024-06-20/joiner-epoch-12-avg-5.onnx ./sherpa-onnx-zipformer-thai-2024-06-20/test_wavs/0.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-thai-2024-06-20/encoder-epoch-12-avg-5.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-thai-2024-06-20/decoder-epoch-12-avg-5.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-thai-2024-06-20/joiner-epoch-12-avg-5.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-zipformer-thai-2024-06-20/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-thai-2024-06-20/test_wavs/0.wav
{&quot;text&quot;: &quot; แต่เดี๋ยวเกมในนัดต่อไปต้องไปเจอกับทางอินโดนีเซียอะไรอย่างนี้&quot;, &quot;timestamps&quot;: [0.00, 0.08, 0.24, 0.44, 0.64, 0.84, 1.20, 1.84, 2.32, 2.64, 3.12, 3.64, 3.80, 3.88, 4.28], &quot;tokens&quot;:[&quot; แต่&quot;, &quot;เดี๋ยว&quot;, &quot;เกม&quot;, &quot;ใน&quot;, &quot;นัด&quot;, &quot;ต่อไป&quot;, &quot;ต้อง&quot;, &quot;ไปเจอ&quot;, &quot;กับ&quot;, &quot;ทาง&quot;, &quot;อิน&quot;, &quot;โดน&quot;, &quot;ี&quot;, &quot;เซีย&quot;, &quot;อะไรอย่างนี้&quot;], &quot;words&quot;: []}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.181 s
Real time factor (RTF): 0.181 / 4.496 = 0.040
</pre></div>
</div>
</section>
<section id="id37">
<h4>int8<a class="headerlink" href="#id37" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-thai-2024-06-20/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-thai-2024-06-20/encoder-epoch-12-avg-5.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-thai-2024-06-20/decoder-epoch-12-avg-5.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-thai-2024-06-20/joiner-epoch-12-avg-5.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-thai-2024-06-20/test_wavs/0.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:360 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-thai-2024-06-20/tokens.txt --encoder=./sherpa-onnx-zipformer-thai-2024-06-20/encoder-epoch-12-avg-5.int8.onnx --decoder=./sherpa-onnx-zipformer-thai-2024-06-20/decoder-epoch-12-avg-5.onnx --joiner=./sherpa-onnx-zipformer-thai-2024-06-20/joiner-epoch-12-avg-5.int8.onnx ./sherpa-onnx-zipformer-thai-2024-06-20/test_wavs/0.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-thai-2024-06-20/encoder-epoch-12-avg-5.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-thai-2024-06-20/decoder-epoch-12-avg-5.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-thai-2024-06-20/joiner-epoch-12-avg-5.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-zipformer-thai-2024-06-20/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-thai-2024-06-20/test_wavs/0.wav
{&quot;text&quot;: &quot; เดี๋ยวเกมในนัดต่อไปต้องไปเจอกับทางอินโดนีเซียนะครับ&quot;, &quot;timestamps&quot;: [0.00, 0.24, 0.44, 0.64, 0.84, 1.20, 1.84, 2.32, 2.64, 3.12, 3.64, 3.80, 3.88, 4.28], &quot;tokens&quot;:[&quot; เดี๋ยว&quot;, &quot;เกม&quot;, &quot;ใน&quot;, &quot;นัด&quot;, &quot;ต่อไป&quot;, &quot;ต้อง&quot;, &quot;ไปเจอ&quot;, &quot;กับ&quot;, &quot;ทาง&quot;, &quot;อิน&quot;, &quot;โดน&quot;, &quot;ี&quot;, &quot;เซีย&quot;, &quot;นะครับ&quot;], &quot;words&quot;: []}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.150 s
Real time factor (RTF): 0.150 / 4.496 = 0.033
</pre></div>
</div>
</section>
</section>
<section id="id38">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id38" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-thai-2024-06-20/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-thai-2024-06-20/encoder-epoch-12-avg-5.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-thai-2024-06-20/decoder-epoch-12-avg-5.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-thai-2024-06-20/joiner-epoch-12-avg-5.int8.onnx
</pre></div>
</div>
</section>
</section>
<section id="sherpa-onnx-zipformer-cantonese-2024-03-13-cantonese">
<h2>sherpa-onnx-zipformer-cantonese-2024-03-13 (Cantonese, 粤语)<a class="headerlink" href="#sherpa-onnx-zipformer-cantonese-2024-03-13-cantonese" title="Permalink to this heading"></a></h2>
<p>Training code for this model can be found at
<a class="reference external" href="https://github.com/k2-fsa/icefall/pull/1537">https://github.com/k2-fsa/icefall/pull/1537</a>.
It supports only Cantonese since it is trained on a <code class="docutils literal notranslate"><span class="pre">Canatonese</span></code> dataset.
The paper for the dataset can be found at <a class="reference external" href="https://arxiv.org/pdf/2201.02419.pdf">https://arxiv.org/pdf/2201.02419.pdf</a>.</p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id39">
<h3>Download the model<a class="headerlink" href="#id39" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-cantonese-2024-03-13.tar.bz2

tar<span class="w"> </span>xf<span class="w"> </span>sherpa-onnx-zipformer-cantonese-2024-03-13.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-cantonese-2024-03-13.tar.bz2

ls<span class="w"> </span>-lh<span class="w"> </span>sherpa-onnx-zipformer-cantonese-2024-03-13
</pre></div>
</div>
<p>You should see the following output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>total<span class="w"> </span>340M
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1001</span><span class="w"> </span><span class="m">127</span><span class="w"> </span><span class="m">2</span>.7M<span class="w"> </span>Mar<span class="w"> </span><span class="m">13</span><span class="w"> </span><span class="m">09</span>:06<span class="w"> </span>decoder-epoch-45-avg-35.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1001</span><span class="w"> </span><span class="m">127</span><span class="w">  </span>11M<span class="w"> </span>Mar<span class="w"> </span><span class="m">13</span><span class="w"> </span><span class="m">09</span>:06<span class="w"> </span>decoder-epoch-45-avg-35.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1001</span><span class="w"> </span><span class="m">127</span><span class="w">  </span>67M<span class="w"> </span>Mar<span class="w"> </span><span class="m">13</span><span class="w"> </span><span class="m">09</span>:06<span class="w"> </span>encoder-epoch-45-avg-35.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1001</span><span class="w"> </span><span class="m">127</span><span class="w"> </span>248M<span class="w"> </span>Mar<span class="w"> </span><span class="m">13</span><span class="w"> </span><span class="m">09</span>:06<span class="w"> </span>encoder-epoch-45-avg-35.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1001</span><span class="w"> </span><span class="m">127</span><span class="w"> </span><span class="m">2</span>.4M<span class="w"> </span>Mar<span class="w"> </span><span class="m">13</span><span class="w"> </span><span class="m">09</span>:06<span class="w"> </span>joiner-epoch-45-avg-35.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1001</span><span class="w"> </span><span class="m">127</span><span class="w"> </span><span class="m">9</span>.5M<span class="w"> </span>Mar<span class="w"> </span><span class="m">13</span><span class="w"> </span><span class="m">09</span>:06<span class="w"> </span>joiner-epoch-45-avg-35.onnx
drwxr-xr-x<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">1001</span><span class="w"> </span><span class="m">127</span><span class="w"> </span><span class="m">4</span>.0K<span class="w"> </span>Mar<span class="w"> </span><span class="m">13</span><span class="w"> </span><span class="m">09</span>:06<span class="w"> </span>test_wavs
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1001</span><span class="w"> </span><span class="m">127</span><span class="w">  </span>42K<span class="w"> </span>Mar<span class="w"> </span><span class="m">13</span><span class="w"> </span><span class="m">09</span>:06<span class="w"> </span>tokens.txt
</pre></div>
</div>
</section>
<section id="id40">
<h3>Decode wave files<a class="headerlink" href="#id40" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id41">
<h4>fp32<a class="headerlink" href="#id41" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--blank-penalty<span class="o">=</span><span class="m">1</span>.2<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-cantonese-2024-03-13/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-cantonese-2024-03-13/encoder-epoch-45-avg-35.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-cantonese-2024-03-13/decoder-epoch-45-avg-35.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-cantonese-2024-03-13/joiner-epoch-45-avg-35.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-cantonese-2024-03-13/test_wavs/test_wavs_1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-cantonese-2024-03-13/test_wavs/test_wavs_2.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/project/sherpa-onnx/csrc/parse-options.cc:Read:361 sherpa-onnx-offline --blank-penalty=1.2 --tokens=./sherpa-onnx-zipformer-cantonese-2024-03-13/tokens.txt --encoder=./sherpa-onnx-zipformer-cantonese-2024-03-13/encoder-epoch-45-avg-35.onnx --decoder=./sherpa-onnx-zipformer-cantonese-2024-03-13/decoder-epoch-45-avg-35.onnx --joiner=./sherpa-onnx-zipformer-cantonese-2024-03-13/joiner-epoch-45-avg-35.onnx ./sherpa-onnx-zipformer-cantonese-2024-03-13/test_wavs/test_wavs_1.wav ./sherpa-onnx-zipformer-cantonese-2024-03-13/test_wavs/test_wavs_2.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-cantonese-2024-03-13/encoder-epoch-45-avg-35.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-cantonese-2024-03-13/decoder-epoch-45-avg-35.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-cantonese-2024-03-13/joiner-epoch-45-avg-35.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-cantonese-2024-03-13/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=1.2)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-cantonese-2024-03-13/test_wavs/test_wavs_1.wav
{&quot;text&quot;: &quot;啊有冇人知道灣仔活道係點去㗎&quot;, &quot;timestamps&quot;: [0.00, 0.88, 1.28, 1.52, 1.84, 2.08, 2.32, 2.56, 2.80, 3.04, 3.20, 3.44, 3.68, 3.92], &quot;tokens&quot;:[&quot;啊&quot;, &quot;有&quot;, &quot;冇&quot;, &quot;人&quot;, &quot;知&quot;, &quot;道&quot;, &quot;灣&quot;, &quot;仔&quot;, &quot;活&quot;, &quot;道&quot;, &quot;係&quot;, &quot;點&quot;, &quot;去&quot;, &quot;㗎&quot;]}
----
./sherpa-onnx-zipformer-cantonese-2024-03-13/test_wavs/test_wavs_2.wav
{&quot;text&quot;: &quot;我喺黃大仙九龍塘聯合到當失路啊&quot;, &quot;timestamps&quot;: [0.00, 0.64, 0.88, 1.12, 1.28, 1.60, 1.80, 2.16, 2.36, 2.56, 2.88, 3.08, 3.32, 3.44, 3.60], &quot;tokens&quot;:[&quot;我&quot;, &quot;喺&quot;, &quot;黃&quot;, &quot;大&quot;, &quot;仙&quot;, &quot;九&quot;, &quot;龍&quot;, &quot;塘&quot;, &quot;聯&quot;, &quot;合&quot;, &quot;到&quot;, &quot;當&quot;, &quot;失&quot;, &quot;路&quot;, &quot;啊&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.349 s
Real time factor (RTF): 1.349 / 10.320 = 0.131
</pre></div>
</div>
</section>
<section id="id42">
<h4>int8<a class="headerlink" href="#id42" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--blank-penalty<span class="o">=</span><span class="m">1</span>.2<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-cantonese-2024-03-13/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-cantonese-2024-03-13/encoder-epoch-45-avg-35.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-cantonese-2024-03-13/decoder-epoch-45-avg-35.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-cantonese-2024-03-13/joiner-epoch-45-avg-35.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-cantonese-2024-03-13/test_wavs/test_wavs_1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-cantonese-2024-03-13/test_wavs/test_wavs_2.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/project/sherpa-onnx/csrc/parse-options.cc:Read:361 sherpa-onnx-offline --blank-penalty=1.2 --tokens=./sherpa-onnx-zipformer-cantonese-2024-03-13/tokens.txt --encoder=./sherpa-onnx-zipformer-cantonese-2024-03-13/encoder-epoch-45-avg-35.int8.onnx --decoder=./sherpa-onnx-zipformer-cantonese-2024-03-13/decoder-epoch-45-avg-35.onnx --joiner=./sherpa-onnx-zipformer-cantonese-2024-03-13/joiner-epoch-45-avg-35.int8.onnx ./sherpa-onnx-zipformer-cantonese-2024-03-13/test_wavs/test_wavs_1.wav ./sherpa-onnx-zipformer-cantonese-2024-03-13/test_wavs/test_wavs_2.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-cantonese-2024-03-13/encoder-epoch-45-avg-35.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-cantonese-2024-03-13/decoder-epoch-45-avg-35.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-cantonese-2024-03-13/joiner-epoch-45-avg-35.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-cantonese-2024-03-13/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=1.2)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-cantonese-2024-03-13/test_wavs/test_wavs_1.wav
{&quot;text&quot;: &quot;啊有冇人知道灣仔活道係點去㗎&quot;, &quot;timestamps&quot;: [0.00, 0.88, 1.28, 1.52, 1.84, 2.08, 2.32, 2.56, 2.80, 3.04, 3.20, 3.44, 3.68, 3.92], &quot;tokens&quot;:[&quot;啊&quot;, &quot;有&quot;, &quot;冇&quot;, &quot;人&quot;, &quot;知&quot;, &quot;道&quot;, &quot;灣&quot;, &quot;仔&quot;, &quot;活&quot;, &quot;道&quot;, &quot;係&quot;, &quot;點&quot;, &quot;去&quot;, &quot;㗎&quot;]}
----
./sherpa-onnx-zipformer-cantonese-2024-03-13/test_wavs/test_wavs_2.wav
{&quot;text&quot;: &quot;我喺黃大仙九龍塘聯合到當失路啊&quot;, &quot;timestamps&quot;: [0.00, 0.64, 0.88, 1.12, 1.28, 1.60, 1.80, 2.16, 2.36, 2.56, 2.88, 3.08, 3.32, 3.44, 3.60], &quot;tokens&quot;:[&quot;我&quot;, &quot;喺&quot;, &quot;黃&quot;, &quot;大&quot;, &quot;仙&quot;, &quot;九&quot;, &quot;龍&quot;, &quot;塘&quot;, &quot;聯&quot;, &quot;合&quot;, &quot;到&quot;, &quot;當&quot;, &quot;失&quot;, &quot;路&quot;, &quot;啊&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.907 s
Real time factor (RTF): 0.907 / 10.320 = 0.088
</pre></div>
</div>
</section>
</section>
<section id="id43">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id43" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-cantonese-2024-03-13/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-cantonese-2024-03-13/encoder-epoch-45-avg-35.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-cantonese-2024-03-13/decoder-epoch-45-avg-35.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-cantonese-2024-03-13/joiner-epoch-45-avg-35.int8.onnx
</pre></div>
</div>
</section>
</section>
<section id="sherpa-onnx-zipformer-gigaspeech-2023-12-12-english">
<h2>sherpa-onnx-zipformer-gigaspeech-2023-12-12 (English)<a class="headerlink" href="#sherpa-onnx-zipformer-gigaspeech-2023-12-12-english" title="Permalink to this heading"></a></h2>
<p>Training code for this model is <a class="reference external" href="https://github.com/k2-fsa/icefall/pull/1254">https://github.com/k2-fsa/icefall/pull/1254</a>.
It supports only English since it is trained on the <a class="reference external" href="https://github.com/SpeechColab/GigaSpeech">GigaSpeech</a> dataset.</p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id44">
<h3>Download the model<a class="headerlink" href="#id44" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-gigaspeech-2023-12-12.tar.bz2

tar<span class="w"> </span>xf<span class="w"> </span>sherpa-onnx-zipformer-gigaspeech-2023-12-12.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-gigaspeech-2023-12-12.tar.bz2
ls<span class="w"> </span>-lh<span class="w"> </span>sherpa-onnx-zipformer-gigaspeech-2023-12-12
</pre></div>
</div>
<p>You should see the following output:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>sherpa-onnx-zipformer-gigaspeech-2023-12-12
total<span class="w"> </span><span class="m">656184</span>
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>28B<span class="w"> </span>Dec<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">19</span>:00<span class="w"> </span>README.md
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>239K<span class="w"> </span>Dec<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">19</span>:00<span class="w"> </span>bpe.model
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>528K<span class="w"> </span>Dec<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">19</span>:00<span class="w"> </span>decoder-epoch-30-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.0M<span class="w"> </span>Dec<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">19</span>:00<span class="w"> </span>decoder-epoch-30-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>68M<span class="w"> </span>Dec<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">19</span>:00<span class="w"> </span>encoder-epoch-30-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>249M<span class="w"> </span>Dec<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">19</span>:00<span class="w"> </span>encoder-epoch-30-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>253K<span class="w"> </span>Dec<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">19</span>:00<span class="w"> </span>joiner-epoch-30-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.0M<span class="w"> </span>Dec<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">19</span>:00<span class="w"> </span>joiner-epoch-30-avg-1.onnx
drwxr-xr-x<span class="w">  </span><span class="m">5</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>160B<span class="w"> </span>Dec<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">19</span>:00<span class="w"> </span>test_wavs
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">4</span>.9K<span class="w"> </span>Dec<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">19</span>:00<span class="w"> </span>tokens.txt
</pre></div>
</div>
</section>
<section id="id45">
<h3>Decode wave files<a class="headerlink" href="#id45" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id46">
<h4>fp32<a class="headerlink" href="#id46" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/encoder-epoch-30-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/decoder-epoch-30-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/joiner-epoch-30-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1089-134686-0001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1221-135766-0001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1221-135766-0002.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-gigaspeech-2023-12-12/tokens.txt --encoder=./sherpa-onnx-zipformer-gigaspeech-2023-12-12/encoder-epoch-30-avg-1.onnx --decoder=./sherpa-onnx-zipformer-gigaspeech-2023-12-12/decoder-epoch-30-avg-1.onnx --joiner=./sherpa-onnx-zipformer-gigaspeech-2023-12-12/joiner-epoch-30-avg-1.onnx ./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1089-134686-0001.wav ./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1221-135766-0001.wav ./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1221-135766-0002.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-gigaspeech-2023-12-12/encoder-epoch-30-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-gigaspeech-2023-12-12/decoder-epoch-30-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-gigaspeech-2023-12-12/joiner-epoch-30-avg-1.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-gigaspeech-2023-12-12/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1089-134686-0001.wav
{&quot;text&quot;: &quot; AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS&quot;, &quot;timestamps&quot;: [0.00, 0.36, 0.52, 0.68, 0.96, 1.00, 1.08, 1.28, 1.40, 1.48, 1.60, 1.76, 1.80, 1.88, 1.92, 2.00, 2.20, 2.32, 2.36, 2.48, 2.60, 2.80, 2.84, 2.92, 3.12, 3.32, 3.56, 3.76, 4.04, 4.20, 4.32, 4.40, 4.56, 4.80, 4.92, 5.08, 5.36, 5.48, 5.64, 5.72, 5.88, 6.04, 6.24], &quot;tokens&quot;:[&quot; AFTER&quot;, &quot; E&quot;, &quot;AR&quot;, &quot;LY&quot;, &quot; &quot;, &quot;N&quot;, &quot;IGHT&quot;, &quot;F&quot;, &quot;AL&quot;, &quot;L&quot;, &quot; THE&quot;, &quot; &quot;, &quot;Y&quot;, &quot;E&quot;, &quot;LL&quot;, &quot;OW&quot;, &quot; LA&quot;, &quot;M&quot;, &quot;P&quot;, &quot;S&quot;, &quot; WOULD&quot;, &quot; &quot;, &quot;L&quot;, &quot;IGHT&quot;, &quot; UP&quot;, &quot; HERE&quot;, &quot; AND&quot;, &quot; THERE&quot;, &quot; THE&quot;, &quot; S&quot;, &quot;QU&quot;, &quot;AL&quot;, &quot;ID&quot;, &quot; QU&quot;, &quot;AR&quot;, &quot;TER&quot;, &quot; OF&quot;, &quot; THE&quot;, &quot; B&quot;, &quot;RO&quot;, &quot;TH&quot;, &quot;EL&quot;, &quot;S&quot;]}
----
./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1221-135766-0001.wav
{&quot;text&quot;: &quot; GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN&quot;, &quot;timestamps&quot;: [0.00, 0.16, 0.40, 0.68, 0.84, 0.96, 1.04, 1.12, 1.32, 1.52, 1.68, 1.76, 2.00, 2.12, 2.28, 2.40, 2.64, 2.92, 3.20, 3.32, 3.52, 3.64, 3.76, 3.96, 4.12, 4.36, 4.52, 4.72, 4.92, 5.16, 5.40, 5.64, 5.76, 5.88, 6.12, 6.28, 6.48, 6.84, 7.08, 7.32, 7.60, 7.92, 8.12, 8.24, 8.36, 8.48, 8.64, 8.76, 8.88, 9.12, 9.32, 9.48, 9.56, 9.60, 9.76, 10.00, 10.12, 10.20, 10.44, 10.68, 10.80, 11.00, 11.20, 11.36, 11.52, 11.76, 12.00, 12.12, 12.24, 12.28, 12.52, 12.72, 12.84, 12.96, 13.04, 13.24, 13.40, 13.64, 13.76, 14.00, 14.08, 14.24, 14.52, 14.68, 14.80, 15.00, 15.04, 15.28, 15.52, 15.76, 16.00, 16.12, 16.20, 16.32], &quot;tokens&quot;:[&quot; GO&quot;, &quot;D&quot;, &quot; AS&quot;, &quot; A&quot;, &quot; DI&quot;, &quot;RE&quot;, &quot;C&quot;, &quot;T&quot;, &quot; CON&quot;, &quot;SE&quot;, &quot;QU&quot;, &quot;ENCE&quot;, &quot; OF&quot;, &quot; THE&quot;, &quot; S&quot;, &quot;IN&quot;, &quot; WHICH&quot;, &quot; MAN&quot;, &quot; TH&quot;, &quot;US&quot;, &quot; P&quot;, &quot;UN&quot;, &quot;ISH&quot;, &quot;ED&quot;, &quot; HAD&quot;, &quot; GIVE&quot;, &quot;N&quot;, &quot; HER&quot;, &quot; A&quot;, &quot; LOVE&quot;, &quot;LY&quot;, &quot; CHI&quot;, &quot;L&quot;, &quot;D&quot;, &quot; WHO&quot;, &quot;SE&quot;, &quot; PLACE&quot;, &quot; WAS&quot;, &quot; ON&quot;, &quot; THAT&quot;, &quot; SAME&quot;, &quot; DIS&quot;, &quot;HO&quot;, &quot;N&quot;, &quot;OR&quot;, &quot;ED&quot;, &quot; BO&quot;, &quot;S&quot;, &quot;OM&quot;, &quot; TO&quot;, &quot; CON&quot;, &quot;NE&quot;, &quot;C&quot;, &quot;T&quot;, &quot; HER&quot;, &quot; PA&quot;, &quot;R&quot;, &quot;ENT&quot;, &quot; FOR&quot;, &quot; E&quot;, &quot;VER&quot;, &quot; WITH&quot;, &quot; THE&quot;, &quot; RA&quot;, &quot;CE&quot;, &quot; AND&quot;, &quot; DE&quot;, &quot;S&quot;, &quot;C&quot;, &quot;ENT&quot;, &quot; OF&quot;, &quot; MO&quot;, &quot;R&quot;, &quot;T&quot;, &quot;AL&quot;, &quot;S&quot;, &quot; AND&quot;, &quot; TO&quot;, &quot; BE&quot;, &quot; F&quot;, &quot;IN&quot;, &quot;ALLY&quot;, &quot; A&quot;, &quot; B&quot;, &quot;LES&quot;, &quot;S&quot;, &quot;ED&quot;, &quot; SO&quot;, &quot;UL&quot;, &quot; IN&quot;, &quot; HE&quot;, &quot;A&quot;, &quot;VE&quot;, &quot;N&quot;]}
----
./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1221-135766-0002.wav
{&quot;text&quot;: &quot; YET THESE THOUGHTS AFFECTED HESTER PRYNE LESS WITH HOPE THAN APPREHENSION&quot;, &quot;timestamps&quot;: [0.00, 0.04, 0.12, 0.40, 0.68, 0.88, 0.96, 1.12, 1.20, 1.32, 1.44, 1.48, 1.64, 1.76, 1.88, 2.04, 2.16, 2.28, 2.52, 2.68, 2.72, 2.88, 3.12, 3.28, 3.52, 3.80, 4.00, 4.16, 4.24, 4.40, 4.48], &quot;tokens&quot;:[&quot; &quot;, &quot;Y&quot;, &quot;ET&quot;, &quot; THESE&quot;, &quot; THOUGH&quot;, &quot;T&quot;, &quot;S&quot;, &quot; A&quot;, &quot;FF&quot;, &quot;E&quot;, &quot;C&quot;, &quot;TED&quot;, &quot; HE&quot;, &quot;S&quot;, &quot;TER&quot;, &quot; P&quot;, &quot;RY&quot;, &quot;NE&quot;, &quot; LE&quot;, &quot;S&quot;, &quot;S&quot;, &quot; WITH&quot;, &quot; HO&quot;, &quot;PE&quot;, &quot; THAN&quot;, &quot; APP&quot;, &quot;RE&quot;, &quot;HE&quot;, &quot;N&quot;, &quot;S&quot;, &quot;ION&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.407 s
Real time factor (RTF): 1.407 / 28.165 = 0.050
</pre></div>
</div>
</section>
<section id="id47">
<h4>int8<a class="headerlink" href="#id47" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/encoder-epoch-30-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/decoder-epoch-30-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/joiner-epoch-30-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1089-134686-0001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1221-135766-0001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1221-135766-0002.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-gigaspeech-2023-12-12/tokens.txt --encoder=./sherpa-onnx-zipformer-gigaspeech-2023-12-12/encoder-epoch-30-avg-1.int8.onnx --decoder=./sherpa-onnx-zipformer-gigaspeech-2023-12-12/decoder-epoch-30-avg-1.onnx --joiner=./sherpa-onnx-zipformer-gigaspeech-2023-12-12/joiner-epoch-30-avg-1.int8.onnx ./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1089-134686-0001.wav ./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1221-135766-0001.wav ./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1221-135766-0002.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-gigaspeech-2023-12-12/encoder-epoch-30-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-gigaspeech-2023-12-12/decoder-epoch-30-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-gigaspeech-2023-12-12/joiner-epoch-30-avg-1.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-gigaspeech-2023-12-12/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5)
Creating recognizer ...
Started
Done!

./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1089-134686-0001.wav
{&quot;text&quot;: &quot; AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS&quot;, &quot;timestamps&quot;: [0.00, 0.36, 0.52, 0.68, 0.96, 1.00, 1.08, 1.28, 1.40, 1.48, 1.60, 1.76, 1.80, 1.88, 1.92, 2.00, 2.20, 2.32, 2.36, 2.48, 2.60, 2.80, 2.84, 2.92, 3.12, 3.32, 3.56, 3.76, 4.04, 4.24, 4.32, 4.40, 4.56, 4.80, 4.92, 5.08, 5.36, 5.48, 5.64, 5.72, 5.88, 6.04, 6.24], &quot;tokens&quot;:[&quot; AFTER&quot;, &quot; E&quot;, &quot;AR&quot;, &quot;LY&quot;, &quot; &quot;, &quot;N&quot;, &quot;IGHT&quot;, &quot;F&quot;, &quot;AL&quot;, &quot;L&quot;, &quot; THE&quot;, &quot; &quot;, &quot;Y&quot;, &quot;E&quot;, &quot;LL&quot;, &quot;OW&quot;, &quot; LA&quot;, &quot;M&quot;, &quot;P&quot;, &quot;S&quot;, &quot; WOULD&quot;, &quot; &quot;, &quot;L&quot;, &quot;IGHT&quot;, &quot; UP&quot;, &quot; HERE&quot;, &quot; AND&quot;, &quot; THERE&quot;, &quot; THE&quot;, &quot; S&quot;, &quot;QU&quot;, &quot;AL&quot;, &quot;ID&quot;, &quot; QU&quot;, &quot;AR&quot;, &quot;TER&quot;, &quot; OF&quot;, &quot; THE&quot;, &quot; B&quot;, &quot;RO&quot;, &quot;TH&quot;, &quot;EL&quot;, &quot;S&quot;]}
----
./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1221-135766-0001.wav
{&quot;text&quot;: &quot; GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN&quot;, &quot;timestamps&quot;: [0.00, 0.16, 0.40, 0.68, 0.84, 0.96, 1.08, 1.12, 1.32, 1.52, 1.68, 1.76, 2.00, 2.12, 2.28, 2.40, 2.64, 2.92, 3.20, 3.32, 3.52, 3.64, 3.76, 3.96, 4.12, 4.36, 4.52, 4.72, 4.92, 5.16, 5.40, 5.64, 5.76, 5.88, 6.12, 6.28, 6.52, 6.84, 7.08, 7.32, 7.60, 7.92, 8.12, 8.24, 8.36, 8.48, 8.64, 8.76, 8.88, 9.12, 9.32, 9.48, 9.56, 9.60, 9.76, 10.00, 10.12, 10.20, 10.44, 10.68, 10.80, 11.00, 11.20, 11.36, 11.52, 11.76, 12.00, 12.12, 12.24, 12.28, 12.52, 12.72, 12.84, 12.96, 13.04, 13.24, 13.44, 13.64, 13.76, 14.00, 14.08, 14.24, 14.52, 14.68, 14.80, 15.00, 15.04, 15.28, 15.48, 15.76, 16.00, 16.12, 16.16, 16.32], &quot;tokens&quot;:[&quot; GO&quot;, &quot;D&quot;, &quot; AS&quot;, &quot; A&quot;, &quot; DI&quot;, &quot;RE&quot;, &quot;C&quot;, &quot;T&quot;, &quot; CON&quot;, &quot;SE&quot;, &quot;QU&quot;, &quot;ENCE&quot;, &quot; OF&quot;, &quot; THE&quot;, &quot; S&quot;, &quot;IN&quot;, &quot; WHICH&quot;, &quot; MAN&quot;, &quot; TH&quot;, &quot;US&quot;, &quot; P&quot;, &quot;UN&quot;, &quot;ISH&quot;, &quot;ED&quot;, &quot; HAD&quot;, &quot; GIVE&quot;, &quot;N&quot;, &quot; HER&quot;, &quot; A&quot;, &quot; LOVE&quot;, &quot;LY&quot;, &quot; CHI&quot;, &quot;L&quot;, &quot;D&quot;, &quot; WHO&quot;, &quot;SE&quot;, &quot; PLACE&quot;, &quot; WAS&quot;, &quot; ON&quot;, &quot; THAT&quot;, &quot; SAME&quot;, &quot; DIS&quot;, &quot;HO&quot;, &quot;N&quot;, &quot;OR&quot;, &quot;ED&quot;, &quot; BO&quot;, &quot;S&quot;, &quot;OM&quot;, &quot; TO&quot;, &quot; CON&quot;, &quot;NE&quot;, &quot;C&quot;, &quot;T&quot;, &quot; HER&quot;, &quot; PA&quot;, &quot;R&quot;, &quot;ENT&quot;, &quot; FOR&quot;, &quot; E&quot;, &quot;VER&quot;, &quot; WITH&quot;, &quot; THE&quot;, &quot; RA&quot;, &quot;CE&quot;, &quot; AND&quot;, &quot; DE&quot;, &quot;S&quot;, &quot;C&quot;, &quot;ENT&quot;, &quot; OF&quot;, &quot; MO&quot;, &quot;R&quot;, &quot;T&quot;, &quot;AL&quot;, &quot;S&quot;, &quot; AND&quot;, &quot; TO&quot;, &quot; BE&quot;, &quot; F&quot;, &quot;IN&quot;, &quot;ALLY&quot;, &quot; A&quot;, &quot; B&quot;, &quot;LES&quot;, &quot;S&quot;, &quot;ED&quot;, &quot; SO&quot;, &quot;UL&quot;, &quot; IN&quot;, &quot; HE&quot;, &quot;A&quot;, &quot;VE&quot;, &quot;N&quot;]}
----
./sherpa-onnx-zipformer-gigaspeech-2023-12-12/test_wavs/1221-135766-0002.wav
{&quot;text&quot;: &quot; YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION&quot;, &quot;timestamps&quot;: [0.00, 0.04, 0.12, 0.40, 0.68, 0.88, 0.96, 1.12, 1.24, 1.32, 1.44, 1.48, 1.64, 1.76, 1.88, 2.04, 2.16, 2.28, 2.32, 2.52, 2.68, 2.72, 2.88, 3.12, 3.32, 3.52, 3.80, 4.00, 4.16, 4.24, 4.40, 4.48], &quot;tokens&quot;:[&quot; &quot;, &quot;Y&quot;, &quot;ET&quot;, &quot; THESE&quot;, &quot; THOUGH&quot;, &quot;T&quot;, &quot;S&quot;, &quot; A&quot;, &quot;FF&quot;, &quot;E&quot;, &quot;C&quot;, &quot;TED&quot;, &quot; HE&quot;, &quot;S&quot;, &quot;TER&quot;, &quot; P&quot;, &quot;RY&quot;, &quot;N&quot;, &quot;NE&quot;, &quot; LE&quot;, &quot;S&quot;, &quot;S&quot;, &quot; WITH&quot;, &quot; HO&quot;, &quot;PE&quot;, &quot; THAN&quot;, &quot; APP&quot;, &quot;RE&quot;, &quot;HE&quot;, &quot;N&quot;, &quot;S&quot;, &quot;ION&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.101 s
Real time factor (RTF): 1.101 / 28.165 = 0.039
</pre></div>
</div>
</section>
</section>
<section id="id48">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id48" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/encoder-epoch-30-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/decoder-epoch-30-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/joiner-epoch-30-avg-1.int8.onnx
</pre></div>
</div>
</section>
<section id="id49">
<h3>Speech recognition from a microphone with VAD<a class="headerlink" href="#id49" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silero_vad.onnx

./build/bin/sherpa-onnx-vad-microphone-offline-asr<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--silero-vad-model<span class="o">=</span>./silero_vad.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/encoder-epoch-30-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/decoder-epoch-30-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-gigaspeech-2023-12-12/joiner-epoch-30-avg-1.int8.onnx
</pre></div>
</div>
</section>
</section>
<section id="zrjin-sherpa-onnx-zipformer-multi-zh-hans-2023-9-2-chinese">
<h2>zrjin/sherpa-onnx-zipformer-multi-zh-hans-2023-9-2 (Chinese)<a class="headerlink" href="#zrjin-sherpa-onnx-zipformer-multi-zh-hans-2023-9-2-chinese" title="Permalink to this heading"></a></h2>
<p>This model is from</p>
<p><a class="reference external" href="https://huggingface.co/zrjin/sherpa-onnx-zipformer-multi-zh-hans-2023-9-2">https://huggingface.co/zrjin/sherpa-onnx-zipformer-multi-zh-hans-2023-9-2</a></p>
<p>which supports Chinese as it is trained on whatever datasets involved in the <a class="reference external" href="https://github.com/k2-fsa/icefall/tree/master/egs/multi_zh-hans/ASR/">multi-zh_hans</a> recipe.</p>
<p>If you are interested in how the model is trained, please refer to
<a class="reference external" href="https://github.com/k2-fsa/icefall/pull/1238">https://github.com/k2-fsa/icefall/pull/1238</a>.</p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id50">
<h3>Download the model<a class="headerlink" href="#id50" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-multi-zh-hans-2023-9-2.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-zipformer-multi-zh-hans-2023-9-2.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-multi-zh-hans-2023-9-2.tar.bz2
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sherpa-onnx-zipformer-multi-zh-hans-2023-9-2<span class="w"> </span>zengruijin$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.onnx
-rw-rw-r--@<span class="w"> </span><span class="m">1</span><span class="w"> </span>zengruijin<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.2M<span class="w"> </span>Sep<span class="w"> </span><span class="m">18</span><span class="w"> </span><span class="m">07</span>:04<span class="w"> </span>decoder-epoch-20-avg-1.int8.onnx
-rw-rw-r--@<span class="w"> </span><span class="m">1</span><span class="w"> </span>zengruijin<span class="w">  </span>staff<span class="w">   </span><span class="m">4</span>.9M<span class="w"> </span>Sep<span class="w"> </span><span class="m">18</span><span class="w"> </span><span class="m">07</span>:04<span class="w"> </span>decoder-epoch-20-avg-1.onnx
-rw-rw-r--@<span class="w"> </span><span class="m">1</span><span class="w"> </span>zengruijin<span class="w">  </span>staff<span class="w">    </span>66M<span class="w"> </span>Sep<span class="w"> </span><span class="m">18</span><span class="w"> </span><span class="m">07</span>:04<span class="w"> </span>encoder-epoch-20-avg-1.int8.onnx
-rw-rw-r--@<span class="w"> </span><span class="m">1</span><span class="w"> </span>zengruijin<span class="w">  </span>staff<span class="w">   </span>248M<span class="w"> </span>Sep<span class="w"> </span><span class="m">18</span><span class="w"> </span><span class="m">07</span>:05<span class="w"> </span>encoder-epoch-20-avg-1.onnx
-rw-rw-r--@<span class="w"> </span><span class="m">1</span><span class="w"> </span>zengruijin<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.0M<span class="w"> </span>Sep<span class="w"> </span><span class="m">18</span><span class="w"> </span><span class="m">07</span>:05<span class="w"> </span>joiner-epoch-20-avg-1.int8.onnx
-rw-rw-r--@<span class="w"> </span><span class="m">1</span><span class="w"> </span>zengruijin<span class="w">  </span>staff<span class="w">   </span><span class="m">3</span>.9M<span class="w"> </span>Sep<span class="w"> </span><span class="m">18</span><span class="w"> </span><span class="m">07</span>:05<span class="w"> </span>joiner-epoch-20-avg-1.onnx
</pre></div>
</div>
</section>
<section id="id51">
<h3>Decode wave files<a class="headerlink" href="#id51" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id52">
<h4>fp32<a class="headerlink" href="#id52" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/encoder-epoch-20-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/decoder-epoch-20-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/joiner-epoch-20-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/runner/work/sherpa-onnx/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/tokens.txt --encoder=./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/encoder-epoch-20-avg-1.onnx --decoder=./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/decoder-epoch-20-avg-1.onnx --joiner=./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/joiner-epoch-20-avg-1.onnx ./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/0.wav ./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/1.wav ./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/8k.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/encoder-epoch-20-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/decoder-epoch-20-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/joiner-epoch-20-avg-1.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5)
Creating recognizer ...
Started
/Users/runner/work/sherpa-onnx/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:117 Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/0.wav
{&quot;text&quot;:&quot; 对我做了介绍那么我想说的是大家如果对我的研究感兴趣&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.16, 0.40, 0.60, 0.84, 1.08, 1.60, 1.72, 1.88, 2.04, 2.24, 2.44, 2.60, 2.96, 3.12, 3.32, 3.40, 3.60, 3.72, 3.84, 4.00, 4.16, 4.32, 4.52, 4.68]&quot;,&quot;tokens&quot;:[&quot; 对&quot;,&quot;我&quot;,&quot;做&quot;,&quot;了&quot;,&quot;介&quot;,&quot;绍&quot;,&quot;那&quot;,&quot;么&quot;,&quot;我&quot;,&quot;想&quot;,&quot;说&quot;,&quot;的&quot;,&quot;是&quot;,&quot;大&quot;,&quot;家&quot;,&quot;如&quot;,&quot;果&quot;,&quot;对&quot;,&quot;我&quot;,&quot;的&quot;,&quot;研&quot;,&quot;究&quot;,&quot;感&quot;,&quot;兴&quot;,&quot;趣&quot;]}
----
./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/1.wav
{&quot;text&quot;:&quot; 重点想谈三个问题首先就是这一轮全球金融动&lt;0xE8&gt;&lt;0x8D&gt;&lt;0xA1&gt;的表现&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.48, 0.68, 0.92, 1.12, 1.28, 1.48, 1.80, 2.04, 2.40, 2.56, 2.76, 2.96, 3.08, 3.32, 3.48, 3.68, 3.84, 4.00, 4.20, 4.24, 4.28, 4.40, 4.60, 4.84]&quot;,&quot;tokens&quot;:[&quot; 重&quot;,&quot;点&quot;,&quot;想&quot;,&quot;谈&quot;,&quot;三&quot;,&quot;个&quot;,&quot;问&quot;,&quot;题&quot;,&quot;首&quot;,&quot;先&quot;,&quot;就&quot;,&quot;是&quot;,&quot;这&quot;,&quot;一&quot;,&quot;轮&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;&lt;0xE8&gt;&quot;,&quot;&lt;0x8D&gt;&quot;,&quot;&lt;0xA1&gt;&quot;,&quot;的&quot;,&quot;表&quot;,&quot;现&quot;]}
----
./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/8k.wav
{&quot;text&quot;:&quot; 深入地分析这一次全球金融动&lt;0xE8&gt;&lt;0x8D&gt;&lt;0xA1&gt;背后的根源&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.04, 0.24, 0.52, 0.76, 1.00, 1.40, 1.64, 1.80, 2.12, 2.32, 2.64, 2.80, 3.00, 3.20, 3.24, 3.28, 3.44, 3.64, 3.76, 3.96, 4.20]&quot;,&quot;tokens&quot;:[&quot; &quot;,&quot;深&quot;,&quot;入&quot;,&quot;地&quot;,&quot;分&quot;,&quot;析&quot;,&quot;这&quot;,&quot;一&quot;,&quot;次&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;&lt;0xE8&gt;&quot;,&quot;&lt;0x8D&gt;&quot;,&quot;&lt;0xA1&gt;&quot;,&quot;背&quot;,&quot;后&quot;,&quot;的&quot;,&quot;根&quot;,&quot;源&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.362 s
Real time factor (RTF): 0.362 / 15.289 = 0.024
</pre></div>
</div>
</section>
<section id="id53">
<h4>int8<a class="headerlink" href="#id53" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/encoder-epoch-20-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/decoder-epoch-20-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/joiner-epoch-20-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/runner/work/sherpa-onnx/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/tokens.txt --encoder=./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/encoder-epoch-20-avg-1.int8.onnx --decoder=./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/decoder-epoch-20-avg-1.onnx --joiner=./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/joiner-epoch-20-avg-1.int8.onnx ./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/0.wav ./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/1.wav ./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/8k.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/encoder-epoch-20-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/decoder-epoch-20-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/joiner-epoch-20-avg-1.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5)
Creating recognizer ...
Started
/Users/runner/work/sherpa-onnx/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:117 Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/0.wav
{&quot;text&quot;:&quot; 对我做了介绍那么我想说的是大家如果对我的研究感兴趣&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.16, 0.40, 0.60, 0.84, 1.08, 1.60, 1.72, 1.88, 2.04, 2.28, 2.44, 2.60, 2.96, 3.12, 3.32, 3.40, 3.60, 3.76, 3.84, 4.00, 4.16, 4.32, 4.52, 4.56]&quot;,&quot;tokens&quot;:[&quot; 对&quot;,&quot;我&quot;,&quot;做&quot;,&quot;了&quot;,&quot;介&quot;,&quot;绍&quot;,&quot;那&quot;,&quot;么&quot;,&quot;我&quot;,&quot;想&quot;,&quot;说&quot;,&quot;的&quot;,&quot;是&quot;,&quot;大&quot;,&quot;家&quot;,&quot;如&quot;,&quot;果&quot;,&quot;对&quot;,&quot;我&quot;,&quot;的&quot;,&quot;研&quot;,&quot;究&quot;,&quot;感&quot;,&quot;兴&quot;,&quot;趣&quot;]}
----
./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/1.wav
{&quot;text&quot;:&quot; 重点想谈三个问题首先就是这一轮全球金融动&lt;0xE8&gt;&lt;0x8D&gt;&lt;0xA1&gt;的表现&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.48, 0.68, 0.92, 1.12, 1.28, 1.48, 1.80, 2.04, 2.40, 2.56, 2.76, 2.96, 3.08, 3.32, 3.48, 3.68, 3.84, 4.00, 4.20, 4.24, 4.28, 4.40, 4.60, 4.84]&quot;,&quot;tokens&quot;:[&quot; 重&quot;,&quot;点&quot;,&quot;想&quot;,&quot;谈&quot;,&quot;三&quot;,&quot;个&quot;,&quot;问&quot;,&quot;题&quot;,&quot;首&quot;,&quot;先&quot;,&quot;就&quot;,&quot;是&quot;,&quot;这&quot;,&quot;一&quot;,&quot;轮&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;&lt;0xE8&gt;&quot;,&quot;&lt;0x8D&gt;&quot;,&quot;&lt;0xA1&gt;&quot;,&quot;的&quot;,&quot;表&quot;,&quot;现&quot;]}
----
./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/test_wavs/8k.wav
{&quot;text&quot;:&quot; 深入地分析这一次全球金融动&lt;0xE8&gt;&lt;0x8D&gt;&lt;0xA1&gt;背后的根源&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.04, 0.24, 0.52, 0.76, 1.00, 1.40, 1.64, 1.80, 2.12, 2.36, 2.64, 2.80, 3.04, 3.16, 3.20, 3.24, 3.44, 3.64, 3.76, 3.96, 4.20]&quot;,&quot;tokens&quot;:[&quot; &quot;,&quot;深&quot;,&quot;入&quot;,&quot;地&quot;,&quot;分&quot;,&quot;析&quot;,&quot;这&quot;,&quot;一&quot;,&quot;次&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;&lt;0xE8&gt;&quot;,&quot;&lt;0x8D&gt;&quot;,&quot;&lt;0xA1&gt;&quot;,&quot;背&quot;,&quot;后&quot;,&quot;的&quot;,&quot;根&quot;,&quot;源&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.305 s
Real time factor (RTF): 0.305 / 15.289 = 0.020
</pre></div>
</div>
</section>
</section>
<section id="id54">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id54" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/encoder-epoch-20-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/decoder-epoch-20-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-multi-zh-hans-2023-9-2/joiner-epoch-20-avg-1.onnx
</pre></div>
</div>
</section>
</section>
<section id="yfyeung-icefall-asr-cv-corpus-13-0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17-english">
<h2>yfyeung/icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17 (English)<a class="headerlink" href="#yfyeung-icefall-asr-cv-corpus-13-0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17-english" title="Permalink to this heading"></a></h2>
<p>This model is from</p>
<p><a class="reference external" href="https://huggingface.co/yfyeung/icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17">https://huggingface.co/yfyeung/icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17</a></p>
<p>which supports only English as it is trained on the <a class="reference external" href="https://commonvoice.mozilla.org">CommonVoice</a> English dataset.</p>
<p>If you are interested in how the model is trained, please refer to
<a class="reference external" href="https://github.com/k2-fsa/icefall/pull/997">https://github.com/k2-fsa/icefall/pull/997</a>.</p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id55">
<h3>Download the model<a class="headerlink" href="#id55" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17.tar.bz2
rm<span class="w"> </span>icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17.tar.bz2
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17<span class="w"> </span>fangjun$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>exp/*epoch-60-avg-20*.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.2M<span class="w"> </span>Jun<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">09</span>:53<span class="w"> </span>exp/decoder-epoch-60-avg-20.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.0M<span class="w"> </span>Jun<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">09</span>:54<span class="w"> </span>exp/decoder-epoch-60-avg-20.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>121M<span class="w"> </span>Jun<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">09</span>:54<span class="w"> </span>exp/encoder-epoch-60-avg-20.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>279M<span class="w"> </span>Jun<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">09</span>:55<span class="w"> </span>exp/encoder-epoch-60-avg-20.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>253K<span class="w"> </span>Jun<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">09</span>:53<span class="w"> </span>exp/joiner-epoch-60-avg-20.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.0M<span class="w"> </span>Jun<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">09</span>:53<span class="w"> </span>exp/joiner-epoch-60-avg-20.onnx
</pre></div>
</div>
</section>
<section id="id56">
<h3>Decode wave files<a class="headerlink" href="#id56" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id57">
<h4>fp32<a class="headerlink" href="#id57" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/data/lang_bpe_500/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/encoder-epoch-60-avg-20.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/decoder-epoch-60-avg-20.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/joiner-epoch-60-avg-20.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1089-134686-0001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1221-135766-0001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1221-135766-0002.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/data/lang_bpe_500/tokens.txt --encoder=./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/encoder-epoch-60-avg-20.onnx --decoder=./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/decoder-epoch-60-avg-20.onnx --joiner=./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/joiner-epoch-60-avg-20.onnx ./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1089-134686-0001.wav ./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1221-135766-0001.wav ./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1221-135766-0002.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/encoder-epoch-60-avg-20.onnx&quot;, decoder_filename=&quot;./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/decoder-epoch-60-avg-20.onnx&quot;, joiner_filename=&quot;./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/joiner-epoch-60-avg-20.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/data/lang_bpe_500/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, context_score=1.5)
Creating recognizer ...
Started
Done!

./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1089-134686-0001.wav
{&quot;text&quot;:&quot; AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.64, 0.76, 0.84, 1.04, 1.08, 1.16, 1.32, 1.44, 1.56, 1.72, 1.84, 1.88, 1.92, 1.96, 2.04, 2.16, 2.32, 2.48, 2.56, 2.76, 2.80, 2.84, 3.08, 3.28, 3.40, 3.52, 3.68, 4.00, 4.24, 4.28, 4.52, 4.68, 4.84, 4.88, 4.96, 5.04, 5.28, 5.40, 5.52, 5.72, 5.88, 6.08]&quot;,&quot;tokens&quot;:[&quot; AFTER&quot;,&quot; E&quot;,&quot;AR&quot;,&quot;LY&quot;,&quot; &quot;,&quot;N&quot;,&quot;IGHT&quot;,&quot;F&quot;,&quot;AL&quot;,&quot;L&quot;,&quot; THE&quot;,&quot; &quot;,&quot;Y&quot;,&quot;E&quot;,&quot;LL&quot;,&quot;OW&quot;,&quot; LA&quot;,&quot;MP&quot;,&quot;S&quot;,&quot; WOULD&quot;,&quot; &quot;,&quot;L&quot;,&quot;IGHT&quot;,&quot; UP&quot;,&quot; HE&quot;,&quot;RE&quot;,&quot; AND&quot;,&quot; THERE&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;QUA&quot;,&quot;LI&quot;,&quot;D&quot;,&quot; &quot;,&quot;QUA&quot;,&quot;R&quot;,&quot;TER&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; BRO&quot;,&quot;TH&quot;,&quot;EL&quot;,&quot;S&quot;]}
----
./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1221-135766-0001.wav
{&quot;text&quot;:&quot; GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOREVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN&quot;,&quot;timestamps&quot;:&quot;[0.04, 0.44, 0.64, 0.84, 0.96, 1.32, 1.52, 1.68, 1.84, 1.88, 2.04, 2.16, 2.32, 2.40, 2.64, 2.88, 3.12, 3.24, 3.44, 3.52, 3.72, 3.88, 4.20, 4.40, 4.48, 4.60, 4.76, 4.96, 5.08, 5.24, 5.36, 5.56, 5.80, 6.20, 6.32, 6.52, 6.92, 7.16, 7.36, 7.60, 7.76, 7.92, 8.16, 8.28, 8.40, 8.48, 8.60, 8.76, 8.84, 9.08, 9.24, 9.44, 9.48, 9.72, 9.88, 10.04, 10.12, 10.52, 10.76, 10.84, 11.08, 11.24, 11.36, 11.60, 11.76, 11.96, 12.08, 12.24, 12.28, 12.48, 12.72, 12.84, 12.92, 13.00, 13.20, 13.52, 13.76, 13.88, 14.08, 14.28, 14.52, 14.64, 14.76, 14.96, 15.04, 15.24, 15.48, 15.68, 15.84, 16.00, 16.04]&quot;,&quot;tokens&quot;:[&quot; GO&quot;,&quot;D&quot;,&quot; AS&quot;,&quot; A&quot;,&quot; DIRECT&quot;,&quot; CON&quot;,&quot;SE&quot;,&quot;QUE&quot;,&quot;N&quot;,&quot;CE&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;IN&quot;,&quot; WHICH&quot;,&quot; MAN&quot;,&quot; TH&quot;,&quot;US&quot;,&quot; P&quot;,&quot;UN&quot;,&quot;ISH&quot;,&quot;ED&quot;,&quot; HAD&quot;,&quot; G&quot;,&quot;IVE&quot;,&quot;N&quot;,&quot; HER&quot;,&quot; A&quot;,&quot; LO&quot;,&quot;VE&quot;,&quot;LY&quot;,&quot; CHI&quot;,&quot;LD&quot;,&quot; WHO&quot;,&quot;SE&quot;,&quot; PLACE&quot;,&quot; WAS&quot;,&quot; ON&quot;,&quot; THAT&quot;,&quot; SA&quot;,&quot;ME&quot;,&quot; DIS&quot;,&quot;HO&quot;,&quot;N&quot;,&quot;OR&quot;,&quot;ED&quot;,&quot; BO&quot;,&quot;S&quot;,&quot;OM&quot;,&quot; TO&quot;,&quot; CON&quot;,&quot;N&quot;,&quot;ECT&quot;,&quot; HER&quot;,&quot; PA&quot;,&quot;R&quot;,&quot;ENT&quot;,&quot; FOR&quot;,&quot;E&quot;,&quot;VER&quot;,&quot; WITH&quot;,&quot; THE&quot;,&quot; RA&quot;,&quot;CE&quot;,&quot; AND&quot;,&quot; DE&quot;,&quot;S&quot;,&quot;C&quot;,&quot;ENT&quot;,&quot; OF&quot;,&quot; MO&quot;,&quot;R&quot;,&quot;T&quot;,&quot;AL&quot;,&quot;S&quot;,&quot; AND&quot;,&quot; TO&quot;,&quot; BE&quot;,&quot; FIN&quot;,&quot;ALLY&quot;,&quot; A&quot;,&quot; B&quot;,&quot;LES&quot;,&quot;S&quot;,&quot;ED&quot;,&quot; SO&quot;,&quot;UL&quot;,&quot; IN&quot;,&quot; HE&quot;,&quot;A&quot;,&quot;VEN&quot;]}
----
./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1221-135766-0002.wav
{&quot;text&quot;:&quot; YET THESE THOUGHTS AFFECTED HESTER PRIN LESS WITH HOPE THAN APPREHENSION&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.04, 0.12, 0.56, 0.80, 0.88, 1.00, 1.04, 1.12, 1.20, 1.28, 1.40, 1.52, 1.64, 1.76, 1.84, 2.04, 2.24, 2.40, 2.64, 2.68, 2.84, 3.04, 3.24, 3.44, 3.52, 3.72, 3.92, 4.00, 4.16, 4.24, 4.36]&quot;,&quot;tokens&quot;:[&quot; &quot;,&quot;Y&quot;,&quot;ET&quot;,&quot; THESE&quot;,&quot; TH&quot;,&quot;O&quot;,&quot;UGH&quot;,&quot;T&quot;,&quot;S&quot;,&quot; A&quot;,&quot;FF&quot;,&quot;ECT&quot;,&quot;ED&quot;,&quot; HE&quot;,&quot;S&quot;,&quot;TER&quot;,&quot; PRI&quot;,&quot;N&quot;,&quot; LE&quot;,&quot;S&quot;,&quot;S&quot;,&quot; WITH&quot;,&quot; HO&quot;,&quot;PE&quot;,&quot; TH&quot;,&quot;AN&quot;,&quot; APP&quot;,&quot;RE&quot;,&quot;HE&quot;,&quot;N&quot;,&quot;S&quot;,&quot;ION&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.611 s
Real time factor (RTF): 1.611 / 28.165 = 0.057
</pre></div>
</div>
</section>
<section id="id58">
<h4>int8<a class="headerlink" href="#id58" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/data/lang_bpe_500/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/encoder-epoch-60-avg-20.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/decoder-epoch-60-avg-20.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/joiner-epoch-60-avg-20.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1089-134686-0001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1221-135766-0001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1221-135766-0002.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/data/lang_bpe_500/tokens.txt --encoder=./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/encoder-epoch-60-avg-20.int8.onnx --decoder=./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/decoder-epoch-60-avg-20.onnx --joiner=./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/joiner-epoch-60-avg-20.int8.onnx ./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1089-134686-0001.wav ./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1221-135766-0001.wav ./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1221-135766-0002.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/encoder-epoch-60-avg-20.int8.onnx&quot;, decoder_filename=&quot;./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/decoder-epoch-60-avg-20.onnx&quot;, joiner_filename=&quot;./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/joiner-epoch-60-avg-20.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/data/lang_bpe_500/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, context_score=1.5)
Creating recognizer ...
Started
Done!

./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1089-134686-0001.wav
{&quot;text&quot;:&quot; AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.64, 0.76, 0.84, 1.04, 1.08, 1.16, 1.36, 1.44, 1.56, 1.72, 1.84, 1.88, 1.92, 1.96, 2.04, 2.20, 2.32, 2.48, 2.56, 2.76, 2.80, 2.84, 3.08, 3.28, 3.40, 3.52, 3.68, 4.00, 4.24, 4.28, 4.52, 4.68, 4.84, 4.88, 4.96, 5.04, 5.28, 5.36, 5.52, 5.72, 5.88, 6.08]&quot;,&quot;tokens&quot;:[&quot; AFTER&quot;,&quot; E&quot;,&quot;AR&quot;,&quot;LY&quot;,&quot; &quot;,&quot;N&quot;,&quot;IGHT&quot;,&quot;F&quot;,&quot;AL&quot;,&quot;L&quot;,&quot; THE&quot;,&quot; &quot;,&quot;Y&quot;,&quot;E&quot;,&quot;LL&quot;,&quot;OW&quot;,&quot; LA&quot;,&quot;MP&quot;,&quot;S&quot;,&quot; WOULD&quot;,&quot; &quot;,&quot;L&quot;,&quot;IGHT&quot;,&quot; UP&quot;,&quot; HE&quot;,&quot;RE&quot;,&quot; AND&quot;,&quot; THERE&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;QUA&quot;,&quot;LI&quot;,&quot;D&quot;,&quot; &quot;,&quot;QUA&quot;,&quot;R&quot;,&quot;TER&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; BRO&quot;,&quot;TH&quot;,&quot;EL&quot;,&quot;S&quot;]}
----
./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1221-135766-0001.wav
{&quot;text&quot;:&quot; GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOREVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN&quot;,&quot;timestamps&quot;:&quot;[0.04, 0.44, 0.64, 0.84, 0.96, 1.32, 1.52, 1.68, 1.84, 1.88, 2.04, 2.16, 2.32, 2.40, 2.64, 2.88, 3.12, 3.24, 3.44, 3.52, 3.72, 3.88, 4.20, 4.40, 4.48, 4.60, 4.76, 4.96, 5.08, 5.24, 5.36, 5.56, 5.80, 6.20, 6.32, 6.52, 6.92, 7.16, 7.32, 7.60, 7.76, 7.92, 8.16, 8.28, 8.40, 8.48, 8.60, 8.76, 8.84, 9.08, 9.24, 9.44, 9.48, 9.72, 9.88, 10.04, 10.12, 10.52, 10.76, 10.84, 11.08, 11.24, 11.36, 11.60, 11.76, 11.96, 12.08, 12.24, 12.28, 12.48, 12.72, 12.84, 12.92, 13.00, 13.20, 13.52, 13.76, 13.88, 14.08, 14.28, 14.52, 14.64, 14.76, 14.96, 15.04, 15.24, 15.48, 15.68, 15.84, 16.00, 16.04]&quot;,&quot;tokens&quot;:[&quot; GO&quot;,&quot;D&quot;,&quot; AS&quot;,&quot; A&quot;,&quot; DIRECT&quot;,&quot; CON&quot;,&quot;SE&quot;,&quot;QUE&quot;,&quot;N&quot;,&quot;CE&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;IN&quot;,&quot; WHICH&quot;,&quot; MAN&quot;,&quot; TH&quot;,&quot;US&quot;,&quot; P&quot;,&quot;UN&quot;,&quot;ISH&quot;,&quot;ED&quot;,&quot; HAD&quot;,&quot; G&quot;,&quot;IVE&quot;,&quot;N&quot;,&quot; HER&quot;,&quot; A&quot;,&quot; LO&quot;,&quot;VE&quot;,&quot;LY&quot;,&quot; CHI&quot;,&quot;LD&quot;,&quot; WHO&quot;,&quot;SE&quot;,&quot; PLACE&quot;,&quot; WAS&quot;,&quot; ON&quot;,&quot; THAT&quot;,&quot; SA&quot;,&quot;ME&quot;,&quot; DIS&quot;,&quot;HO&quot;,&quot;N&quot;,&quot;OR&quot;,&quot;ED&quot;,&quot; BO&quot;,&quot;S&quot;,&quot;OM&quot;,&quot; TO&quot;,&quot; CON&quot;,&quot;N&quot;,&quot;ECT&quot;,&quot; HER&quot;,&quot; PA&quot;,&quot;R&quot;,&quot;ENT&quot;,&quot; FOR&quot;,&quot;E&quot;,&quot;VER&quot;,&quot; WITH&quot;,&quot; THE&quot;,&quot; RA&quot;,&quot;CE&quot;,&quot; AND&quot;,&quot; DE&quot;,&quot;S&quot;,&quot;C&quot;,&quot;ENT&quot;,&quot; OF&quot;,&quot; MO&quot;,&quot;R&quot;,&quot;T&quot;,&quot;AL&quot;,&quot;S&quot;,&quot; AND&quot;,&quot; TO&quot;,&quot; BE&quot;,&quot; FIN&quot;,&quot;ALLY&quot;,&quot; A&quot;,&quot; B&quot;,&quot;LES&quot;,&quot;S&quot;,&quot;ED&quot;,&quot; SO&quot;,&quot;UL&quot;,&quot; IN&quot;,&quot; HE&quot;,&quot;A&quot;,&quot;VEN&quot;]}
----
./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/test_wavs/1221-135766-0002.wav
{&quot;text&quot;:&quot; YET THESE THOUGHTS AFFECTED HESTER PRIN LESS WITH HOPE THAN APPREHENSION&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.04, 0.12, 0.56, 0.80, 0.88, 1.00, 1.04, 1.12, 1.20, 1.28, 1.40, 1.52, 1.64, 1.76, 1.84, 2.04, 2.24, 2.40, 2.64, 2.68, 2.84, 3.04, 3.24, 3.44, 3.52, 3.72, 3.92, 4.00, 4.16, 4.24, 4.36]&quot;,&quot;tokens&quot;:[&quot; &quot;,&quot;Y&quot;,&quot;ET&quot;,&quot; THESE&quot;,&quot; TH&quot;,&quot;O&quot;,&quot;UGH&quot;,&quot;T&quot;,&quot;S&quot;,&quot; A&quot;,&quot;FF&quot;,&quot;ECT&quot;,&quot;ED&quot;,&quot; HE&quot;,&quot;S&quot;,&quot;TER&quot;,&quot; PRI&quot;,&quot;N&quot;,&quot; LE&quot;,&quot;S&quot;,&quot;S&quot;,&quot; WITH&quot;,&quot; HO&quot;,&quot;PE&quot;,&quot; TH&quot;,&quot;AN&quot;,&quot; APP&quot;,&quot;RE&quot;,&quot;HE&quot;,&quot;N&quot;,&quot;S&quot;,&quot;ION&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.368 s
Real time factor (RTF): 1.368 / 28.165 = 0.049
</pre></div>
</div>
</section>
</section>
<section id="id59">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id59" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/data/lang_bpe_500/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/encoder-epoch-60-avg-20.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/decoder-epoch-60-avg-20.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./icefall-asr-cv-corpus-13.0-2023-03-09-en-pruned-transducer-stateless7-2023-04-17/exp/joiner-epoch-60-avg-20.onnx
</pre></div>
</div>
</section>
</section>
<section id="k2-fsa-icefall-asr-zipformer-wenetspeech-small-chinese">
<span id="sherpa-onnx-wenetspeech-small"></span><h2>k2-fsa/icefall-asr-zipformer-wenetspeech-small (Chinese)<a class="headerlink" href="#k2-fsa-icefall-asr-zipformer-wenetspeech-small-chinese" title="Permalink to this heading"></a></h2>
<p>This model is from</p>
<p><a class="reference external" href="https://huggingface.co/k2-fsa/icefall-asr-zipformer-wenetspeech-small">https://huggingface.co/k2-fsa/icefall-asr-zipformer-wenetspeech-small</a></p>
<p>which supports only Chinese as it is trained on the <a class="reference external" href="https://github.com/wenet-e2e/WenetSpeech">WenetSpeech</a> corpus.</p>
<p>In the following, we describe how to download it.</p>
<section id="id60">
<h3>Download the model<a class="headerlink" href="#id60" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>lfs<span class="w"> </span>install
git<span class="w"> </span>clone<span class="w"> </span>https://huggingface.co/k2-fsa/icefall-asr-zipformer-wenetspeech-small
</pre></div>
</div>
</section>
</section>
<section id="k2-fsa-icefall-asr-zipformer-wenetspeech-large-chinese">
<span id="sherpa-onnx-wenetspeech-large"></span><h2>k2-fsa/icefall-asr-zipformer-wenetspeech-large (Chinese)<a class="headerlink" href="#k2-fsa-icefall-asr-zipformer-wenetspeech-large-chinese" title="Permalink to this heading"></a></h2>
<p>This model is from</p>
<p><a class="reference external" href="https://huggingface.co/k2-fsa/icefall-asr-zipformer-wenetspeech-large">https://huggingface.co/k2-fsa/icefall-asr-zipformer-wenetspeech-large</a></p>
<p>which supports only Chinese as it is trained on the <a class="reference external" href="https://github.com/wenet-e2e/WenetSpeech">WenetSpeech</a> corpus.</p>
<p>In the following, we describe how to download it.</p>
<section id="id61">
<h3>Download the model<a class="headerlink" href="#id61" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>lfs<span class="w"> </span>install
git<span class="w"> </span>clone<span class="w"> </span>https://huggingface.co/k2-fsa/icefall-asr-zipformer-wenetspeech-large
</pre></div>
</div>
</section>
</section>
<section id="pkufool-icefall-asr-zipformer-wenetspeech-20230615-chinese">
<h2>pkufool/icefall-asr-zipformer-wenetspeech-20230615 (Chinese)<a class="headerlink" href="#pkufool-icefall-asr-zipformer-wenetspeech-20230615-chinese" title="Permalink to this heading"></a></h2>
<p>This model is from</p>
<p><a class="reference external" href="https://huggingface.co/pkufool/icefall-asr-zipformer-wenetspeech-20230615">https://huggingface.co/pkufool/icefall-asr-zipformer-wenetspeech-20230615</a></p>
<p>which supports only Chinese as it is trained on the <a class="reference external" href="https://github.com/wenet-e2e/WenetSpeech">WenetSpeech</a> corpus.</p>
<p>If you are interested in how the model is trained, please refer to
<a class="reference external" href="https://github.com/k2-fsa/icefall/pull/1130">https://github.com/k2-fsa/icefall/pull/1130</a>.</p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id62">
<h3>Download the model<a class="headerlink" href="#id62" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/icefall-asr-zipformer-wenetspeech-20230615.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>icefall-asr-zipformer-wenetspeech-20230615.tar.bz2
rm<span class="w"> </span>icefall-asr-zipformer-wenetspeech-20230615.tar.bz2
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>icefall-asr-zipformer-wenetspeech-20230615<span class="w"> </span>fangjun$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>exp/*.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>11M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">14</span>:31<span class="w"> </span>exp/decoder-epoch-12-avg-4.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>12M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">14</span>:31<span class="w"> </span>exp/decoder-epoch-12-avg-4.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>66M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">14</span>:32<span class="w"> </span>exp/encoder-epoch-12-avg-4.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>248M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">14</span>:34<span class="w"> </span>exp/encoder-epoch-12-avg-4.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.7M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">14</span>:31<span class="w"> </span>exp/joiner-epoch-12-avg-4.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>11M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">14</span>:31<span class="w"> </span>exp/joiner-epoch-12-avg-4.onnx
</pre></div>
</div>
</section>
<section id="id63">
<h3>Decode wave files<a class="headerlink" href="#id63" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id64">
<h4>fp32<a class="headerlink" href="#id64" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./icefall-asr-zipformer-wenetspeech-20230615/data/lang_char/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./icefall-asr-zipformer-wenetspeech-20230615/exp/encoder-epoch-12-avg-4.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./icefall-asr-zipformer-wenetspeech-20230615/exp/decoder-epoch-12-avg-4.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./icefall-asr-zipformer-wenetspeech-20230615/exp/joiner-epoch-12-avg-4.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000000.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000002.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./icefall-asr-zipformer-wenetspeech-20230615/data/lang_char/tokens.txt --encoder=./icefall-asr-zipformer-wenetspeech-20230615/exp/encoder-epoch-12-avg-4.onnx --decoder=./icefall-asr-zipformer-wenetspeech-20230615/exp/decoder-epoch-12-avg-4.onnx --joiner=./icefall-asr-zipformer-wenetspeech-20230615/exp/joiner-epoch-12-avg-4.onnx ./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000000.wav ./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000001.wav ./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000002.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./icefall-asr-zipformer-wenetspeech-20230615/exp/encoder-epoch-12-avg-4.onnx&quot;, decoder_filename=&quot;./icefall-asr-zipformer-wenetspeech-20230615/exp/decoder-epoch-12-avg-4.onnx&quot;, joiner_filename=&quot;./icefall-asr-zipformer-wenetspeech-20230615/exp/joiner-epoch-12-avg-4.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./icefall-asr-zipformer-wenetspeech-20230615/data/lang_char/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, context_score=1.5)
Creating recognizer ...
Started
Done!

./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000000.wav
{&quot;text&quot;:&quot;对我做了介绍那么我想说的是大家如果对我的研究感兴趣呢&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.48, 0.64, 0.88, 1.16, 1.64, 1.76, 1.92, 2.08, 2.32, 2.48, 2.64, 3.08, 3.20, 3.40, 3.48, 3.64, 3.76, 3.88, 3.96, 4.12, 4.28, 4.52, 4.72, 4.84]&quot;,&quot;tokens&quot;:[&quot;对&quot;,&quot;我&quot;,&quot;做&quot;,&quot;了&quot;,&quot;介&quot;,&quot;绍&quot;,&quot;那&quot;,&quot;么&quot;,&quot;我&quot;,&quot;想&quot;,&quot;说&quot;,&quot;的&quot;,&quot;是&quot;,&quot;大&quot;,&quot;家&quot;,&quot;如&quot;,&quot;果&quot;,&quot;对&quot;,&quot;我&quot;,&quot;的&quot;,&quot;研&quot;,&quot;究&quot;,&quot;感&quot;,&quot;兴&quot;,&quot;趣&quot;,&quot;呢&quot;]}
----
./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000001.wav
{&quot;text&quot;:&quot;重点想谈三个问题首先就是这一轮全球金融动荡的表现&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.16, 0.48, 0.72, 0.92, 1.08, 1.28, 1.52, 1.92, 2.08, 2.52, 2.64, 2.88, 3.04, 3.20, 3.40, 3.56, 3.76, 3.84, 4.00, 4.16, 4.32, 4.56, 4.84]&quot;,&quot;tokens&quot;:[&quot;重&quot;,&quot;点&quot;,&quot;想&quot;,&quot;谈&quot;,&quot;三&quot;,&quot;个&quot;,&quot;问&quot;,&quot;题&quot;,&quot;首&quot;,&quot;先&quot;,&quot;就&quot;,&quot;是&quot;,&quot;这&quot;,&quot;一&quot;,&quot;轮&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;荡&quot;,&quot;的&quot;,&quot;表&quot;,&quot;现&quot;]}
----
./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000002.wav
{&quot;text&quot;:&quot;深入地分析这一次全球金融动荡背后的根源&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.32, 0.56, 0.84, 1.12, 1.44, 1.68, 1.84, 2.28, 2.48, 2.76, 2.92, 3.12, 3.28, 3.44, 3.60, 3.72, 3.92, 4.20]&quot;,&quot;tokens&quot;:[&quot;深&quot;,&quot;入&quot;,&quot;地&quot;,&quot;分&quot;,&quot;析&quot;,&quot;这&quot;,&quot;一&quot;,&quot;次&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;荡&quot;,&quot;背&quot;,&quot;后&quot;,&quot;的&quot;,&quot;根&quot;,&quot;源&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.458 s
Real time factor (RTF): 0.458 / 15.289 = 0.030
</pre></div>
</div>
</section>
<section id="id65">
<h4>int8<a class="headerlink" href="#id65" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./icefall-asr-zipformer-wenetspeech-20230615/data/lang_char/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./icefall-asr-zipformer-wenetspeech-20230615/exp/encoder-epoch-12-avg-4.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./icefall-asr-zipformer-wenetspeech-20230615/exp/decoder-epoch-12-avg-4.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./icefall-asr-zipformer-wenetspeech-20230615/exp/joiner-epoch-12-avg-4.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000000.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000002.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./icefall-asr-zipformer-wenetspeech-20230615/data/lang_char/tokens.txt --encoder=./icefall-asr-zipformer-wenetspeech-20230615/exp/encoder-epoch-12-avg-4.int8.onnx --decoder=./icefall-asr-zipformer-wenetspeech-20230615/exp/decoder-epoch-12-avg-4.onnx --joiner=./icefall-asr-zipformer-wenetspeech-20230615/exp/joiner-epoch-12-avg-4.int8.onnx ./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000000.wav ./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000001.wav ./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000002.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./icefall-asr-zipformer-wenetspeech-20230615/exp/encoder-epoch-12-avg-4.int8.onnx&quot;, decoder_filename=&quot;./icefall-asr-zipformer-wenetspeech-20230615/exp/decoder-epoch-12-avg-4.onnx&quot;, joiner_filename=&quot;./icefall-asr-zipformer-wenetspeech-20230615/exp/joiner-epoch-12-avg-4.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./icefall-asr-zipformer-wenetspeech-20230615/data/lang_char/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, context_score=1.5)
Creating recognizer ...
Started
Done!

./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000000.wav
{&quot;text&quot;:&quot;对我做了介绍那么我想说的是大家如果对我的研究感兴趣呢&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.48, 0.60, 0.80, 1.08, 1.64, 1.76, 1.92, 2.08, 2.32, 2.48, 2.64, 3.08, 3.20, 3.28, 3.44, 3.60, 3.72, 3.84, 3.92, 4.12, 4.28, 4.48, 4.72, 4.84]&quot;,&quot;tokens&quot;:[&quot;对&quot;,&quot;我&quot;,&quot;做&quot;,&quot;了&quot;,&quot;介&quot;,&quot;绍&quot;,&quot;那&quot;,&quot;么&quot;,&quot;我&quot;,&quot;想&quot;,&quot;说&quot;,&quot;的&quot;,&quot;是&quot;,&quot;大&quot;,&quot;家&quot;,&quot;如&quot;,&quot;果&quot;,&quot;对&quot;,&quot;我&quot;,&quot;的&quot;,&quot;研&quot;,&quot;究&quot;,&quot;感&quot;,&quot;兴&quot;,&quot;趣&quot;,&quot;呢&quot;]}
----
./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000001.wav
{&quot;text&quot;:&quot;重点想谈三个问题首先呢就是这一轮全球金融动荡的表现&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.16, 0.48, 0.68, 0.84, 1.08, 1.20, 1.48, 1.64, 2.08, 2.36, 2.52, 2.64, 2.84, 3.00, 3.16, 3.40, 3.52, 3.72, 3.84, 4.00, 4.16, 4.32, 4.56, 4.84]&quot;,&quot;tokens&quot;:[&quot;重&quot;,&quot;点&quot;,&quot;想&quot;,&quot;谈&quot;,&quot;三&quot;,&quot;个&quot;,&quot;问&quot;,&quot;题&quot;,&quot;首&quot;,&quot;先&quot;,&quot;呢&quot;,&quot;就&quot;,&quot;是&quot;,&quot;这&quot;,&quot;一&quot;,&quot;轮&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;荡&quot;,&quot;的&quot;,&quot;表&quot;,&quot;现&quot;]}
----
./icefall-asr-zipformer-wenetspeech-20230615/test_wavs/DEV_T0000000002.wav
{&quot;text&quot;:&quot;深入地分析这一次全球金融动荡荡背后的根源&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.48, 0.84, 1.08, 1.44, 1.60, 1.84, 2.24, 2.48, 2.76, 2.88, 3.12, 3.24, 3.28, 3.36, 3.60, 3.72, 3.84, 4.16]&quot;,&quot;tokens&quot;:[&quot;深&quot;,&quot;入&quot;,&quot;地&quot;,&quot;分&quot;,&quot;析&quot;,&quot;这&quot;,&quot;一&quot;,&quot;次&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;荡&quot;,&quot;荡&quot;,&quot;背&quot;,&quot;后&quot;,&quot;的&quot;,&quot;根&quot;,&quot;源&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.338 s
Real time factor (RTF): 0.338 / 15.289 = 0.022
</pre></div>
</div>
</section>
</section>
<section id="id66">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id66" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./icefall-asr-zipformer-wenetspeech-20230615/data/lang_char/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./icefall-asr-zipformer-wenetspeech-20230615/exp/encoder-epoch-12-avg-4.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./icefall-asr-zipformer-wenetspeech-20230615/exp/decoder-epoch-12-avg-4.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./icefall-asr-zipformer-wenetspeech-20230615/exp/joiner-epoch-12-avg-4.onnx
</pre></div>
</div>
</section>
</section>
<section id="csukuangfj-sherpa-onnx-zipformer-large-en-2023-06-26-english">
<h2>csukuangfj/sherpa-onnx-zipformer-large-en-2023-06-26 (English)<a class="headerlink" href="#csukuangfj-sherpa-onnx-zipformer-large-en-2023-06-26-english" title="Permalink to this heading"></a></h2>
<p>This model is converted from</p>
<p><a class="reference external" href="https://huggingface.co/Zengwei/icefall-asr-librispeech-zipformer-large-2023-05-16">https://huggingface.co/Zengwei/icefall-asr-librispeech-zipformer-large-2023-05-16</a></p>
<p>which supports only English as it is trained on the <a class="reference external" href="https://www.openslr.org/12">LibriSpeech</a> corpus.</p>
<p>You can find the training code at</p>
<p><a class="reference external" href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/zipformer">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/zipformer</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id67">
<h3>Download the model<a class="headerlink" href="#id67" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-large-en-2023-06-26.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-zipformer-large-en-2023-06-26.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-large-en-2023-06-26.tar.bz2
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sherpa-onnx-zipformer-large-en-2023-06-26<span class="w"> </span>fangjun$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.2M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">13</span>:19<span class="w"> </span>decoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.0M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">13</span>:19<span class="w"> </span>decoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>145M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">13</span>:20<span class="w"> </span>encoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>564M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">13</span>:22<span class="w"> </span>encoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>253K<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">13</span>:19<span class="w"> </span>joiner-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.0M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">13</span>:19<span class="w"> </span>joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
<section id="id68">
<h3>Decode wave files<a class="headerlink" href="#id68" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id69">
<h4>fp32<a class="headerlink" href="#id69" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-large-en-2023-06-26/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-large-en-2023-06-26/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-large-en-2023-06-26/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-large-en-2023-06-26/joiner-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-large-en-2023-06-26/tokens.txt --encoder=./sherpa-onnx-zipformer-large-en-2023-06-26/encoder-epoch-99-avg-1.onnx --decoder=./sherpa-onnx-zipformer-large-en-2023-06-26/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-zipformer-large-en-2023-06-26/joiner-epoch-99-avg-1.onnx ./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/0.wav ./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/1.wav ./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/8k.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-large-en-2023-06-26/encoder-epoch-99-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-large-en-2023-06-26/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-large-en-2023-06-26/joiner-epoch-99-avg-1.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-large-en-2023-06-26/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, context_score=1.5)
Creating recognizer ...
Started
/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:108 Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/0.wav
{&quot;text&quot;:&quot; AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.48, 0.60, 0.72, 1.04, 1.28, 1.36, 1.48, 1.60, 1.84, 1.96, 2.00, 2.16, 2.32, 2.40, 2.48, 2.60, 2.80, 3.04, 3.28, 3.40, 3.56, 3.76, 4.04, 4.24, 4.28, 4.48, 4.64, 4.80, 4.84, 5.00, 5.04, 5.28, 5.40, 5.56, 5.60, 5.76, 5.96, 6.16]&quot;,&quot;tokens&quot;:[&quot; AFTER&quot;,&quot; E&quot;,&quot;AR&quot;,&quot;LY&quot;,&quot; NIGHT&quot;,&quot;F&quot;,&quot;A&quot;,&quot;LL&quot;,&quot; THE&quot;,&quot; YE&quot;,&quot;LL&quot;,&quot;OW&quot;,&quot; LA&quot;,&quot;M&quot;,&quot;P&quot;,&quot;S&quot;,&quot; WOULD&quot;,&quot; LIGHT&quot;,&quot; UP&quot;,&quot; HE&quot;,&quot;RE&quot;,&quot; AND&quot;,&quot; THERE&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;QUA&quot;,&quot;LI&quot;,&quot;D&quot;,&quot; &quot;,&quot;QUA&quot;,&quot;R&quot;,&quot;TER&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; B&quot;,&quot;RO&quot;,&quot;TH&quot;,&quot;EL&quot;,&quot;S&quot;]}
----
./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/1.wav
{&quot;text&quot;:&quot; GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.20, 0.48, 0.72, 0.88, 1.04, 1.12, 1.20, 1.36, 1.52, 1.68, 1.84, 1.88, 2.00, 2.12, 2.32, 2.36, 2.60, 2.84, 3.12, 3.24, 3.48, 3.56, 3.76, 3.92, 4.12, 4.36, 4.56, 4.72, 4.96, 5.16, 5.44, 5.68, 6.12, 6.28, 6.48, 6.88, 7.12, 7.36, 7.56, 7.92, 8.16, 8.28, 8.40, 8.48, 8.60, 8.76, 8.88, 9.08, 9.28, 9.44, 9.52, 9.60, 9.72, 9.92, 10.00, 10.12, 10.48, 10.68, 10.76, 11.00, 11.20, 11.36, 11.56, 11.76, 12.00, 12.12, 12.28, 12.32, 12.52, 12.72, 12.84, 12.92, 13.04, 13.20, 13.44, 13.64, 13.76, 14.00, 14.12, 14.24, 14.36, 14.52, 14.72, 14.80, 15.04, 15.28, 15.52, 15.76, 16.00, 16.20, 16.24, 16.32]&quot;,&quot;tokens&quot;:[&quot; GO&quot;,&quot;D&quot;,&quot; AS&quot;,&quot; A&quot;,&quot; DI&quot;,&quot;RE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; CON&quot;,&quot;SE&quot;,&quot;QUE&quot;,&quot;N&quot;,&quot;CE&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;IN&quot;,&quot; WHICH&quot;,&quot; MAN&quot;,&quot; TH&quot;,&quot;US&quot;,&quot; P&quot;,&quot;UN&quot;,&quot;ISH&quot;,&quot;ED&quot;,&quot; HAD&quot;,&quot; GIVE&quot;,&quot;N&quot;,&quot; HER&quot;,&quot; A&quot;,&quot; LOVE&quot;,&quot;LY&quot;,&quot; CHILD&quot;,&quot; WHO&quot;,&quot;SE&quot;,&quot; PLACE&quot;,&quot; WAS&quot;,&quot; ON&quot;,&quot; THAT&quot;,&quot; SAME&quot;,&quot; DIS&quot;,&quot;HO&quot;,&quot;N&quot;,&quot;OR&quot;,&quot;ED&quot;,&quot; BO&quot;,&quot;S&quot;,&quot;OM&quot;,&quot; TO&quot;,&quot; CON&quot;,&quot;NE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; HER&quot;,&quot; P&quot;,&quot;AR&quot;,&quot;ENT&quot;,&quot; FOR&quot;,&quot; E&quot;,&quot;VER&quot;,&quot; WITH&quot;,&quot; THE&quot;,&quot; RA&quot;,&quot;CE&quot;,&quot; AND&quot;,&quot; DE&quot;,&quot;S&quot;,&quot;C&quot;,&quot;ENT&quot;,&quot; OF&quot;,&quot; MO&quot;,&quot;R&quot;,&quot;T&quot;,&quot;AL&quot;,&quot;S&quot;,&quot; AND&quot;,&quot; TO&quot;,&quot; BE&quot;,&quot; FI&quot;,&quot;N&quot;,&quot;AL&quot;,&quot;LY&quot;,&quot; A&quot;,&quot; B&quot;,&quot;LESS&quot;,&quot;ED&quot;,&quot; SO&quot;,&quot;UL&quot;,&quot; IN&quot;,&quot; HE&quot;,&quot;A&quot;,&quot;VE&quot;,&quot;N&quot;]}
----
./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/8k.wav
{&quot;text&quot;:&quot; YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.36, 0.48, 0.76, 0.96, 1.12, 1.24, 1.32, 1.44, 1.48, 1.68, 1.76, 1.88, 2.04, 2.12, 2.24, 2.28, 2.48, 2.56, 2.80, 3.08, 3.28, 3.52, 3.80, 3.92, 4.00, 4.16, 4.24, 4.36, 4.44]&quot;,&quot;tokens&quot;:[&quot; YE&quot;,&quot;T&quot;,&quot; THE&quot;,&quot;SE&quot;,&quot; THOUGHT&quot;,&quot;S&quot;,&quot; A&quot;,&quot;FF&quot;,&quot;E&quot;,&quot;C&quot;,&quot;TED&quot;,&quot; HE&quot;,&quot;S&quot;,&quot;TER&quot;,&quot; P&quot;,&quot;RY&quot;,&quot;N&quot;,&quot;NE&quot;,&quot; &quot;,&quot;LESS&quot;,&quot; WITH&quot;,&quot; HO&quot;,&quot;PE&quot;,&quot; THAN&quot;,&quot; A&quot;,&quot;PP&quot;,&quot;RE&quot;,&quot;HE&quot;,&quot;N&quot;,&quot;S&quot;,&quot;ION&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.843 s
Real time factor (RTF): 1.843 / 28.165 = 0.065
</pre></div>
</div>
</section>
<section id="id70">
<h4>int8<a class="headerlink" href="#id70" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-large-en-2023-06-26/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-large-en-2023-06-26/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-large-en-2023-06-26/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-large-en-2023-06-26/joiner-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-large-en-2023-06-26/tokens.txt --encoder=./sherpa-onnx-zipformer-large-en-2023-06-26/encoder-epoch-99-avg-1.int8.onnx --decoder=./sherpa-onnx-zipformer-large-en-2023-06-26/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-zipformer-large-en-2023-06-26/joiner-epoch-99-avg-1.int8.onnx ./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/0.wav ./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/1.wav ./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/8k.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-large-en-2023-06-26/encoder-epoch-99-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-large-en-2023-06-26/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-large-en-2023-06-26/joiner-epoch-99-avg-1.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-large-en-2023-06-26/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, context_score=1.5)
Creating recognizer ...
Started
/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:108 Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/0.wav
{&quot;text&quot;:&quot; AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.48, 0.60, 0.72, 1.04, 1.28, 1.36, 1.48, 1.60, 1.84, 1.96, 2.00, 2.16, 2.32, 2.40, 2.48, 2.60, 2.80, 3.04, 3.28, 3.40, 3.56, 3.76, 4.04, 4.24, 4.28, 4.48, 4.64, 4.80, 4.84, 5.00, 5.04, 5.28, 5.40, 5.56, 5.60, 5.76, 5.96, 6.16]&quot;,&quot;tokens&quot;:[&quot; AFTER&quot;,&quot; E&quot;,&quot;AR&quot;,&quot;LY&quot;,&quot; NIGHT&quot;,&quot;F&quot;,&quot;A&quot;,&quot;LL&quot;,&quot; THE&quot;,&quot; YE&quot;,&quot;LL&quot;,&quot;OW&quot;,&quot; LA&quot;,&quot;M&quot;,&quot;P&quot;,&quot;S&quot;,&quot; WOULD&quot;,&quot; LIGHT&quot;,&quot; UP&quot;,&quot; HE&quot;,&quot;RE&quot;,&quot; AND&quot;,&quot; THERE&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;QUA&quot;,&quot;LI&quot;,&quot;D&quot;,&quot; &quot;,&quot;QUA&quot;,&quot;R&quot;,&quot;TER&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; B&quot;,&quot;RO&quot;,&quot;TH&quot;,&quot;EL&quot;,&quot;S&quot;]}
----
./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/1.wav
{&quot;text&quot;:&quot; GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.20, 0.48, 0.72, 0.88, 1.04, 1.12, 1.20, 1.36, 1.52, 1.64, 1.84, 1.88, 2.00, 2.12, 2.32, 2.36, 2.60, 2.84, 3.12, 3.24, 3.48, 3.56, 3.76, 3.92, 4.12, 4.36, 4.52, 4.72, 4.96, 5.16, 5.44, 5.68, 6.12, 6.28, 6.48, 6.88, 7.12, 7.36, 7.56, 7.92, 8.16, 8.28, 8.40, 8.48, 8.60, 8.76, 8.88, 9.08, 9.28, 9.44, 9.52, 9.60, 9.72, 9.92, 10.00, 10.12, 10.48, 10.68, 10.76, 11.00, 11.20, 11.36, 11.56, 11.76, 12.00, 12.12, 12.28, 12.32, 12.52, 12.72, 12.84, 12.92, 13.04, 13.20, 13.44, 13.64, 13.76, 14.00, 14.08, 14.24, 14.36, 14.52, 14.72, 14.76, 15.04, 15.28, 15.52, 15.76, 16.00, 16.20, 16.24, 16.32]&quot;,&quot;tokens&quot;:[&quot; GO&quot;,&quot;D&quot;,&quot; AS&quot;,&quot; A&quot;,&quot; DI&quot;,&quot;RE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; CON&quot;,&quot;SE&quot;,&quot;QUE&quot;,&quot;N&quot;,&quot;CE&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;IN&quot;,&quot; WHICH&quot;,&quot; MAN&quot;,&quot; TH&quot;,&quot;US&quot;,&quot; P&quot;,&quot;UN&quot;,&quot;ISH&quot;,&quot;ED&quot;,&quot; HAD&quot;,&quot; GIVE&quot;,&quot;N&quot;,&quot; HER&quot;,&quot; A&quot;,&quot; LOVE&quot;,&quot;LY&quot;,&quot; CHILD&quot;,&quot; WHO&quot;,&quot;SE&quot;,&quot; PLACE&quot;,&quot; WAS&quot;,&quot; ON&quot;,&quot; THAT&quot;,&quot; SAME&quot;,&quot; DIS&quot;,&quot;HO&quot;,&quot;N&quot;,&quot;OR&quot;,&quot;ED&quot;,&quot; BO&quot;,&quot;S&quot;,&quot;OM&quot;,&quot; TO&quot;,&quot; CON&quot;,&quot;NE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; HER&quot;,&quot; P&quot;,&quot;AR&quot;,&quot;ENT&quot;,&quot; FOR&quot;,&quot; E&quot;,&quot;VER&quot;,&quot; WITH&quot;,&quot; THE&quot;,&quot; RA&quot;,&quot;CE&quot;,&quot; AND&quot;,&quot; DE&quot;,&quot;S&quot;,&quot;C&quot;,&quot;ENT&quot;,&quot; OF&quot;,&quot; MO&quot;,&quot;R&quot;,&quot;T&quot;,&quot;AL&quot;,&quot;S&quot;,&quot; AND&quot;,&quot; TO&quot;,&quot; BE&quot;,&quot; FI&quot;,&quot;N&quot;,&quot;AL&quot;,&quot;LY&quot;,&quot; A&quot;,&quot; B&quot;,&quot;LESS&quot;,&quot;ED&quot;,&quot; SO&quot;,&quot;UL&quot;,&quot; IN&quot;,&quot; HE&quot;,&quot;A&quot;,&quot;VE&quot;,&quot;N&quot;]}
----
./sherpa-onnx-zipformer-large-en-2023-06-26/test_wavs/8k.wav
{&quot;text&quot;:&quot; YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.36, 0.48, 0.76, 0.96, 1.12, 1.24, 1.32, 1.44, 1.48, 1.68, 1.76, 1.88, 2.04, 2.12, 2.28, 2.32, 2.48, 2.52, 2.80, 3.08, 3.28, 3.52, 3.76, 3.92, 4.00, 4.16, 4.24, 4.36, 4.44]&quot;,&quot;tokens&quot;:[&quot; YE&quot;,&quot;T&quot;,&quot; THE&quot;,&quot;SE&quot;,&quot; THOUGHT&quot;,&quot;S&quot;,&quot; A&quot;,&quot;FF&quot;,&quot;E&quot;,&quot;C&quot;,&quot;TED&quot;,&quot; HE&quot;,&quot;S&quot;,&quot;TER&quot;,&quot; P&quot;,&quot;RY&quot;,&quot;N&quot;,&quot;NE&quot;,&quot; &quot;,&quot;LESS&quot;,&quot; WITH&quot;,&quot; HO&quot;,&quot;PE&quot;,&quot; THAN&quot;,&quot; A&quot;,&quot;PP&quot;,&quot;RE&quot;,&quot;HE&quot;,&quot;N&quot;,&quot;S&quot;,&quot;ION&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.490 s
Real time factor (RTF): 1.490 / 28.165 = 0.053
</pre></div>
</div>
</section>
</section>
<section id="id71">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id71" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-large-en-2023-06-26/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-large-en-2023-06-26/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-large-en-2023-06-26/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-large-en-2023-06-26/joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
</section>
<section id="csukuangfj-sherpa-onnx-zipformer-small-en-2023-06-26-english">
<h2>csukuangfj/sherpa-onnx-zipformer-small-en-2023-06-26 (English)<a class="headerlink" href="#csukuangfj-sherpa-onnx-zipformer-small-en-2023-06-26-english" title="Permalink to this heading"></a></h2>
<p>This model is converted from</p>
<p><a class="reference external" href="https://huggingface.co/Zengwei/icefall-asr-librispeech-zipformer-small-2023-05-16">https://huggingface.co/Zengwei/icefall-asr-librispeech-zipformer-small-2023-05-16</a></p>
<p>which supports only English as it is trained on the <a class="reference external" href="https://www.openslr.org/12">LibriSpeech</a> corpus.</p>
<p>You can find the training code at</p>
<p><a class="reference external" href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/zipformer">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/zipformer</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id73">
<h3>Download the model<a class="headerlink" href="#id73" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-small-en-2023-06-26.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-zipformer-small-en-2023-06-26.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-small-en-2023-06-26.tar.bz2
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sherpa-onnx-zipformer-small-en-2023-06-26<span class="w"> </span>fangjun$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.2M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">13</span>:04<span class="w"> </span>decoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.0M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">13</span>:04<span class="w"> </span>decoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>25M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">13</span>:04<span class="w"> </span>encoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>87M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">13</span>:04<span class="w"> </span>encoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>253K<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">13</span>:04<span class="w"> </span>joiner-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.0M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">13</span>:04<span class="w"> </span>joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
<section id="id74">
<h3>Decode wave files<a class="headerlink" href="#id74" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id75">
<h4>fp32<a class="headerlink" href="#id75" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-small-en-2023-06-26/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-small-en-2023-06-26/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-small-en-2023-06-26/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-small-en-2023-06-26/joiner-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-small-en-2023-06-26/tokens.txt --encoder=./sherpa-onnx-zipformer-small-en-2023-06-26/encoder-epoch-99-avg-1.onnx --decoder=./sherpa-onnx-zipformer-small-en-2023-06-26/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-zipformer-small-en-2023-06-26/joiner-epoch-99-avg-1.onnx ./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/0.wav ./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/1.wav ./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/8k.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-small-en-2023-06-26/encoder-epoch-99-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-small-en-2023-06-26/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-small-en-2023-06-26/joiner-epoch-99-avg-1.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-small-en-2023-06-26/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, context_score=1.5)
Creating recognizer ...
Started
/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:108 Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/0.wav
{&quot;text&quot;:&quot; AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.64, 0.76, 0.84, 1.12, 1.36, 1.44, 1.56, 1.72, 1.84, 1.96, 2.04, 2.20, 2.32, 2.36, 2.44, 2.60, 2.76, 3.04, 3.24, 3.40, 3.52, 3.72, 4.04, 4.20, 4.28, 4.48, 4.64, 4.80, 4.84, 4.96, 5.00, 5.28, 5.40, 5.52, 5.60, 5.76, 5.92, 6.08]&quot;,&quot;tokens&quot;:[&quot; AFTER&quot;,&quot; E&quot;,&quot;AR&quot;,&quot;LY&quot;,&quot; NIGHT&quot;,&quot;F&quot;,&quot;A&quot;,&quot;LL&quot;,&quot; THE&quot;,&quot; YE&quot;,&quot;LL&quot;,&quot;OW&quot;,&quot; LA&quot;,&quot;M&quot;,&quot;P&quot;,&quot;S&quot;,&quot; WOULD&quot;,&quot; LIGHT&quot;,&quot; UP&quot;,&quot; HE&quot;,&quot;RE&quot;,&quot; AND&quot;,&quot; THERE&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;QUA&quot;,&quot;LI&quot;,&quot;D&quot;,&quot; &quot;,&quot;QUA&quot;,&quot;R&quot;,&quot;TER&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; B&quot;,&quot;RO&quot;,&quot;TH&quot;,&quot;EL&quot;,&quot;S&quot;]}
----
./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/1.wav
{&quot;text&quot;:&quot; GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONOURED BOSOM TO CONNECT HER PARENT FOREVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.32, 0.64, 0.80, 0.96, 1.08, 1.16, 1.20, 1.32, 1.52, 1.68, 1.80, 1.88, 2.04, 2.16, 2.32, 2.40, 2.64, 2.88, 3.16, 3.20, 3.44, 3.52, 3.72, 3.88, 4.16, 4.44, 4.60, 4.76, 4.96, 5.16, 5.36, 5.60, 6.16, 6.32, 6.52, 6.88, 7.16, 7.32, 7.60, 7.96, 8.16, 8.28, 8.36, 8.48, 8.64, 8.76, 8.84, 9.04, 9.28, 9.44, 9.52, 9.60, 9.68, 9.88, 9.92, 10.12, 10.52, 10.76, 10.80, 11.08, 11.20, 11.36, 11.56, 11.76, 11.96, 12.08, 12.24, 12.28, 12.48, 12.68, 12.80, 12.92, 13.00, 13.20, 13.48, 13.72, 13.84, 14.04, 14.20, 14.28, 14.40, 14.56, 14.68, 14.76, 15.00, 15.24, 15.48, 15.68, 15.92, 16.08, 16.12, 16.20]&quot;,&quot;tokens&quot;:[&quot; GO&quot;,&quot;D&quot;,&quot; AS&quot;,&quot; A&quot;,&quot; DI&quot;,&quot;RE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; CON&quot;,&quot;SE&quot;,&quot;QUE&quot;,&quot;N&quot;,&quot;CE&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;IN&quot;,&quot; WHICH&quot;,&quot; MAN&quot;,&quot; TH&quot;,&quot;US&quot;,&quot; P&quot;,&quot;UN&quot;,&quot;ISH&quot;,&quot;ED&quot;,&quot; HAD&quot;,&quot; GIVE&quot;,&quot;N&quot;,&quot; HER&quot;,&quot; A&quot;,&quot; LOVE&quot;,&quot;LY&quot;,&quot; CHILD&quot;,&quot; WHO&quot;,&quot;SE&quot;,&quot; PLACE&quot;,&quot; WAS&quot;,&quot; ON&quot;,&quot; THAT&quot;,&quot; SAME&quot;,&quot; DIS&quot;,&quot;HO&quot;,&quot;N&quot;,&quot;OUR&quot;,&quot;ED&quot;,&quot; BO&quot;,&quot;S&quot;,&quot;OM&quot;,&quot; TO&quot;,&quot; CON&quot;,&quot;NE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; HER&quot;,&quot; P&quot;,&quot;AR&quot;,&quot;ENT&quot;,&quot; FOR&quot;,&quot;E&quot;,&quot;VER&quot;,&quot; WITH&quot;,&quot; THE&quot;,&quot; RA&quot;,&quot;CE&quot;,&quot; AND&quot;,&quot; DE&quot;,&quot;S&quot;,&quot;C&quot;,&quot;ENT&quot;,&quot; OF&quot;,&quot; MO&quot;,&quot;R&quot;,&quot;T&quot;,&quot;AL&quot;,&quot;S&quot;,&quot; AND&quot;,&quot; TO&quot;,&quot; BE&quot;,&quot; FI&quot;,&quot;N&quot;,&quot;AL&quot;,&quot;LY&quot;,&quot; A&quot;,&quot; B&quot;,&quot;LESS&quot;,&quot;ED&quot;,&quot; SO&quot;,&quot;UL&quot;,&quot; IN&quot;,&quot; HE&quot;,&quot;A&quot;,&quot;VE&quot;,&quot;N&quot;]}
----
./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/8k.wav
{&quot;text&quot;:&quot; YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.32, 0.48, 0.64, 0.84, 1.08, 1.20, 1.32, 1.36, 1.44, 1.48, 1.64, 1.76, 1.88, 2.08, 2.12, 2.24, 2.28, 2.44, 2.48, 2.80, 3.04, 3.24, 3.48, 3.72, 3.88, 3.92, 4.08, 4.16, 4.24, 4.36]&quot;,&quot;tokens&quot;:[&quot; YE&quot;,&quot;T&quot;,&quot; THE&quot;,&quot;SE&quot;,&quot; THOUGHT&quot;,&quot;S&quot;,&quot; A&quot;,&quot;FF&quot;,&quot;E&quot;,&quot;C&quot;,&quot;TED&quot;,&quot; HE&quot;,&quot;S&quot;,&quot;TER&quot;,&quot; P&quot;,&quot;RY&quot;,&quot;N&quot;,&quot;NE&quot;,&quot; &quot;,&quot;LESS&quot;,&quot; WITH&quot;,&quot; HO&quot;,&quot;PE&quot;,&quot; THAN&quot;,&quot; A&quot;,&quot;PP&quot;,&quot;RE&quot;,&quot;HE&quot;,&quot;N&quot;,&quot;S&quot;,&quot;ION&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.953 s
Real time factor (RTF): 0.953 / 28.165 = 0.034
</pre></div>
</div>
</section>
<section id="id76">
<h4>int8<a class="headerlink" href="#id76" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-small-en-2023-06-26/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-small-en-2023-06-26/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-small-en-2023-06-26/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-small-en-2023-06-26/joiner-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-small-en-2023-06-26/tokens.txt --encoder=./sherpa-onnx-zipformer-small-en-2023-06-26/encoder-epoch-99-avg-1.int8.onnx --decoder=./sherpa-onnx-zipformer-small-en-2023-06-26/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-zipformer-small-en-2023-06-26/joiner-epoch-99-avg-1.int8.onnx ./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/0.wav ./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/1.wav ./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/8k.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-small-en-2023-06-26/encoder-epoch-99-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-small-en-2023-06-26/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-small-en-2023-06-26/joiner-epoch-99-avg-1.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-small-en-2023-06-26/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, context_score=1.5)
Creating recognizer ...
Started
/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:108 Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/0.wav
{&quot;text&quot;:&quot; AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.64, 0.76, 0.84, 1.08, 1.36, 1.44, 1.56, 1.72, 1.84, 1.96, 2.04, 2.20, 2.32, 2.36, 2.44, 2.60, 2.76, 3.04, 3.24, 3.40, 3.52, 3.72, 4.00, 4.20, 4.28, 4.48, 4.64, 4.80, 4.84, 4.96, 5.00, 5.28, 5.40, 5.52, 5.60, 5.76, 5.92, 6.08]&quot;,&quot;tokens&quot;:[&quot; AFTER&quot;,&quot; E&quot;,&quot;AR&quot;,&quot;LY&quot;,&quot; NIGHT&quot;,&quot;F&quot;,&quot;A&quot;,&quot;LL&quot;,&quot; THE&quot;,&quot; YE&quot;,&quot;LL&quot;,&quot;OW&quot;,&quot; LA&quot;,&quot;M&quot;,&quot;P&quot;,&quot;S&quot;,&quot; WOULD&quot;,&quot; LIGHT&quot;,&quot; UP&quot;,&quot; HE&quot;,&quot;RE&quot;,&quot; AND&quot;,&quot; THERE&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;QUA&quot;,&quot;LI&quot;,&quot;D&quot;,&quot; &quot;,&quot;QUA&quot;,&quot;R&quot;,&quot;TER&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; B&quot;,&quot;RO&quot;,&quot;TH&quot;,&quot;EL&quot;,&quot;S&quot;]}
----
./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/1.wav
{&quot;text&quot;:&quot; GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONOURED BOSOM TO CONNECT HER PARENT FOREVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.32, 0.64, 0.80, 0.96, 1.08, 1.16, 1.20, 1.32, 1.52, 1.68, 1.80, 1.88, 2.04, 2.16, 2.32, 2.40, 2.64, 2.88, 3.16, 3.20, 3.44, 3.52, 3.72, 3.88, 4.16, 4.44, 4.60, 4.76, 4.96, 5.16, 5.36, 5.60, 6.16, 6.32, 6.52, 6.88, 7.16, 7.32, 7.60, 7.96, 8.16, 8.28, 8.36, 8.48, 8.64, 8.76, 8.84, 9.04, 9.28, 9.44, 9.52, 9.60, 9.68, 9.88, 9.92, 10.12, 10.52, 10.76, 10.80, 11.08, 11.20, 11.36, 11.56, 11.76, 11.96, 12.08, 12.24, 12.28, 12.48, 12.68, 12.80, 12.92, 13.04, 13.16, 13.48, 13.72, 13.84, 14.04, 14.20, 14.28, 14.40, 14.56, 14.68, 14.76, 15.00, 15.28, 15.48, 15.68, 15.92, 16.08, 16.12, 16.20]&quot;,&quot;tokens&quot;:[&quot; GO&quot;,&quot;D&quot;,&quot; AS&quot;,&quot; A&quot;,&quot; DI&quot;,&quot;RE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; CON&quot;,&quot;SE&quot;,&quot;QUE&quot;,&quot;N&quot;,&quot;CE&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;IN&quot;,&quot; WHICH&quot;,&quot; MAN&quot;,&quot; TH&quot;,&quot;US&quot;,&quot; P&quot;,&quot;UN&quot;,&quot;ISH&quot;,&quot;ED&quot;,&quot; HAD&quot;,&quot; GIVE&quot;,&quot;N&quot;,&quot; HER&quot;,&quot; A&quot;,&quot; LOVE&quot;,&quot;LY&quot;,&quot; CHILD&quot;,&quot; WHO&quot;,&quot;SE&quot;,&quot; PLACE&quot;,&quot; WAS&quot;,&quot; ON&quot;,&quot; THAT&quot;,&quot; SAME&quot;,&quot; DIS&quot;,&quot;HO&quot;,&quot;N&quot;,&quot;OUR&quot;,&quot;ED&quot;,&quot; BO&quot;,&quot;S&quot;,&quot;OM&quot;,&quot; TO&quot;,&quot; CON&quot;,&quot;NE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; HER&quot;,&quot; P&quot;,&quot;AR&quot;,&quot;ENT&quot;,&quot; FOR&quot;,&quot;E&quot;,&quot;VER&quot;,&quot; WITH&quot;,&quot; THE&quot;,&quot; RA&quot;,&quot;CE&quot;,&quot; AND&quot;,&quot; DE&quot;,&quot;S&quot;,&quot;C&quot;,&quot;ENT&quot;,&quot; OF&quot;,&quot; MO&quot;,&quot;R&quot;,&quot;T&quot;,&quot;AL&quot;,&quot;S&quot;,&quot; AND&quot;,&quot; TO&quot;,&quot; BE&quot;,&quot; FI&quot;,&quot;N&quot;,&quot;AL&quot;,&quot;LY&quot;,&quot; A&quot;,&quot; B&quot;,&quot;LESS&quot;,&quot;ED&quot;,&quot; SO&quot;,&quot;UL&quot;,&quot; IN&quot;,&quot; HE&quot;,&quot;A&quot;,&quot;VE&quot;,&quot;N&quot;]}
----
./sherpa-onnx-zipformer-small-en-2023-06-26/test_wavs/8k.wav
{&quot;text&quot;:&quot; YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.32, 0.48, 0.64, 0.84, 1.08, 1.20, 1.32, 1.36, 1.44, 1.48, 1.64, 1.76, 1.88, 2.08, 2.12, 2.24, 2.28, 2.44, 2.48, 2.80, 3.04, 3.24, 3.48, 3.72, 3.88, 3.92, 4.08, 4.16, 4.24, 4.36]&quot;,&quot;tokens&quot;:[&quot; YE&quot;,&quot;T&quot;,&quot; THE&quot;,&quot;SE&quot;,&quot; THOUGHT&quot;,&quot;S&quot;,&quot; A&quot;,&quot;FF&quot;,&quot;E&quot;,&quot;C&quot;,&quot;TED&quot;,&quot; HE&quot;,&quot;S&quot;,&quot;TER&quot;,&quot; P&quot;,&quot;RY&quot;,&quot;N&quot;,&quot;NE&quot;,&quot; &quot;,&quot;LESS&quot;,&quot; WITH&quot;,&quot; HO&quot;,&quot;PE&quot;,&quot; THAN&quot;,&quot; A&quot;,&quot;PP&quot;,&quot;RE&quot;,&quot;HE&quot;,&quot;N&quot;,&quot;S&quot;,&quot;ION&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.891 s
Real time factor (RTF): 0.891 / 28.165 = 0.032
</pre></div>
</div>
</section>
</section>
<section id="id77">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id77" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-small-en-2023-06-26/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-small-en-2023-06-26/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-small-en-2023-06-26/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-small-en-2023-06-26/joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
</section>
<section id="csukuangfj-sherpa-onnx-zipformer-en-2023-06-26-english">
<span id="sherpa-onnx-zipformer-en-2023-06-26-english"></span><h2>csukuangfj/sherpa-onnx-zipformer-en-2023-06-26 (English)<a class="headerlink" href="#csukuangfj-sherpa-onnx-zipformer-en-2023-06-26-english" title="Permalink to this heading"></a></h2>
<p>This model is converted from</p>
<p><a class="reference external" href="https://huggingface.co/Zengwei/icefall-asr-librispeech-zipformer-2023-05-15">https://huggingface.co/Zengwei/icefall-asr-librispeech-zipformer-2023-05-15</a></p>
<p>which supports only English as it is trained on the <a class="reference external" href="https://www.openslr.org/12">LibriSpeech</a> corpus.</p>
<p>You can find the training code at</p>
<p><a class="reference external" href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/zipformer">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/zipformer</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id79">
<h3>Download the model<a class="headerlink" href="#id79" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-en-2023-06-26.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-zipformer-en-2023-06-26.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-en-2023-06-26.tar.bz2
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sherpa-onnx-zipformer-en-2023-06-26<span class="w"> </span>fangjun$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.2M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">12</span>:45<span class="w"> </span>decoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.0M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">12</span>:45<span class="w"> </span>decoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>66M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">12</span>:45<span class="w"> </span>encoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>248M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">12</span>:46<span class="w"> </span>encoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>253K<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">12</span>:45<span class="w"> </span>joiner-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.0M<span class="w"> </span>Jun<span class="w"> </span><span class="m">26</span><span class="w"> </span><span class="m">12</span>:45<span class="w"> </span>joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
<section id="id80">
<h3>Decode wave files<a class="headerlink" href="#id80" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id81">
<h4>fp32<a class="headerlink" href="#id81" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-06-26/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-06-26/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-06-26/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-06-26/joiner-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-en-2023-06-26/tokens.txt --encoder=./sherpa-onnx-zipformer-en-2023-06-26/encoder-epoch-99-avg-1.onnx --decoder=./sherpa-onnx-zipformer-en-2023-06-26/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-zipformer-en-2023-06-26/joiner-epoch-99-avg-1.onnx ./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/0.wav ./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/1.wav ./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/8k.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-en-2023-06-26/encoder-epoch-99-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-en-2023-06-26/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-en-2023-06-26/joiner-epoch-99-avg-1.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-en-2023-06-26/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, context_score=1.5)
Creating recognizer ...
Started
/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:108 Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/0.wav
{&quot;text&quot;:&quot; AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.56, 0.64, 0.80, 1.08, 1.36, 1.40, 1.52, 1.68, 1.84, 1.96, 2.04, 2.20, 2.32, 2.40, 2.48, 2.60, 2.80, 3.04, 3.28, 3.40, 3.56, 3.76, 4.08, 4.24, 4.32, 4.48, 4.64, 4.80, 4.84, 5.00, 5.04, 5.28, 5.40, 5.56, 5.60, 5.76, 5.96, 6.12]&quot;,&quot;tokens&quot;:[&quot; AFTER&quot;,&quot; E&quot;,&quot;AR&quot;,&quot;LY&quot;,&quot; NIGHT&quot;,&quot;F&quot;,&quot;A&quot;,&quot;LL&quot;,&quot; THE&quot;,&quot; YE&quot;,&quot;LL&quot;,&quot;OW&quot;,&quot; LA&quot;,&quot;M&quot;,&quot;P&quot;,&quot;S&quot;,&quot; WOULD&quot;,&quot; LIGHT&quot;,&quot; UP&quot;,&quot; HE&quot;,&quot;RE&quot;,&quot; AND&quot;,&quot; THERE&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;QUA&quot;,&quot;LI&quot;,&quot;D&quot;,&quot; &quot;,&quot;QUA&quot;,&quot;R&quot;,&quot;TER&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; B&quot;,&quot;RO&quot;,&quot;TH&quot;,&quot;EL&quot;,&quot;S&quot;]}
----
./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/1.wav
{&quot;text&quot;:&quot; GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOREVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.24, 0.56, 0.76, 0.92, 1.04, 1.16, 1.20, 1.36, 1.52, 1.64, 1.80, 1.88, 2.00, 2.16, 2.32, 2.40, 2.64, 2.88, 3.12, 3.24, 3.48, 3.56, 3.72, 3.92, 4.12, 4.40, 4.52, 4.72, 4.96, 5.16, 5.36, 5.64, 6.12, 6.28, 6.52, 6.88, 7.12, 7.32, 7.56, 7.92, 8.16, 8.28, 8.40, 8.48, 8.64, 8.76, 8.88, 9.04, 9.28, 9.44, 9.52, 9.60, 9.72, 9.92, 9.96, 10.16, 10.48, 10.72, 10.80, 11.04, 11.20, 11.36, 11.56, 11.76, 12.00, 12.12, 12.28, 12.32, 12.52, 12.72, 12.84, 12.92, 13.04, 13.20, 13.44, 13.68, 13.84, 14.00, 14.16, 14.28, 14.40, 14.56, 14.72, 14.76, 15.00, 15.28, 15.48, 15.68, 15.96, 16.16, 16.20, 16.28]&quot;,&quot;tokens&quot;:[&quot; GO&quot;,&quot;D&quot;,&quot; AS&quot;,&quot; A&quot;,&quot; DI&quot;,&quot;RE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; CON&quot;,&quot;SE&quot;,&quot;QUE&quot;,&quot;N&quot;,&quot;CE&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;IN&quot;,&quot; WHICH&quot;,&quot; MAN&quot;,&quot; TH&quot;,&quot;US&quot;,&quot; P&quot;,&quot;UN&quot;,&quot;ISH&quot;,&quot;ED&quot;,&quot; HAD&quot;,&quot; GIVE&quot;,&quot;N&quot;,&quot; HER&quot;,&quot; A&quot;,&quot; LOVE&quot;,&quot;LY&quot;,&quot; CHILD&quot;,&quot; WHO&quot;,&quot;SE&quot;,&quot; PLACE&quot;,&quot; WAS&quot;,&quot; ON&quot;,&quot; THAT&quot;,&quot; SAME&quot;,&quot; DIS&quot;,&quot;HO&quot;,&quot;N&quot;,&quot;OR&quot;,&quot;ED&quot;,&quot; BO&quot;,&quot;S&quot;,&quot;OM&quot;,&quot; TO&quot;,&quot; CON&quot;,&quot;NE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; HER&quot;,&quot; P&quot;,&quot;AR&quot;,&quot;ENT&quot;,&quot; FOR&quot;,&quot;E&quot;,&quot;VER&quot;,&quot; WITH&quot;,&quot; THE&quot;,&quot; RA&quot;,&quot;CE&quot;,&quot; AND&quot;,&quot; DE&quot;,&quot;S&quot;,&quot;C&quot;,&quot;ENT&quot;,&quot; OF&quot;,&quot; MO&quot;,&quot;R&quot;,&quot;T&quot;,&quot;AL&quot;,&quot;S&quot;,&quot; AND&quot;,&quot; TO&quot;,&quot; BE&quot;,&quot; FI&quot;,&quot;N&quot;,&quot;AL&quot;,&quot;LY&quot;,&quot; A&quot;,&quot; B&quot;,&quot;LESS&quot;,&quot;ED&quot;,&quot; SO&quot;,&quot;UL&quot;,&quot; IN&quot;,&quot; HE&quot;,&quot;A&quot;,&quot;VE&quot;,&quot;N&quot;]}
----
./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/8k.wav
{&quot;text&quot;:&quot; YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.24, 0.40, 0.60, 0.80, 1.04, 1.16, 1.28, 1.36, 1.44, 1.48, 1.68, 1.76, 1.88, 2.00, 2.12, 2.24, 2.28, 2.48, 2.52, 2.80, 3.08, 3.28, 3.52, 3.68, 3.84, 3.96, 4.12, 4.20, 4.32, 4.44]&quot;,&quot;tokens&quot;:[&quot; YE&quot;,&quot;T&quot;,&quot; THE&quot;,&quot;SE&quot;,&quot; THOUGHT&quot;,&quot;S&quot;,&quot; A&quot;,&quot;FF&quot;,&quot;E&quot;,&quot;C&quot;,&quot;TED&quot;,&quot; HE&quot;,&quot;S&quot;,&quot;TER&quot;,&quot; P&quot;,&quot;RY&quot;,&quot;N&quot;,&quot;NE&quot;,&quot; &quot;,&quot;LESS&quot;,&quot; WITH&quot;,&quot; HO&quot;,&quot;PE&quot;,&quot; THAN&quot;,&quot; A&quot;,&quot;PP&quot;,&quot;RE&quot;,&quot;HE&quot;,&quot;N&quot;,&quot;S&quot;,&quot;ION&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.301 s
Real time factor (RTF): 1.301 / 28.165 = 0.046
</pre></div>
</div>
</section>
<section id="id82">
<h4>int8<a class="headerlink" href="#id82" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-06-26/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-06-26/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-06-26/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-06-26/joiner-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-zipformer-en-2023-06-26/tokens.txt --encoder=./sherpa-onnx-zipformer-en-2023-06-26/encoder-epoch-99-avg-1.int8.onnx --decoder=./sherpa-onnx-zipformer-en-2023-06-26/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-zipformer-en-2023-06-26/joiner-epoch-99-avg-1.int8.onnx ./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/0.wav ./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/1.wav ./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/8k.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-en-2023-06-26/encoder-epoch-99-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-en-2023-06-26/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-en-2023-06-26/joiner-epoch-99-avg-1.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-en-2023-06-26/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, context_score=1.5)
Creating recognizer ...
Started
/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:108 Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/0.wav
{&quot;text&quot;:&quot; AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.56, 0.64, 0.80, 1.08, 1.36, 1.40, 1.52, 1.68, 1.84, 1.96, 2.04, 2.20, 2.32, 2.40, 2.48, 2.60, 2.76, 3.04, 3.28, 3.40, 3.56, 3.76, 4.08, 4.24, 4.32, 4.48, 4.64, 4.80, 4.84, 5.00, 5.04, 5.28, 5.40, 5.56, 5.60, 5.76, 5.96, 6.12]&quot;,&quot;tokens&quot;:[&quot; AFTER&quot;,&quot; E&quot;,&quot;AR&quot;,&quot;LY&quot;,&quot; NIGHT&quot;,&quot;F&quot;,&quot;A&quot;,&quot;LL&quot;,&quot; THE&quot;,&quot; YE&quot;,&quot;LL&quot;,&quot;OW&quot;,&quot; LA&quot;,&quot;M&quot;,&quot;P&quot;,&quot;S&quot;,&quot; WOULD&quot;,&quot; LIGHT&quot;,&quot; UP&quot;,&quot; HE&quot;,&quot;RE&quot;,&quot; AND&quot;,&quot; THERE&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;QUA&quot;,&quot;LI&quot;,&quot;D&quot;,&quot; &quot;,&quot;QUA&quot;,&quot;R&quot;,&quot;TER&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; B&quot;,&quot;RO&quot;,&quot;TH&quot;,&quot;EL&quot;,&quot;S&quot;]}
----
./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/1.wav
{&quot;text&quot;:&quot; GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOREVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.24, 0.56, 0.76, 0.92, 1.04, 1.16, 1.20, 1.36, 1.52, 1.64, 1.80, 1.88, 2.00, 2.16, 2.32, 2.40, 2.64, 2.88, 3.12, 3.24, 3.48, 3.56, 3.72, 3.92, 4.12, 4.40, 4.52, 4.72, 4.96, 5.12, 5.40, 5.64, 6.12, 6.28, 6.52, 6.88, 7.12, 7.32, 7.60, 7.92, 8.16, 8.28, 8.40, 8.48, 8.64, 8.76, 8.88, 9.04, 9.28, 9.44, 9.52, 9.60, 9.72, 9.92, 9.96, 10.16, 10.48, 10.72, 10.80, 11.04, 11.20, 11.36, 11.56, 11.76, 12.00, 12.12, 12.28, 12.32, 12.52, 12.72, 12.84, 12.92, 13.04, 13.20, 13.44, 13.68, 13.84, 14.00, 14.16, 14.28, 14.40, 14.56, 14.72, 14.76, 15.00, 15.28, 15.48, 15.68, 15.96, 16.16, 16.20, 16.28]&quot;,&quot;tokens&quot;:[&quot; GO&quot;,&quot;D&quot;,&quot; AS&quot;,&quot; A&quot;,&quot; DI&quot;,&quot;RE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; CON&quot;,&quot;SE&quot;,&quot;QUE&quot;,&quot;N&quot;,&quot;CE&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;IN&quot;,&quot; WHICH&quot;,&quot; MAN&quot;,&quot; TH&quot;,&quot;US&quot;,&quot; P&quot;,&quot;UN&quot;,&quot;ISH&quot;,&quot;ED&quot;,&quot; HAD&quot;,&quot; GIVE&quot;,&quot;N&quot;,&quot; HER&quot;,&quot; A&quot;,&quot; LOVE&quot;,&quot;LY&quot;,&quot; CHILD&quot;,&quot; WHO&quot;,&quot;SE&quot;,&quot; PLACE&quot;,&quot; WAS&quot;,&quot; ON&quot;,&quot; THAT&quot;,&quot; SAME&quot;,&quot; DIS&quot;,&quot;HO&quot;,&quot;N&quot;,&quot;OR&quot;,&quot;ED&quot;,&quot; BO&quot;,&quot;S&quot;,&quot;OM&quot;,&quot; TO&quot;,&quot; CON&quot;,&quot;NE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; HER&quot;,&quot; P&quot;,&quot;AR&quot;,&quot;ENT&quot;,&quot; FOR&quot;,&quot;E&quot;,&quot;VER&quot;,&quot; WITH&quot;,&quot; THE&quot;,&quot; RA&quot;,&quot;CE&quot;,&quot; AND&quot;,&quot; DE&quot;,&quot;S&quot;,&quot;C&quot;,&quot;ENT&quot;,&quot; OF&quot;,&quot; MO&quot;,&quot;R&quot;,&quot;T&quot;,&quot;AL&quot;,&quot;S&quot;,&quot; AND&quot;,&quot; TO&quot;,&quot; BE&quot;,&quot; FI&quot;,&quot;N&quot;,&quot;AL&quot;,&quot;LY&quot;,&quot; A&quot;,&quot; B&quot;,&quot;LESS&quot;,&quot;ED&quot;,&quot; SO&quot;,&quot;UL&quot;,&quot; IN&quot;,&quot; HE&quot;,&quot;A&quot;,&quot;VE&quot;,&quot;N&quot;]}
----
./sherpa-onnx-zipformer-en-2023-06-26/test_wavs/8k.wav
{&quot;text&quot;:&quot; YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.24, 0.40, 0.60, 0.80, 1.04, 1.16, 1.28, 1.36, 1.44, 1.48, 1.68, 1.76, 1.88, 2.00, 2.08, 2.24, 2.28, 2.48, 2.52, 2.80, 3.08, 3.28, 3.52, 3.68, 3.84, 3.96, 4.12, 4.20, 4.32, 4.44]&quot;,&quot;tokens&quot;:[&quot; YE&quot;,&quot;T&quot;,&quot; THE&quot;,&quot;SE&quot;,&quot; THOUGHT&quot;,&quot;S&quot;,&quot; A&quot;,&quot;FF&quot;,&quot;E&quot;,&quot;C&quot;,&quot;TED&quot;,&quot; HE&quot;,&quot;S&quot;,&quot;TER&quot;,&quot; P&quot;,&quot;RY&quot;,&quot;N&quot;,&quot;NE&quot;,&quot; &quot;,&quot;LESS&quot;,&quot; WITH&quot;,&quot; HO&quot;,&quot;PE&quot;,&quot; THAN&quot;,&quot; A&quot;,&quot;PP&quot;,&quot;RE&quot;,&quot;HE&quot;,&quot;N&quot;,&quot;S&quot;,&quot;ION&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.106 s
Real time factor (RTF): 1.106 / 28.165 = 0.039
</pre></div>
</div>
</section>
</section>
<section id="id83">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id83" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-06-26/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-06-26/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-06-26/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-06-26/joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
</section>
<section id="icefall-asr-multidataset-pruned-transducer-stateless7-2023-05-04-english">
<span id="id84"></span><h2>icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04 (English)<a class="headerlink" href="#icefall-asr-multidataset-pruned-transducer-stateless7-2023-05-04-english" title="Permalink to this heading"></a></h2>
<p>This model is trained using GigaSpeech + LibriSpeech + Common Voice 13.0 with zipformer</p>
<p>See <a class="reference external" href="https://github.com/k2-fsa/icefall/pull/1010">https://github.com/k2-fsa/icefall/pull/1010</a> if you are interested in how
it is trained.</p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id85">
<h3>Download the model<a class="headerlink" href="#id85" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04.tar.bz2
rm<span class="w"> </span>icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04.tar.bz2
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.2M<span class="w"> </span>May<span class="w"> </span><span class="m">15</span><span class="w"> </span><span class="m">11</span>:11<span class="w"> </span>decoder-epoch-30-avg-4.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.0M<span class="w"> </span>May<span class="w"> </span><span class="m">15</span><span class="w"> </span><span class="m">11</span>:11<span class="w"> </span>decoder-epoch-30-avg-4.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>121M<span class="w"> </span>May<span class="w"> </span><span class="m">15</span><span class="w"> </span><span class="m">11</span>:12<span class="w"> </span>encoder-epoch-30-avg-4.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>279M<span class="w"> </span>May<span class="w"> </span><span class="m">15</span><span class="w"> </span><span class="m">11</span>:13<span class="w"> </span>encoder-epoch-30-avg-4.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>253K<span class="w"> </span>May<span class="w"> </span><span class="m">15</span><span class="w"> </span><span class="m">11</span>:11<span class="w"> </span>joiner-epoch-30-avg-4.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">1</span>.0M<span class="w"> </span>May<span class="w"> </span><span class="m">15</span><span class="w"> </span><span class="m">11</span>:11<span class="w"> </span>joiner-epoch-30-avg-4.onnx
</pre></div>
</div>
</section>
<section id="id86">
<h3>Decode wave files<a class="headerlink" href="#id86" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id87">
<h4>fp32<a class="headerlink" href="#id87" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/data/lang_bpe_500/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/encoder-epoch-30-avg-4.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/decoder-epoch-30-avg-4.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/joiner-epoch-30-avg-4.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1089-134686-0001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1221-135766-0001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1221-135766-0002.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/data/lang_bpe_500/tokens.txt --encoder=./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/encoder-epoch-30-avg-4.onnx --decoder=./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/decoder-epoch-30-avg-4.onnx --joiner=./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/joiner-epoch-30-avg-4.onnx ./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1089-134686-0001.wav ./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1221-135766-0001.wav ./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1221-135766-0002.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/encoder-epoch-30-avg-4.onnx&quot;, decoder_filename=&quot;./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/decoder-epoch-30-avg-4.onnx&quot;, joiner_filename=&quot;./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/joiner-epoch-30-avg-4.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/data/lang_bpe_500/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4)
Creating recognizer ...
Started
Done!

./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1089-134686-0001.wav
{&quot;text&quot;:&quot; AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS&quot;,&quot;timestamps&quot;:&quot;[0.00,0.40,0.56,0.64,0.96,1.24,1.32,1.44,1.56,1.76,1.88,1.96,2.16,2.32,2.36,2.48,2.60,2.80,3.08,3.28,3.36,3.56,3.80,4.04,4.24,4.32,4.48,4.64,4.84,4.88,5.00,5.08,5.32,5.44,5.56,5.64,5.80,5.96,6.20]&quot;,&quot;tokens&quot;:[&quot; AFTER&quot;,&quot; E&quot;,&quot;AR&quot;,&quot;LY&quot;,&quot; NIGHT&quot;,&quot;F&quot;,&quot;A&quot;,&quot;LL&quot;,&quot; THE&quot;,&quot; YE&quot;,&quot;LL&quot;,&quot;OW&quot;,&quot; LA&quot;,&quot;M&quot;,&quot;P&quot;,&quot;S&quot;,&quot; WOULD&quot;,&quot; LIGHT&quot;,&quot; UP&quot;,&quot; HE&quot;,&quot;RE&quot;,&quot; AND&quot;,&quot; THERE&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;QUA&quot;,&quot;LI&quot;,&quot;D&quot;,&quot; &quot;,&quot;QUA&quot;,&quot;R&quot;,&quot;TER&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; B&quot;,&quot;RO&quot;,&quot;TH&quot;,&quot;EL&quot;,&quot;S&quot;]}
----
./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1221-135766-0001.wav
{&quot;text&quot;:&quot; GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN&quot;,&quot;timestamps&quot;:&quot;[0.00,0.16,0.44,0.68,0.84,1.00,1.12,1.16,1.32,1.48,1.64,1.80,1.84,2.00,2.12,2.28,2.40,2.64,2.88,3.16,3.28,3.56,3.60,3.76,3.92,4.12,4.36,4.52,4.72,4.92,5.16,5.44,5.72,6.12,6.24,6.48,6.84,7.08,7.28,7.56,7.88,8.12,8.28,8.36,8.48,8.60,8.76,8.88,9.12,9.28,9.48,9.56,9.64,9.80,10.00,10.04,10.20,10.44,10.68,10.80,11.04,11.20,11.40,11.56,11.80,12.00,12.12,12.28,12.32,12.52,12.72,12.84,12.96,13.04,13.24,13.40,13.64,13.80,14.00,14.16,14.24,14.36,14.56,14.72,14.80,15.08,15.32,15.52,15.76,16.04,16.16,16.24,16.36]&quot;,&quot;tokens&quot;:[&quot; GO&quot;,&quot;D&quot;,&quot; AS&quot;,&quot; A&quot;,&quot; DI&quot;,&quot;RE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; CON&quot;,&quot;SE&quot;,&quot;QUE&quot;,&quot;N&quot;,&quot;CE&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;IN&quot;,&quot; WHICH&quot;,&quot; MAN&quot;,&quot; TH&quot;,&quot;US&quot;,&quot; P&quot;,&quot;UN&quot;,&quot;ISH&quot;,&quot;ED&quot;,&quot; HAD&quot;,&quot; GIVE&quot;,&quot;N&quot;,&quot; HER&quot;,&quot; A&quot;,&quot; LOVE&quot;,&quot;LY&quot;,&quot; CHILD&quot;,&quot; WHO&quot;,&quot;SE&quot;,&quot; PLACE&quot;,&quot; WAS&quot;,&quot; ON&quot;,&quot; THAT&quot;,&quot; SAME&quot;,&quot; DIS&quot;,&quot;HO&quot;,&quot;N&quot;,&quot;OR&quot;,&quot;ED&quot;,&quot; BO&quot;,&quot;S&quot;,&quot;OM&quot;,&quot; TO&quot;,&quot; CON&quot;,&quot;NE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; HER&quot;,&quot; P&quot;,&quot;AR&quot;,&quot;ENT&quot;,&quot; FOR&quot;,&quot; E&quot;,&quot;VER&quot;,&quot; WITH&quot;,&quot; THE&quot;,&quot; RA&quot;,&quot;CE&quot;,&quot; AND&quot;,&quot; DE&quot;,&quot;S&quot;,&quot;C&quot;,&quot;ENT&quot;,&quot; OF&quot;,&quot; MO&quot;,&quot;R&quot;,&quot;T&quot;,&quot;AL&quot;,&quot;S&quot;,&quot; AND&quot;,&quot; TO&quot;,&quot; BE&quot;,&quot; FI&quot;,&quot;N&quot;,&quot;AL&quot;,&quot;LY&quot;,&quot; A&quot;,&quot; B&quot;,&quot;LESS&quot;,&quot;ED&quot;,&quot; SO&quot;,&quot;UL&quot;,&quot; IN&quot;,&quot; HE&quot;,&quot;A&quot;,&quot;VE&quot;,&quot;N&quot;]}
----
./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1221-135766-0002.wav
{&quot;text&quot;:&quot; YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION&quot;,&quot;timestamps&quot;:&quot;[0.00,0.08,0.32,0.48,0.68,0.92,1.08,1.20,1.28,1.40,1.44,1.64,1.76,1.88,2.04,2.12,2.24,2.32,2.48,2.56,2.88,3.12,3.32,3.52,3.76,3.92,4.00,4.20,4.28,4.40,4.52]&quot;,&quot;tokens&quot;:[&quot; YE&quot;,&quot;T&quot;,&quot; THE&quot;,&quot;SE&quot;,&quot; THOUGHT&quot;,&quot;S&quot;,&quot; A&quot;,&quot;FF&quot;,&quot;E&quot;,&quot;C&quot;,&quot;TED&quot;,&quot; HE&quot;,&quot;S&quot;,&quot;TER&quot;,&quot; P&quot;,&quot;RY&quot;,&quot;N&quot;,&quot;NE&quot;,&quot; &quot;,&quot;LESS&quot;,&quot; WITH&quot;,&quot; HO&quot;,&quot;PE&quot;,&quot; THAN&quot;,&quot; A&quot;,&quot;PP&quot;,&quot;RE&quot;,&quot;HE&quot;,&quot;N&quot;,&quot;S&quot;,&quot;ION&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.662 s
Real time factor (RTF): 1.662 / 28.165 = 0.059
</pre></div>
</div>
</section>
<section id="id88">
<h4>int8<a class="headerlink" href="#id88" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/data/lang_bpe_500/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/encoder-epoch-30-avg-4.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/decoder-epoch-30-avg-4.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/joiner-epoch-30-avg-4.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1089-134686-0001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1221-135766-0001.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1221-135766-0002.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/data/lang_bpe_500/tokens.txt --encoder=./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/encoder-epoch-30-avg-4.int8.onnx --decoder=./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/decoder-epoch-30-avg-4.onnx --joiner=./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/joiner-epoch-30-avg-4.int8.onnx ./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1089-134686-0001.wav ./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1221-135766-0001.wav ./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1221-135766-0002.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/encoder-epoch-30-avg-4.int8.onnx&quot;, decoder_filename=&quot;./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/decoder-epoch-30-avg-4.onnx&quot;, joiner_filename=&quot;./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/joiner-epoch-30-avg-4.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/data/lang_bpe_500/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4)
Creating recognizer ...
Started
Done!

./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1089-134686-0001.wav
{&quot;text&quot;:&quot; AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS&quot;,&quot;timestamps&quot;:&quot;[0.00,0.40,0.56,0.64,0.96,1.24,1.32,1.44,1.56,1.76,1.88,1.96,2.16,2.32,2.36,2.48,2.60,2.80,3.08,3.28,3.36,3.56,3.80,4.04,4.24,4.32,4.48,4.64,4.84,4.88,5.00,5.08,5.32,5.44,5.56,5.64,5.80,5.96,6.20]&quot;,&quot;tokens&quot;:[&quot; AFTER&quot;,&quot; E&quot;,&quot;AR&quot;,&quot;LY&quot;,&quot; NIGHT&quot;,&quot;F&quot;,&quot;A&quot;,&quot;LL&quot;,&quot; THE&quot;,&quot; YE&quot;,&quot;LL&quot;,&quot;OW&quot;,&quot; LA&quot;,&quot;M&quot;,&quot;P&quot;,&quot;S&quot;,&quot; WOULD&quot;,&quot; LIGHT&quot;,&quot; UP&quot;,&quot; HE&quot;,&quot;RE&quot;,&quot; AND&quot;,&quot; THERE&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;QUA&quot;,&quot;LI&quot;,&quot;D&quot;,&quot; &quot;,&quot;QUA&quot;,&quot;R&quot;,&quot;TER&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; B&quot;,&quot;RO&quot;,&quot;TH&quot;,&quot;EL&quot;,&quot;S&quot;]}
----
./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1221-135766-0001.wav
{&quot;text&quot;:&quot; GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN&quot;,&quot;timestamps&quot;:&quot;[0.00,0.12,0.44,0.68,0.80,1.00,1.12,1.16,1.32,1.48,1.64,1.80,1.84,2.00,2.12,2.28,2.40,2.64,2.88,3.16,3.28,3.56,3.60,3.76,3.92,4.12,4.36,4.52,4.72,4.92,5.16,5.44,5.72,6.12,6.24,6.48,6.84,7.08,7.28,7.56,7.88,8.12,8.28,8.36,8.48,8.60,8.76,8.88,9.12,9.28,9.48,9.56,9.64,9.80,10.00,10.04,10.16,10.44,10.68,10.80,11.04,11.20,11.40,11.56,11.80,12.00,12.16,12.28,12.32,12.52,12.72,12.84,12.96,13.04,13.24,13.40,13.64,13.80,14.00,14.16,14.24,14.36,14.56,14.72,14.80,15.08,15.32,15.52,15.76,16.04,16.16,16.24,16.36]&quot;,&quot;tokens&quot;:[&quot; GO&quot;,&quot;D&quot;,&quot; AS&quot;,&quot; A&quot;,&quot; DI&quot;,&quot;RE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; CON&quot;,&quot;SE&quot;,&quot;QUE&quot;,&quot;N&quot;,&quot;CE&quot;,&quot; OF&quot;,&quot; THE&quot;,&quot; S&quot;,&quot;IN&quot;,&quot; WHICH&quot;,&quot; MAN&quot;,&quot; TH&quot;,&quot;US&quot;,&quot; P&quot;,&quot;UN&quot;,&quot;ISH&quot;,&quot;ED&quot;,&quot; HAD&quot;,&quot; GIVE&quot;,&quot;N&quot;,&quot; HER&quot;,&quot; A&quot;,&quot; LOVE&quot;,&quot;LY&quot;,&quot; CHILD&quot;,&quot; WHO&quot;,&quot;SE&quot;,&quot; PLACE&quot;,&quot; WAS&quot;,&quot; ON&quot;,&quot; THAT&quot;,&quot; SAME&quot;,&quot; DIS&quot;,&quot;HO&quot;,&quot;N&quot;,&quot;OR&quot;,&quot;ED&quot;,&quot; BO&quot;,&quot;S&quot;,&quot;OM&quot;,&quot; TO&quot;,&quot; CON&quot;,&quot;NE&quot;,&quot;C&quot;,&quot;T&quot;,&quot; HER&quot;,&quot; P&quot;,&quot;AR&quot;,&quot;ENT&quot;,&quot; FOR&quot;,&quot; E&quot;,&quot;VER&quot;,&quot; WITH&quot;,&quot; THE&quot;,&quot; RA&quot;,&quot;CE&quot;,&quot; AND&quot;,&quot; DE&quot;,&quot;S&quot;,&quot;C&quot;,&quot;ENT&quot;,&quot; OF&quot;,&quot; MO&quot;,&quot;R&quot;,&quot;T&quot;,&quot;AL&quot;,&quot;S&quot;,&quot; AND&quot;,&quot; TO&quot;,&quot; BE&quot;,&quot; FI&quot;,&quot;N&quot;,&quot;AL&quot;,&quot;LY&quot;,&quot; A&quot;,&quot; B&quot;,&quot;LESS&quot;,&quot;ED&quot;,&quot; SO&quot;,&quot;UL&quot;,&quot; IN&quot;,&quot; HE&quot;,&quot;A&quot;,&quot;VE&quot;,&quot;N&quot;]}
----
./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/test_wavs/1221-135766-0002.wav
{&quot;text&quot;:&quot; YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION&quot;,&quot;timestamps&quot;:&quot;[0.00,0.08,0.32,0.48,0.68,0.92,1.08,1.20,1.28,1.40,1.44,1.64,1.76,1.88,2.04,2.12,2.28,2.32,2.52,2.56,2.88,3.12,3.32,3.52,3.76,3.92,4.00,4.20,4.28,4.40,4.52]&quot;,&quot;tokens&quot;:[&quot; YE&quot;,&quot;T&quot;,&quot; THE&quot;,&quot;SE&quot;,&quot; THOUGHT&quot;,&quot;S&quot;,&quot; A&quot;,&quot;FF&quot;,&quot;E&quot;,&quot;C&quot;,&quot;TED&quot;,&quot; HE&quot;,&quot;S&quot;,&quot;TER&quot;,&quot; P&quot;,&quot;RY&quot;,&quot;N&quot;,&quot;NE&quot;,&quot; &quot;,&quot;LESS&quot;,&quot; WITH&quot;,&quot; HO&quot;,&quot;PE&quot;,&quot; THAN&quot;,&quot; A&quot;,&quot;PP&quot;,&quot;RE&quot;,&quot;HE&quot;,&quot;N&quot;,&quot;S&quot;,&quot;ION&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.424 s
Real time factor (RTF): 1.424 / 28.165 = 0.051
</pre></div>
</div>
</section>
</section>
<section id="id89">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id89" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/data/lang_bpe_500/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/encoder-epoch-30-avg-4.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/decoder-epoch-30-avg-4.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./icefall-asr-multidataset-pruned_transducer_stateless7-2023-05-04/exp/joiner-epoch-30-avg-4.onnx
</pre></div>
</div>
</section>
</section>
<section id="csukuangfj-sherpa-onnx-zipformer-en-2023-04-01-english">
<span id="sherpa-onnx-zipformer-en-2023-04-01"></span><h2>csukuangfj/sherpa-onnx-zipformer-en-2023-04-01 (English)<a class="headerlink" href="#csukuangfj-sherpa-onnx-zipformer-en-2023-04-01-english" title="Permalink to this heading"></a></h2>
<p>This model is converted from</p>
<p><a class="reference external" href="https://huggingface.co/WeijiZhuang/icefall-asr-librispeech-pruned-transducer-stateless8-2022-12-02">https://huggingface.co/WeijiZhuang/icefall-asr-librispeech-pruned-transducer-stateless8-2022-12-02</a></p>
<p>which supports only English as it is trained on the <a class="reference external" href="https://www.openslr.org/12">LibriSpeech</a> and <a class="reference external" href="https://github.com/SpeechColab/GigaSpeech">GigaSpeech</a> corpus.</p>
<p>You can find the training code at</p>
<p><a class="reference external" href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless8">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless8</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id90">
<h3>Download the model<a class="headerlink" href="#id90" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-en-2023-04-01.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-zipformer-en-2023-04-01.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-en-2023-04-01.tar.bz2
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sherpa-onnx-zipformer-en-2023-04-01$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span><span class="m">1</span>.3M<span class="w"> </span>Apr<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">14</span>:34<span class="w"> </span>decoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span><span class="m">2</span>.0M<span class="w"> </span>Apr<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">14</span>:34<span class="w"> </span>decoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>180M<span class="w"> </span>Apr<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">14</span>:34<span class="w"> </span>encoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>338M<span class="w"> </span>Apr<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">14</span>:34<span class="w"> </span>encoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>254K<span class="w"> </span>Apr<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">14</span>:34<span class="w"> </span>joiner-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w"> </span>1003K<span class="w"> </span>Apr<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">14</span>:34<span class="w"> </span>joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
<section id="id91">
<h3>Decode wave files<a class="headerlink" href="#id91" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id92">
<h4>fp32<a class="headerlink" href="#id92" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-04-01/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-04-01/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-04-01/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-04-01/joiner-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-04-01/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-04-01/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-04-01/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-en-2023-04-01/encoder-epoch-99-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-en-2023-04-01/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-en-2023-04-01/joiner-epoch-99-avg-1.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-en-2023-04-01/tokens.txt&quot;, num_threads=2, debug=False), decoding_method=&quot;greedy_search&quot;)
Creating recognizer ...
2023-04-01 14:40:56.353883875 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 638155, index: 16, mask: {17, 53, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
2023-04-01 14:40:56.353881478 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 638154, index: 15, mask: {16, 52, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
Started
Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-zipformer-en-2023-04-01/test_wavs/0.wav
 AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS
----
./sherpa-onnx-zipformer-en-2023-04-01/test_wavs/1.wav
 GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONOURED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN
----
./sherpa-onnx-zipformer-en-2023-04-01/test_wavs/8k.wav
 YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 2.151 s
Real time factor (RTF): 2.151 / 28.165 = 0.076
</pre></div>
</div>
</section>
<section id="id93">
<h4>int8<a class="headerlink" href="#id93" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-04-01/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-04-01/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-04-01/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-04-01/joiner-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-04-01/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-04-01/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-04-01/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-en-2023-04-01/encoder-epoch-99-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-en-2023-04-01/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-en-2023-04-01/joiner-epoch-99-avg-1.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-en-2023-04-01/tokens.txt&quot;, num_threads=2, debug=False), decoding_method=&quot;greedy_search&quot;)
Creating recognizer ...
2023-04-01 14:42:00.407939001 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 638195, index: 15, mask: {16, 52, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
2023-04-01 14:42:00.407940827 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 638196, index: 16, mask: {17, 53, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
Started
Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-zipformer-en-2023-04-01/test_wavs/0.wav
 AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS
----
./sherpa-onnx-zipformer-en-2023-04-01/test_wavs/1.wav
 GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONOURED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN
----
./sherpa-onnx-zipformer-en-2023-04-01/test_wavs/8k.wav
 YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.478 s
Real time factor (RTF): 1.478 / 28.165 = 0.052
</pre></div>
</div>
</section>
</section>
<section id="id94">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id94" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-04-01/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-04-01/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-04-01/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-04-01/joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
</section>
<section id="csukuangfj-sherpa-onnx-zipformer-en-2023-03-30-english">
<span id="sherpa-onnx-zipformer-en-2023-03-30"></span><h2>csukuangfj/sherpa-onnx-zipformer-en-2023-03-30 (English)<a class="headerlink" href="#csukuangfj-sherpa-onnx-zipformer-en-2023-03-30-english" title="Permalink to this heading"></a></h2>
<p>This model is converted from</p>
<p><a class="reference external" href="https://huggingface.co/csukuangfj/icefall-asr-librispeech-pruned-transducer-stateless7-2022-11-11">https://huggingface.co/csukuangfj/icefall-asr-librispeech-pruned-transducer-stateless7-2022-11-11</a></p>
<p>which supports only English as it is trained on the <a class="reference external" href="https://www.openslr.org/12">LibriSpeech</a> corpus.</p>
<p>You can find the training code at</p>
<p><a class="reference external" href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless7">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless7</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id95">
<h3>Download the model<a class="headerlink" href="#id95" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-en-2023-03-30.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-zipformer-en-2023-03-30.tar.bz2
rm<span class="w"> </span>sherpa-onnx-zipformer-en-2023-03-30.tar.bz2
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sherpa-onnx-zipformer-en-2023-03-30$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span><span class="m">1</span>.3M<span class="w"> </span>Mar<span class="w"> </span><span class="m">31</span><span class="w"> </span><span class="m">00</span>:37<span class="w"> </span>decoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span><span class="m">2</span>.0M<span class="w"> </span>Mar<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="m">20</span>:10<span class="w"> </span>decoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>180M<span class="w"> </span>Mar<span class="w"> </span><span class="m">31</span><span class="w"> </span><span class="m">00</span>:37<span class="w"> </span>encoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>338M<span class="w"> </span>Mar<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="m">20</span>:10<span class="w"> </span>encoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>254K<span class="w"> </span>Mar<span class="w"> </span><span class="m">31</span><span class="w"> </span><span class="m">00</span>:37<span class="w"> </span>joiner-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w"> </span>1003K<span class="w"> </span>Mar<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="m">20</span>:10<span class="w"> </span>joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
<section id="id96">
<h3>Decode wave files<a class="headerlink" href="#id96" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id97">
<h4>fp32<a class="headerlink" href="#id97" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-03-30/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-03-30/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-03-30/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-03-30/joiner-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-03-30/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-03-30/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-03-30/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-en-2023-03-30/encoder-epoch-99-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-en-2023-03-30/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-en-2023-03-30/joiner-epoch-99-avg-1.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-en-2023-03-30/tokens.txt&quot;, num_threads=2, debug=False), decoding_method=&quot;greedy_search&quot;)
Creating recognizer ...
2023-04-01 06:47:56.620698024 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 607690, index: 15, mask: {16, 52, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
2023-04-01 06:47:56.620700026 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 607691, index: 16, mask: {17, 53, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
Started
Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-zipformer-en-2023-03-30/test_wavs/0.wav
 AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS
----
./sherpa-onnx-zipformer-en-2023-03-30/test_wavs/1.wav
 GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONOURED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN
----
./sherpa-onnx-zipformer-en-2023-03-30/test_wavs/8k.wav
 YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.950 s
Real time factor (RTF): 1.950 / 28.165 = 0.069
</pre></div>
</div>
</section>
<section id="id98">
<h4>int8<a class="headerlink" href="#id98" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-03-30/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-03-30/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-03-30/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-03-30/joiner-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-03-30/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-03-30/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-zipformer-en-2023-03-30/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-zipformer-en-2023-03-30/encoder-epoch-99-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-zipformer-en-2023-03-30/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-zipformer-en-2023-03-30/joiner-epoch-99-avg-1.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-zipformer-en-2023-03-30/tokens.txt&quot;, num_threads=2, debug=False), decoding_method=&quot;greedy_search&quot;)
Creating recognizer ...
2023-04-01 06:49:34.370117205 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 607732, index: 16, mask: {17, 53, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
2023-04-01 06:49:34.370115197 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 607731, index: 15, mask: {16, 52, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
Started
Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-zipformer-en-2023-03-30/test_wavs/0.wav
 AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS
----
./sherpa-onnx-zipformer-en-2023-03-30/test_wavs/1.wav
 GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONOURED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN
----
./sherpa-onnx-zipformer-en-2023-03-30/test_wavs/8k.wav
 YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.710 s
Real time factor (RTF): 1.710 / 28.165 = 0.061
</pre></div>
</div>
</section>
</section>
<section id="id99">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id99" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-03-30/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-03-30/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-03-30/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-zipformer-en-2023-03-30/joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Offline transducer models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="conformer-transducer-models.html" class="btn btn-neutral float-right" title="Conformer-transducer-based Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022-2025, sherpa development team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>