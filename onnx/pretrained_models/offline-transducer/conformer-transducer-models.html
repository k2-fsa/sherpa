<!-- see https://stackoverflow.com/questions/2454577/sphinx-restructuredtext-show-hide-code-snippets -->
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Conformer-transducer-based Models &mdash; sherpa 1.3 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/user.define.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="NeMo transducer-based Models" href="nemo-transducer-models.html" />
    <link rel="prev" title="Zipformer-transducer-based Models" href="zipformer-transducer-models.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> sherpa
          </a>
              <div class="version">
                1.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pdf.html">Download pdf</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../social-groups.html">Social groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../huggingface/index.html">Run Next-gen Kaldi in your browser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pretrained-models.html">Pre-trained models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../sherpa/index.html">sherpa</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-ncnn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../ncnn/index.html">sherpa-ncnn</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-onnx</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">sherpa-onnx</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/index.html">Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../faqs/index.html">Frequently Asked Question (FAQs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python/index.html">Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c-api/index.html">C API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../java-api/index.html">Java API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../javascript-api/index.html">Javascript API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kotlin-api/index.html">Kotlin API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../swift-api/index.html">Swift API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../go-api/index.html">Go API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../csharp-api/index.html">C# API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pascal-api/index.html">Pascal API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../lazarus/index.html">Lazarus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../wasm/index.html">WebAssembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../android/index.html">Android</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../harmony-os/index.html">HarmonyOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ios/index.html">iOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../flutter/index.html">Flutter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websocket/index.html">WebSocket</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hotwords/index.html">Hotwords (Contextual biasing)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kws/index.html">Keyword spotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../punctuation/index.html">Punctuation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../audio-tagging/index.html">Audio tagging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../spoken-language-identification/index.html">Spoken language identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../vad/index.html">VAD</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">Pre-trained models</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../online-transducer/index.html">Online transducer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../online-paraformer/index.html">Online paraformer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../online-ctc/index.html">Online CTC models</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="index.html">Offline transducer models</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="zipformer-transducer-models.html">Zipformer-transducer-based Models</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">Conformer-transducer-based Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="nemo-transducer-models.html">NeMo transducer-based Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../offline-paraformer/index.html">Offline paraformer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../offline-ctc/index.html">Offline CTC models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../telespeech/index.html">TeleSpeech</a></li>
<li class="toctree-l3"><a class="reference internal" href="../whisper/index.html">Whisper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../wenet/index.html">WeNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../small-online-models.html">Small models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../sense-voice/index.html">SenseVoice</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../whisper/index.html">Whisper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../moonshine/index.html">Moonshine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../omnilingual-asr/index.html">Omnilingual ASR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sense-voice/index.html">SenseVoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../funasr-nano/index.html">FunASR Nano</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../paraformer/index.html">Paraformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nemo/index.html">NeMo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../FireRedAsr/index.html">FireRedAsr</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Dolphin/index.html">Dolphin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../homophone-replacer/index.html">拼音词组匹配替换</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../speaker-diarization/index.html">Speaker Diarization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../speaker-identification/index.html">Speaker Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../speech-enhancement/index.html">Speech enhancement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../source-separation/index.html">Source separation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../qnn/index.html">Qualcomm NPU (QNN, HTP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rknn/index.html">rknn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ascend/index.html">Ascend NPU (昇腾 NPU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tts/index.html">Text-to-speech (TTS)</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../triton/overview.html">Triton</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">sherpa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">sherpa-onnx</a> &raquo;</li>
          <li><a href="../index.html">Pre-trained models</a> &raquo;</li>
          <li><a href="index.html">Offline transducer models</a> &raquo;</li>
      <li>Conformer-transducer-based Models</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/k2-fsa/sherpa/blob/master/docs/source/onnx/pretrained_models/offline-transducer/conformer-transducer-models.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="conformer-transducer-based-models">
<h1>Conformer-transducer-based Models<a class="headerlink" href="#conformer-transducer-based-models" title="Permalink to this heading"></a></h1>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Please refer to <a class="reference internal" href="../../install/index.html#install-sherpa-onnx"><span class="std std-ref">Installation</span></a> to install <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>
before you read this section.</p>
</div>
<section id="csukuangfj-sherpa-onnx-conformer-zh-stateless2-2023-05-23-chinese">
<h2>csukuangfj/sherpa-onnx-conformer-zh-stateless2-2023-05-23 (Chinese)<a class="headerlink" href="#csukuangfj-sherpa-onnx-conformer-zh-stateless2-2023-05-23-chinese" title="Permalink to this heading"></a></h2>
<p>This model is converted from</p>
<p><a class="reference external" href="https://huggingface.co/luomingshuang/icefall_asr_wenetspeech_pruned_transducer_stateless2">https://huggingface.co/luomingshuang/icefall_asr_wenetspeech_pruned_transducer_stateless2</a></p>
<p>which supports only Chinese as it is trained on the <a class="reference external" href="https://github.com/wenet-e2e/WenetSpeech">WenetSpeech</a> corpus.</p>
<p>You can find the training code at</p>
<p><a class="reference external" href="https://github.com/k2-fsa/icefall/tree/master/egs/wenetspeech/ASR/pruned_transducer_stateless2">https://github.com/k2-fsa/icefall/tree/master/egs/wenetspeech/ASR/pruned_transducer_stateless2</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="download-the-model">
<h3>Download the model<a class="headerlink" href="#download-the-model" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-conformer-zh-stateless2-2023-05-23.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-conformer-zh-stateless2-2023-05-23.tar.bz2
rm<span class="w"> </span>sherpa-onnx-conformer-zh-stateless2-2023-05-23.tar.bz2
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sherpa-onnx-conformer-zh-stateless2-2023-05-23<span class="w"> </span>fangjun$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>11M<span class="w"> </span>May<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">15</span>:29<span class="w"> </span>decoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>12M<span class="w"> </span>May<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">15</span>:29<span class="w"> </span>decoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>122M<span class="w"> </span>May<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">15</span>:30<span class="w"> </span>encoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>315M<span class="w"> </span>May<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">15</span>:31<span class="w"> </span>encoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.7M<span class="w"> </span>May<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">15</span>:29<span class="w"> </span>joiner-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>11M<span class="w"> </span>May<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">15</span>:29<span class="w"> </span>joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
<section id="decode-wave-files">
<h3>Decode wave files<a class="headerlink" href="#decode-wave-files" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="fp32">
<h4>fp32<a class="headerlink" href="#fp32" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/joiner-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/2.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-conformer-zh-stateless2-2023-05-23/tokens.txt --encoder=./sherpa-onnx-conformer-zh-stateless2-2023-05-23/encoder-epoch-99-avg-1.onnx --decoder=./sherpa-onnx-conformer-zh-stateless2-2023-05-23/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-conformer-zh-stateless2-2023-05-23/joiner-epoch-99-avg-1.onnx ./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/0.wav ./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/1.wav ./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/2.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-conformer-zh-stateless2-2023-05-23/encoder-epoch-99-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-conformer-zh-stateless2-2023-05-23/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-conformer-zh-stateless2-2023-05-23/joiner-epoch-99-avg-1.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-conformer-zh-stateless2-2023-05-23/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4)
Creating recognizer ...
Started
Done!

./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/0.wav
{&quot;text&quot;:&quot;对我做了介绍那么我想说的是呢大家如果对我的研究感兴趣呢&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.44, 0.64, 0.84, 1.04, 1.64, 1.72, 1.88, 2.08, 2.28, 2.44, 2.56, 2.76, 3.08, 3.20, 3.32, 3.48, 3.64, 3.76, 3.88, 4.00, 4.16, 4.24, 4.44, 4.60, 4.84]&quot;,&quot;tokens&quot;:[&quot;对&quot;,&quot;我&quot;,&quot;做&quot;,&quot;了&quot;,&quot;介&quot;,&quot;绍&quot;,&quot;那&quot;,&quot;么&quot;,&quot;我&quot;,&quot;想&quot;,&quot;说&quot;,&quot;的&quot;,&quot;是&quot;,&quot;呢&quot;,&quot;大&quot;,&quot;家&quot;,&quot;如&quot;,&quot;果&quot;,&quot;对&quot;,&quot;我&quot;,&quot;的&quot;,&quot;研&quot;,&quot;究&quot;,&quot;感&quot;,&quot;兴&quot;,&quot;趣&quot;,&quot;呢&quot;]}
----
./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/1.wav
{&quot;text&quot;:&quot;重点想谈三个问题首先呢就是这一轮全球金融动荡的表现&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.48, 0.64, 0.88, 1.08, 1.28, 1.48, 1.80, 2.12, 2.40, 2.56, 2.68, 2.88, 3.04, 3.16, 3.36, 3.56, 3.68, 3.84, 4.00, 4.16, 4.32, 4.56, 4.76]&quot;,&quot;tokens&quot;:[&quot;重&quot;,&quot;点&quot;,&quot;想&quot;,&quot;谈&quot;,&quot;三&quot;,&quot;个&quot;,&quot;问&quot;,&quot;题&quot;,&quot;首&quot;,&quot;先&quot;,&quot;呢&quot;,&quot;就&quot;,&quot;是&quot;,&quot;这&quot;,&quot;一&quot;,&quot;轮&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;荡&quot;,&quot;的&quot;,&quot;表&quot;,&quot;现&quot;]}
----
./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/2.wav
{&quot;text&quot;:&quot;深入地分析这一次全球金融动荡背后的根源&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.16, 0.60, 0.88, 1.08, 1.36, 1.64, 1.84, 2.24, 2.52, 2.72, 2.92, 3.08, 3.24, 3.40, 3.56, 3.72, 3.88, 4.12]&quot;,&quot;tokens&quot;:[&quot;深&quot;,&quot;入&quot;,&quot;地&quot;,&quot;分&quot;,&quot;析&quot;,&quot;这&quot;,&quot;一&quot;,&quot;次&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;荡&quot;,&quot;背&quot;,&quot;后&quot;,&quot;的&quot;,&quot;根&quot;,&quot;源&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.596 s
Real time factor (RTF): 0.596 / 15.289 = 0.039
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
</section>
<section id="int8">
<h4>int8<a class="headerlink" href="#int8" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/joiner-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/2.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>We did not use <code class="docutils literal notranslate"><span class="pre">int8</span></code> for the decoder model above.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-conformer-zh-stateless2-2023-05-23/tokens.txt --encoder=./sherpa-onnx-conformer-zh-stateless2-2023-05-23/encoder-epoch-99-avg-1.int8.onnx --decoder=./sherpa-onnx-conformer-zh-stateless2-2023-05-23/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-conformer-zh-stateless2-2023-05-23/joiner-epoch-99-avg-1.int8.onnx ./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/0.wav ./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/1.wav ./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/2.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-conformer-zh-stateless2-2023-05-23/encoder-epoch-99-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-conformer-zh-stateless2-2023-05-23/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-conformer-zh-stateless2-2023-05-23/joiner-epoch-99-avg-1.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-conformer-zh-stateless2-2023-05-23/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4)
Creating recognizer ...
Started
Done!

./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/0.wav
{&quot;text&quot;:&quot;对我做了介绍那么我想说的是呢大家如果对我的研究感兴趣呢&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.44, 0.64, 0.84, 1.08, 1.64, 1.72, 1.88, 2.08, 2.28, 2.44, 2.56, 2.76, 3.08, 3.20, 3.32, 3.48, 3.64, 3.76, 3.88, 4.00, 4.16, 4.24, 4.48, 4.60, 4.84]&quot;,&quot;tokens&quot;:[&quot;对&quot;,&quot;我&quot;,&quot;做&quot;,&quot;了&quot;,&quot;介&quot;,&quot;绍&quot;,&quot;那&quot;,&quot;么&quot;,&quot;我&quot;,&quot;想&quot;,&quot;说&quot;,&quot;的&quot;,&quot;是&quot;,&quot;呢&quot;,&quot;大&quot;,&quot;家&quot;,&quot;如&quot;,&quot;果&quot;,&quot;对&quot;,&quot;我&quot;,&quot;的&quot;,&quot;研&quot;,&quot;究&quot;,&quot;感&quot;,&quot;兴&quot;,&quot;趣&quot;,&quot;呢&quot;]}
----
./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/1.wav
{&quot;text&quot;:&quot;重点想谈三个问题首先呢就是这一轮全球金融动荡的表现&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.08, 0.48, 0.64, 0.88, 1.08, 1.28, 1.48, 1.80, 2.08, 2.40, 2.56, 2.68, 2.88, 3.04, 3.16, 3.36, 3.56, 3.68, 3.84, 4.00, 4.16, 4.32, 4.56, 4.76]&quot;,&quot;tokens&quot;:[&quot;重&quot;,&quot;点&quot;,&quot;想&quot;,&quot;谈&quot;,&quot;三&quot;,&quot;个&quot;,&quot;问&quot;,&quot;题&quot;,&quot;首&quot;,&quot;先&quot;,&quot;呢&quot;,&quot;就&quot;,&quot;是&quot;,&quot;这&quot;,&quot;一&quot;,&quot;轮&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;荡&quot;,&quot;的&quot;,&quot;表&quot;,&quot;现&quot;]}
----
./sherpa-onnx-conformer-zh-stateless2-2023-05-23/test_wavs/2.wav
{&quot;text&quot;:&quot;深入地分析这一次全球金融动荡背后的根源&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.56, 0.84, 1.08, 1.40, 1.64, 1.84, 2.24, 2.52, 2.72, 2.92, 3.08, 3.24, 3.40, 3.56, 3.72, 3.88, 4.12]&quot;,&quot;tokens&quot;:[&quot;深&quot;,&quot;入&quot;,&quot;地&quot;,&quot;分&quot;,&quot;析&quot;,&quot;这&quot;,&quot;一&quot;,&quot;次&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;荡&quot;,&quot;背&quot;,&quot;后&quot;,&quot;的&quot;,&quot;根&quot;,&quot;源&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.439 s
Real time factor (RTF): 0.439 / 15.289 = 0.029
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
</section>
</section>
<section id="speech-recognition-from-a-microphone">
<h3>Speech recognition from a microphone<a class="headerlink" href="#speech-recognition-from-a-microphone" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-conformer-zh-stateless2-2023-05-23/joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
</section>
</section>
<section id="csukuangfj-sherpa-onnx-conformer-zh-2023-05-23-chinese">
<h2>csukuangfj/sherpa-onnx-conformer-zh-2023-05-23 (Chinese)<a class="headerlink" href="#csukuangfj-sherpa-onnx-conformer-zh-2023-05-23-chinese" title="Permalink to this heading"></a></h2>
<p>This model is converted from</p>
<p><a class="reference external" href="https://huggingface.co/luomingshuang/icefall_asr_wenetspeech_pruned_transducer_stateless5_offline">https://huggingface.co/luomingshuang/icefall_asr_wenetspeech_pruned_transducer_stateless5_offline</a></p>
<p>which supports only Chinese as it is trained on the <a class="reference external" href="https://github.com/wenet-e2e/WenetSpeech">WenetSpeech</a> corpus.</p>
<p>You can find the training code at</p>
<p><a class="reference external" href="https://github.com/k2-fsa/icefall/tree/master/egs/wenetspeech/ASR/pruned_transducer_stateless5">https://github.com/k2-fsa/icefall/tree/master/egs/wenetspeech/ASR/pruned_transducer_stateless5</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id1">
<h3>Download the model<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-conformer-zh-2023-05-23.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-conformer-zh-2023-05-23.tar.bz2
rm<span class="w"> </span>sherpa-onnx-conformer-zh-2023-05-23.tar.bz2
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sherpa-onnx-conformer-zh-2023-05-23<span class="w"> </span>fangjun$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>11M<span class="w"> </span>May<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">13</span>:45<span class="w"> </span>decoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>12M<span class="w"> </span>May<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">13</span>:45<span class="w"> </span>decoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>129M<span class="w"> </span>May<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">13</span>:47<span class="w"> </span>encoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>345M<span class="w"> </span>May<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">13</span>:48<span class="w"> </span>encoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.7M<span class="w"> </span>May<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">13</span>:45<span class="w"> </span>joiner-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>11M<span class="w"> </span>May<span class="w"> </span><span class="m">23</span><span class="w"> </span><span class="m">13</span>:45<span class="w"> </span>joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
<section id="id2">
<h3>Decode wave files<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id3">
<h4>fp32<a class="headerlink" href="#id3" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-conformer-zh-2023-05-23/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-conformer-zh-2023-05-23/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-conformer-zh-2023-05-23/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-conformer-zh-2023-05-23/joiner-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/2.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-conformer-zh-2023-05-23/tokens.txt --encoder=./sherpa-onnx-conformer-zh-2023-05-23/encoder-epoch-99-avg-1.onnx --decoder=./sherpa-onnx-conformer-zh-2023-05-23/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-conformer-zh-2023-05-23/joiner-epoch-99-avg-1.onnx ./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/0.wav ./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/1.wav ./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/2.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-conformer-zh-2023-05-23/encoder-epoch-99-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-conformer-zh-2023-05-23/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-conformer-zh-2023-05-23/joiner-epoch-99-avg-1.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-conformer-zh-2023-05-23/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4)
Creating recognizer ...
Started
Done!

./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/0.wav
{&quot;text&quot;:&quot;对我做了介绍那么我想说的是呢大家如果对我的研究感兴趣呢&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.52, 0.64, 0.84, 1.04, 1.68, 1.80, 1.92, 2.12, 2.32, 2.48, 2.64, 2.76, 3.08, 3.20, 3.44, 3.52, 3.64, 3.76, 3.88, 4.00, 4.16, 4.32, 4.48, 4.64, 4.84]&quot;,&quot;tokens&quot;:[&quot;对&quot;,&quot;我&quot;,&quot;做&quot;,&quot;了&quot;,&quot;介&quot;,&quot;绍&quot;,&quot;那&quot;,&quot;么&quot;,&quot;我&quot;,&quot;想&quot;,&quot;说&quot;,&quot;的&quot;,&quot;是&quot;,&quot;呢&quot;,&quot;大&quot;,&quot;家&quot;,&quot;如&quot;,&quot;果&quot;,&quot;对&quot;,&quot;我&quot;,&quot;的&quot;,&quot;研&quot;,&quot;究&quot;,&quot;感&quot;,&quot;兴&quot;,&quot;趣&quot;,&quot;呢&quot;]}
----
./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/1.wav
{&quot;text&quot;:&quot;重点呢想谈三个问题首先呢就是这一轮全球金融动荡的表现&quot;,&quot;timestamps&quot;:&quot;[0.04, 0.16, 0.36, 0.48, 0.68, 0.92, 1.08, 1.24, 1.44, 1.84, 2.08, 2.36, 2.52, 2.68, 2.88, 3.04, 3.16, 3.40, 3.56, 3.72, 3.84, 4.04, 4.16, 4.32, 4.56, 4.76]&quot;,&quot;tokens&quot;:[&quot;重&quot;,&quot;点&quot;,&quot;呢&quot;,&quot;想&quot;,&quot;谈&quot;,&quot;三&quot;,&quot;个&quot;,&quot;问&quot;,&quot;题&quot;,&quot;首&quot;,&quot;先&quot;,&quot;呢&quot;,&quot;就&quot;,&quot;是&quot;,&quot;这&quot;,&quot;一&quot;,&quot;轮&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;荡&quot;,&quot;的&quot;,&quot;表&quot;,&quot;现&quot;]}
----
./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/2.wav
{&quot;text&quot;:&quot;深度地分析这一次全球金融动荡背后的根源&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.60, 0.84, 1.04, 1.44, 1.68, 1.84, 2.28, 2.52, 2.80, 2.92, 3.08, 3.24, 3.40, 3.60, 3.72, 3.84, 4.12]&quot;,&quot;tokens&quot;:[&quot;深&quot;,&quot;度&quot;,&quot;地&quot;,&quot;分&quot;,&quot;析&quot;,&quot;这&quot;,&quot;一&quot;,&quot;次&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;荡&quot;,&quot;背&quot;,&quot;后&quot;,&quot;的&quot;,&quot;根&quot;,&quot;源&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.706 s
Real time factor (RTF): 0.706 / 15.289 = 0.046
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
</section>
<section id="id4">
<h4>int8<a class="headerlink" href="#id4" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-conformer-zh-2023-05-23/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-conformer-zh-2023-05-23/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-conformer-zh-2023-05-23/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-conformer-zh-2023-05-23/joiner-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/2.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>We did not use <code class="docutils literal notranslate"><span class="pre">int8</span></code> for the decoder model above.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./build/bin/sherpa-onnx-offline --decoding-method=greedy_search --tokens=./sherpa-onnx-conformer-zh-2023-05-23/tokens.txt --encoder=./sherpa-onnx-conformer-zh-2023-05-23/encoder-epoch-99-avg-1.int8.onnx --decoder=./sherpa-onnx-conformer-zh-2023-05-23/decoder-epoch-99-avg-1.onnx --joiner=./sherpa-onnx-conformer-zh-2023-05-23/joiner-epoch-99-avg-1.int8.onnx ./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/0.wav ./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/1.wav ./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/2.wav 

OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-conformer-zh-2023-05-23/encoder-epoch-99-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-conformer-zh-2023-05-23/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-conformer-zh-2023-05-23/joiner-epoch-99-avg-1.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-conformer-zh-2023-05-23/tokens.txt&quot;, num_threads=2, debug=False, provider=&quot;cpu&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5), decoding_method=&quot;greedy_search&quot;, max_active_paths=4)
Creating recognizer ...
Started
Done!

./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/0.wav
{&quot;text&quot;:&quot;对我做了介绍那么我想说的是呢大家如果对我的研究感兴趣呢&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.52, 0.64, 0.84, 1.04, 1.68, 1.80, 1.92, 2.08, 2.32, 2.48, 2.64, 2.76, 3.08, 3.20, 3.44, 3.52, 3.64, 3.76, 3.88, 4.00, 4.16, 4.32, 4.48, 4.60, 4.84]&quot;,&quot;tokens&quot;:[&quot;对&quot;,&quot;我&quot;,&quot;做&quot;,&quot;了&quot;,&quot;介&quot;,&quot;绍&quot;,&quot;那&quot;,&quot;么&quot;,&quot;我&quot;,&quot;想&quot;,&quot;说&quot;,&quot;的&quot;,&quot;是&quot;,&quot;呢&quot;,&quot;大&quot;,&quot;家&quot;,&quot;如&quot;,&quot;果&quot;,&quot;对&quot;,&quot;我&quot;,&quot;的&quot;,&quot;研&quot;,&quot;究&quot;,&quot;感&quot;,&quot;兴&quot;,&quot;趣&quot;,&quot;呢&quot;]}
----
./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/1.wav
{&quot;text&quot;:&quot;重点呢想谈三个问题首先呢就是这一轮全球金融动荡的表现&quot;,&quot;timestamps&quot;:&quot;[0.04, 0.16, 0.36, 0.48, 0.68, 0.92, 1.08, 1.24, 1.44, 1.88, 2.08, 2.36, 2.52, 2.64, 2.88, 3.00, 3.16, 3.40, 3.56, 3.72, 3.84, 4.04, 4.20, 4.32, 4.56, 4.76]&quot;,&quot;tokens&quot;:[&quot;重&quot;,&quot;点&quot;,&quot;呢&quot;,&quot;想&quot;,&quot;谈&quot;,&quot;三&quot;,&quot;个&quot;,&quot;问&quot;,&quot;题&quot;,&quot;首&quot;,&quot;先&quot;,&quot;呢&quot;,&quot;就&quot;,&quot;是&quot;,&quot;这&quot;,&quot;一&quot;,&quot;轮&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;荡&quot;,&quot;的&quot;,&quot;表&quot;,&quot;现&quot;]}
----
./sherpa-onnx-conformer-zh-2023-05-23/test_wavs/2.wav
{&quot;text&quot;:&quot;深度地分析这一次全球金融动荡背后的根源&quot;,&quot;timestamps&quot;:&quot;[0.00, 0.12, 0.60, 0.84, 1.04, 1.44, 1.64, 1.84, 2.28, 2.52, 2.80, 2.92, 3.08, 3.28, 3.36, 3.60, 3.72, 3.84, 4.12]&quot;,&quot;tokens&quot;:[&quot;深&quot;,&quot;度&quot;,&quot;地&quot;,&quot;分&quot;,&quot;析&quot;,&quot;这&quot;,&quot;一&quot;,&quot;次&quot;,&quot;全&quot;,&quot;球&quot;,&quot;金&quot;,&quot;融&quot;,&quot;动&quot;,&quot;荡&quot;,&quot;背&quot;,&quot;后&quot;,&quot;的&quot;,&quot;根&quot;,&quot;源&quot;]}
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 0.502 s
Real time factor (RTF): 0.502 / 15.289 = 0.033
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
</section>
</section>
<section id="id5">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id5" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-conformer-zh-2023-05-23/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-conformer-zh-2023-05-23/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-conformer-zh-2023-05-23/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-conformer-zh-2023-05-23/joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If you use Windows and get encoding issues, please run:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>CHCP<span class="w"> </span><span class="m">65001</span>
</pre></div>
</div>
</div></blockquote>
<p>in your commandline.</p>
</div>
</section>
</section>
<section id="csukuangfj-sherpa-onnx-conformer-en-2023-03-18-english">
<h2>csukuangfj/sherpa-onnx-conformer-en-2023-03-18 (English)<a class="headerlink" href="#csukuangfj-sherpa-onnx-conformer-en-2023-03-18-english" title="Permalink to this heading"></a></h2>
<p>This model is converted from</p>
<p><a class="reference external" href="https://huggingface.co/csukuangfj/icefall-asr-librispeech-pruned-transducer-stateless3-2022-05-13">https://huggingface.co/csukuangfj/icefall-asr-librispeech-pruned-transducer-stateless3-2022-05-13</a></p>
<p>which supports only English as it is trained on the <a class="reference external" href="https://www.openslr.org/12">LibriSpeech</a> corpus.</p>
<p>You can find the training code at</p>
<p><a class="reference external" href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless3">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/pruned_transducer_stateless3</a></p>
<p>In the following, we describe how to download it and use it with <a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>.</p>
<section id="id6">
<h3>Download the model<a class="headerlink" href="#id6" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

wget<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-conformer-en-2023-03-18.tar.bz2

tar<span class="w"> </span>xvf<span class="w"> </span>sherpa-onnx-conformer-en-2023-03-18.tar.bz2
rm<span class="w"> </span>sherpa-onnx-conformer-en-2023-03-18.tar.bz2
</pre></div>
</div>
<p>Please check that the file sizes of the pre-trained models are correct. See
the file sizes of <code class="docutils literal notranslate"><span class="pre">*.onnx</span></code> files below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sherpa-onnx-en-2023-03-18$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>*.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span><span class="m">1</span>.3M<span class="w"> </span>Apr<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">07</span>:02<span class="w"> </span>decoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span><span class="m">2</span>.0M<span class="w"> </span>Apr<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">07</span>:02<span class="w"> </span>decoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>122M<span class="w"> </span>Apr<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">07</span>:02<span class="w"> </span>encoder-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>315M<span class="w"> </span>Apr<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">07</span>:02<span class="w"> </span>encoder-epoch-99-avg-1.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w">  </span>254K<span class="w"> </span>Apr<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">07</span>:02<span class="w"> </span>joiner-epoch-99-avg-1.int8.onnx
-rw-r--r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>kuangfangjun<span class="w"> </span>root<span class="w"> </span>1003K<span class="w"> </span>Apr<span class="w">  </span><span class="m">1</span><span class="w"> </span><span class="m">07</span>:02<span class="w"> </span>joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
<section id="id7">
<h3>Decode wave files<a class="headerlink" href="#id7" title="Permalink to this heading"></a></h3>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>It supports decoding only wave files of a single channel with 16-bit
encoded samples, while the sampling rate does not need to be 16 kHz.</p>
</div>
<section id="id8">
<h4>fp32<a class="headerlink" href="#id8" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">fp32</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-conformer-en-2023-03-18/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-conformer-en-2023-03-18/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-conformer-en-2023-03-18/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-conformer-en-2023-03-18/joiner-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-en-2023-03-18/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-en-2023-03-18/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-en-2023-03-18/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-conformer-en-2023-03-18/encoder-epoch-99-avg-1.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-conformer-en-2023-03-18/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-conformer-en-2023-03-18/joiner-epoch-99-avg-1.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-conformer-en-2023-03-18/tokens.txt&quot;, num_threads=2, debug=False), decoding_method=&quot;greedy_search&quot;)
Creating recognizer ...
2023-04-01 07:11:51.666456713 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 608379, index: 15, mask: {16, 52, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
2023-04-01 07:11:51.666458525 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 608380, index: 16, mask: {17, 53, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
Started
Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-conformer-en-2023-03-18/test_wavs/0.wav
 AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS
----
./sherpa-onnx-conformer-en-2023-03-18/test_wavs/1.wav
 GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOREVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN
----
./sherpa-onnx-conformer-en-2023-03-18/test_wavs/8k.wav
 YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 2.264 s
Real time factor (RTF): 2.264 / 28.165 = 0.080
</pre></div>
</div>
</section>
<section id="id9">
<h4>int8<a class="headerlink" href="#id9" title="Permalink to this heading"></a></h4>
<p>The following code shows how to use <code class="docutils literal notranslate"><span class="pre">int8</span></code> models to decode wave files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-conformer-en-2023-03-18/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-conformer-en-2023-03-18/encoder-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-conformer-en-2023-03-18/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-conformer-en-2023-03-18/joiner-epoch-99-avg-1.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-en-2023-03-18/test_wavs/0.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-en-2023-03-18/test_wavs/1.wav<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-conformer-en-2023-03-18/test_wavs/8k.wav
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please use <code class="docutils literal notranslate"><span class="pre">./build/bin/Release/sherpa-onnx-offline.exe</span></code> for Windows.</p>
</div>
<p>You should see the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;./sherpa-onnx-conformer-en-2023-03-18/encoder-epoch-99-avg-1.int8.onnx&quot;, decoder_filename=&quot;./sherpa-onnx-conformer-en-2023-03-18/decoder-epoch-99-avg-1.onnx&quot;, joiner_filename=&quot;./sherpa-onnx-conformer-en-2023-03-18/joiner-epoch-99-avg-1.int8.onnx&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), tokens=&quot;./sherpa-onnx-conformer-en-2023-03-18/tokens.txt&quot;, num_threads=2, debug=False), decoding_method=&quot;greedy_search&quot;)
Creating recognizer ...
2023-04-01 07:13:26.514109433 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 608419, index: 15, mask: {16, 52, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
2023-04-01 07:13:26.514112711 [E:onnxruntime:, env.cc:251 ThreadMain] pthread_setaffinity_np failed for thread: 608420, index: 16, mask: {17, 53, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.
Started
Creating a resampler:
   in_sample_rate: 8000
   output_sample_rate: 16000

Done!

./sherpa-onnx-conformer-en-2023-03-18/test_wavs/0.wav
 AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS
----
./sherpa-onnx-conformer-en-2023-03-18/test_wavs/1.wav
 GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOREVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN
----
./sherpa-onnx-conformer-en-2023-03-18/test_wavs/8k.wav
 YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION
----
num threads: 2
decoding method: greedy_search
Elapsed seconds: 1.370 s
Real time factor (RTF): 1.370 / 28.165 = 0.049
</pre></div>
</div>
</section>
</section>
<section id="id10">
<h3>Speech recognition from a microphone<a class="headerlink" href="#id10" title="Permalink to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path/to/sherpa-onnx

./build/bin/sherpa-onnx-microphone-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-conformer-en-2023-03-18/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="o">=</span>./sherpa-onnx-conformer-en-2023-03-18/encoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="o">=</span>./sherpa-onnx-conformer-en-2023-03-18/decoder-epoch-99-avg-1.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--joiner<span class="o">=</span>./sherpa-onnx-conformer-en-2023-03-18/joiner-epoch-99-avg-1.onnx
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="zipformer-transducer-models.html" class="btn btn-neutral float-left" title="Zipformer-transducer-based Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nemo-transducer-models.html" class="btn btn-neutral float-right" title="NeMo transducer-based Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022-2026, sherpa development team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>