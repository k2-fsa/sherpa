<!-- see https://stackoverflow.com/questions/2454577/sphinx-restructuredtext-show-hide-code-snippets -->
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Export Whisper to ONNX &mdash; sherpa 1.3 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/user.define.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="tiny.en" href="tiny.en.html" />
    <link rel="prev" title="Whisper" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> sherpa
          </a>
              <div class="version">
                1.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pdf.html">Download pdf</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../social-groups.html">Social groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../huggingface/index.html">Run Next-gen Kaldi in your browser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pretrained-models.html">Pre-trained models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../sherpa/index.html">sherpa</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-ncnn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../ncnn/index.html">sherpa-ncnn</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-onnx</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">sherpa-onnx</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/index.html">Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../faqs/index.html">Frequently Asked Question (FAQs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../python/index.html">Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../c-api/index.html">C API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../java-api/index.html">Java API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../javascript-api/index.html">Javascript API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kotlin-api/index.html">Kotlin API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../swift-api/index.html">Swift API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../go-api/index.html">Go API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../csharp-api/index.html">C# API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pascal-api/index.html">Pascal API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../lazarus/index.html">Lazarus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../wasm/index.html">WebAssembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../android/index.html">Android</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../harmony-os/index.html">HarmonyOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ios/index.html">iOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../flutter/index.html">Flutter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websocket/index.html">WebSocket</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../hotwords/index.html">Hotwords (Contextual biasing)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kws/index.html">Keyword spotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../punctuation/index.html">Punctuation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../audio-tagging/index.html">Audio tagging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../spoken-language-identification/index.html">Spoken language identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../vad/index.html">VAD</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">Pre-trained models</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../online-transducer/index.html">Online transducer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../online-paraformer/index.html">Online paraformer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../online-ctc/index.html">Online CTC models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../offline-transducer/index.html">Offline transducer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../offline-paraformer/index.html">Offline paraformer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../offline-ctc/index.html">Offline CTC models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../telespeech/index.html">TeleSpeech</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="index.html">Whisper</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">Export Whisper to ONNX</a></li>
<li class="toctree-l4"><a class="reference internal" href="tiny.en.html">tiny.en</a></li>
<li class="toctree-l4"><a class="reference internal" href="large-v3.html">large-v3</a></li>
<li class="toctree-l4"><a class="reference internal" href="colab.html">colab</a></li>
<li class="toctree-l4"><a class="reference internal" href="huggingface.html">Huggingface space</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../wenet/index.html">WeNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../small-online-models.html">Small models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../sense-voice/index.html">SenseVoice</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Whisper</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Export Whisper to ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#available-models">Available models</a></li>
<li class="toctree-l4"><a class="reference internal" href="#export-to-onnx">Export to onnx</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tiny.en.html">tiny.en</a></li>
<li class="toctree-l3"><a class="reference internal" href="large-v3.html">large-v3</a></li>
<li class="toctree-l3"><a class="reference internal" href="colab.html">colab</a></li>
<li class="toctree-l3"><a class="reference internal" href="huggingface.html">Huggingface space</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../moonshine/index.html">Moonshine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../omnilingual-asr/index.html">Omnilingual ASR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sense-voice/index.html">SenseVoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../funasr-nano/index.html">FunASR Nano</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../paraformer/index.html">Paraformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nemo/index.html">NeMo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../FireRedAsr/index.html">FireRedAsr</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Dolphin/index.html">Dolphin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../homophone-replacer/index.html">拼音词组匹配替换</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../speaker-diarization/index.html">Speaker Diarization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../speaker-identification/index.html">Speaker Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../speech-enhancement/index.html">Speech enhancement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../source-separation/index.html">Source separation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../qnn/index.html">Qualcomm NPU (QNN, HTP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rknn/index.html">rknn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ascend/index.html">Ascend NPU (昇腾 NPU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tts/index.html">Text-to-speech (TTS)</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../triton/overview.html">Triton</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">sherpa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">sherpa-onnx</a> &raquo;</li>
          <li><a href="../index.html">Pre-trained models</a> &raquo;</li>
          <li><a href="index.html">Whisper</a> &raquo;</li>
      <li>Export Whisper to ONNX</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/k2-fsa/sherpa/blob/master/docs/source/onnx/pretrained_models/whisper/export-onnx.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="export-whisper-to-onnx">
<h1>Export Whisper to ONNX<a class="headerlink" href="#export-whisper-to-onnx" title="Permalink to this heading"></a></h1>
<p>This section describes how to export <a class="reference external" href="https://github.com/openai/whisper/">Whisper</a> models to <a class="reference external" href="https://github.com/onnx/onnx">onnx</a>.</p>
<section id="available-models">
<h2>Available models<a class="headerlink" href="#available-models" title="Permalink to this heading"></a></h2>
<p>Note that we have already exported <a class="reference external" href="https://github.com/openai/whisper/">Whisper</a> models to <a class="reference external" href="https://github.com/onnx/onnx">onnx</a> and they are available
from the following huggingface repositories:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Model type</p></td>
<td><p>Huggingface repo</p></td>
<td><p>Chinese users</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">tiny.en</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-tiny.en">Here</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">base.en</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-base.en">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-base.en</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-base.en">Here</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">small.en</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-small.en">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-small.en</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-small.en">Here</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">distil-small.en</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-distil-small.en">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-distil-small.en</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-distil-small.en">Here</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">medium.en</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-medium.en">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-medium.en</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-medium.en">Here</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">distil-medium.en</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-distil-medium.en">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-distil-medium.en</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-distil-medium.en">Here</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">tiny</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-tiny">Here</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">base</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-base">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-base</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-base">Here</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">small</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-small">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-small</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-small">Here</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">medium</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-medium">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-medium</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-medium">Here</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">large</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-large">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-large</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-large">Here</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">large-v1</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-large-v1">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-large-v1</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-large-v1">Here</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">large-v2</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-large-v2">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-large-v2</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-large-v2">Here</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">large-v3</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-large-v3">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-large-v3</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-large-v3">Here</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">turbo</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-turbo">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-turbo</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-turbo">Here</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">distil-large-v2</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-distil-large-v2">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-distil-large-v2</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-distil-large-v2">Here</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">distil-large-v3</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-distil-large-v3">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-distil-large-v3</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-distil-large-v3">Here</a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">distil-large-v3.5</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-distil-large-v3.5">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-distil-large-v3.5</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-distil-large-v3.5">Here</a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">medium-aishell</span></code></p></td>
<td><p><a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-medium-aishell">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-medium-aishell</a></p></td>
<td><p><a class="reference external" href="https://hf-mirror.com/csukuangfj/sherpa-onnx-whisper-medium-aishell2">Here</a></p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can also download them from</p>
<blockquote>
<div><p><a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx/releases/tag/asr-models">https://github.com/k2-fsa/sherpa-onnx/releases/tag/asr-models</a></p>
</div></blockquote>
<p>Models end with <code class="docutils literal notranslate"><span class="pre">.en</span></code> support only English and all
other models are multilingual.</p>
</div>
<p>If you want to export the models by yourself or/and want to learn how the models
are exported, please read below.</p>
</section>
<section id="export-to-onnx">
<h2>Export to onnx<a class="headerlink" href="#export-to-onnx" title="Permalink to this heading"></a></h2>
<p>We use</p>
<blockquote>
<div><p><a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx/blob/master/scripts/whisper/export-onnx.py">https://github.com/k2-fsa/sherpa-onnx/blob/master/scripts/whisper/export-onnx.py</a></p>
</div></blockquote>
<p>to export <a class="reference external" href="https://github.com/openai/whisper/">Whisper</a> models to <a class="reference external" href="https://github.com/onnx/onnx">onnx</a>.</p>
<p>First, let us install dependencies and download the export script</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>torch<span class="w"> </span>openai-whisper<span class="w"> </span>onnxruntime<span class="w"> </span>onnx<span class="w"> </span>librosa<span class="w"> </span>soundfile

git<span class="w"> </span>clone<span class="w"> </span>https://github.com/k2-fsa/sherpa-onnx/
<span class="nb">cd</span><span class="w"> </span>sherpa-onnx/scripts/whisper
python3<span class="w"> </span>./export-onnx.py<span class="w"> </span>--help
</pre></div>
</div>
<p>It will print the following message:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>usage:<span class="w"> </span>export-onnx.py<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span>--model
<span class="w">                      </span><span class="o">{</span>tiny,tiny.en,base,base.en,small,small.en,medium,medium.en,large,large-v1,large-v2,large-v3,distil-medium.en,distil-small.en,distil-large-v2,distil-large-v3,distil-large-v3.5,medium-aishell<span class="o">}</span>

optional<span class="w"> </span>arguments:
<span class="w">  </span>-h,<span class="w"> </span>--help<span class="w">            </span>show<span class="w"> </span>this<span class="w"> </span><span class="nb">help</span><span class="w"> </span>message<span class="w"> </span>and<span class="w"> </span><span class="nb">exit</span>
<span class="w">  </span>--model<span class="w"> </span><span class="o">{</span>tiny,tiny.en,base,base.en,small,small.en,medium,medium.en,large,large-v1,large-v2,large-v3,distil-medium.en,distil-small.en,distil-large-v2,distil-large-v3,distil-large-v3.5,medium-aishell<span class="o">}</span>
</pre></div>
</div>
<section id="example-1-export-tiny-en">
<h3>Example 1: Export tiny.en<a class="headerlink" href="#example-1-export-tiny-en" title="Permalink to this heading"></a></h3>
<p>To export <code class="docutils literal notranslate"><span class="pre">tiny.en</span></code>, we can use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>./export-onnx.py<span class="w"> </span>--model<span class="w"> </span>tiny.en
</pre></div>
</div>
<p>It will generate the following files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>py38<span class="o">)</span><span class="w"> </span>fangjuns-MacBook-Pro:whisper<span class="w"> </span>fangjun$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>tiny.en-*
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>105M<span class="w"> </span>Aug<span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">15</span>:43<span class="w"> </span>tiny.en-decoder.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>185M<span class="w"> </span>Aug<span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">15</span>:43<span class="w"> </span>tiny.en-decoder.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>12M<span class="w"> </span>Aug<span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">15</span>:43<span class="w"> </span>tiny.en-encoder.int8.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">    </span>36M<span class="w"> </span>Aug<span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">15</span>:43<span class="w"> </span>tiny.en-encoder.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>816K<span class="w"> </span>Aug<span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">15</span>:43<span class="w"> </span>tiny.en-tokens.txt
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">tiny.en-encoder.onnx</span></code> is the encoder model and <code class="docutils literal notranslate"><span class="pre">tiny.en-decoder.onnx</span></code> is the
decoder model.</p>
<p><code class="docutils literal notranslate"><span class="pre">tiny.en-encoder.int8.onnx</span></code> is the quantized encoder model and <code class="docutils literal notranslate"><span class="pre">tiny.en-decoder.onnx</span></code> is the
quantized decoder model.</p>
<p><code class="docutils literal notranslate"><span class="pre">tiny.en-tokens.txt</span></code> contains the token table, which maps an integer to a token and vice versa.</p>
<dl class="simple">
<dt>To check whether the exported model works correctly, we can use</dt><dd><p><a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx/blob/master/scripts/whisper/test.py">https://github.com/k2-fsa/sherpa-onnx/blob/master/scripts/whisper/test.py</a></p>
</dd>
</dl>
<p>We use <a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en/resolve/main/test_wavs/0.wav">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en/resolve/main/test_wavs/0.wav</a>
as the test wave.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>kaldi-native-fbank
wget<span class="w"> </span>https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en/resolve/main/test_wavs/0.wav

python3<span class="w"> </span>./test.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="w"> </span>./tiny.en-encoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="w"> </span>./tiny.en-decoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="w"> </span>./tiny.en-tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./0.wav
</pre></div>
</div>
<p>To test <code class="docutils literal notranslate"><span class="pre">int8</span></code> quantized models, we can use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>./test.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="w"> </span>./tiny.en-encoder.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="w"> </span>./tiny.en-decoder.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="w"> </span>./tiny.en-tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./0.wav
</pre></div>
</div>
</section>
<section id="example-2-export-large-v3">
<h3>Example 2: Export large-v3<a class="headerlink" href="#example-2-export-large-v3" title="Permalink to this heading"></a></h3>
<p>To export <code class="docutils literal notranslate"><span class="pre">large-v3</span></code>, we can use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>./export-onnx.py<span class="w"> </span>--model<span class="w"> </span>large-v3
</pre></div>
</div>
<p>It will generate the following files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>py38<span class="o">)</span><span class="w"> </span>fangjuns-MacBook-Pro:whisper<span class="w"> </span>fangjun$<span class="w"> </span>ls<span class="w"> </span>-lh<span class="w"> </span>large-v3-*
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.7M<span class="w"> </span>Jul<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">20</span>:38<span class="w"> </span>large-v3-decoder.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">3</span>.0G<span class="w"> </span>Jul<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">20</span>:38<span class="w"> </span>large-v3-decoder.weights
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>744K<span class="w"> </span>Jul<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">20</span>:35<span class="w"> </span>large-v3-encoder.onnx
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span><span class="m">2</span>.8G<span class="w"> </span>Jul<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">20</span>:35<span class="w"> </span>large-v3-encoder.weights
-rw-r--r--<span class="w">  </span><span class="m">1</span><span class="w"> </span>fangjun<span class="w">  </span>staff<span class="w">   </span>798K<span class="w"> </span>Jul<span class="w"> </span><span class="m">12</span><span class="w"> </span><span class="m">20</span>:32<span class="w"> </span>large-v3-tokens.txt
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">large-v3-encoder.onnx</span></code> is the encoder model and <code class="docutils literal notranslate"><span class="pre">large-v3-decoder.onnx</span></code> is the
decoder model.</p>
<p>Note that for <code class="docutils literal notranslate"><span class="pre">large</span></code> models, there will also be two additional <code class="docutils literal notranslate"><span class="pre">weights</span></code> files.</p>
<p><code class="docutils literal notranslate"><span class="pre">large-v3-tokens.txt</span></code> contains the token table, which maps an integer to a token and vice versa.</p>
<dl class="simple">
<dt>To check whether the exported model works correctly, we can use</dt><dd><p><a class="reference external" href="https://github.com/k2-fsa/sherpa-onnx/blob/master/scripts/whisper/test.py">https://github.com/k2-fsa/sherpa-onnx/blob/master/scripts/whisper/test.py</a></p>
</dd>
</dl>
<p>We use <a class="reference external" href="https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en/resolve/main/test_wavs/0.wav">https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en/resolve/main/test_wavs/0.wav</a>
as the test wave.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>kaldi-native-fbank
wget<span class="w"> </span>https://huggingface.co/csukuangfj/sherpa-onnx-whisper-tiny.en/resolve/main/test_wavs/0.wav

python3<span class="w"> </span>./test.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--encoder<span class="w"> </span>./large-v3-encoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--decoder<span class="w"> </span>./large-v3-decoder.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="w"> </span>./large-v3-tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./0.wav
</pre></div>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>We provide a colab notebook
<a class="reference external" href="https://github.com/k2-fsa/colab/blob/master/sherpa-onnx/sherpa_onnx_whisper_large_v3.ipynb"><img alt="sherpa-onnx with whisper large-v3 colab notebook" src="https://github.com/k2-fsa/sherpa/releases/download/doc/colab-badge.jpg" /></a>
for you to try the exported large-v3 onnx model with sherpa-onnx
on CPU as well as on GPU.</p>
<p>You will find the RTF on GPU (Tesla T4) is less than 1.</p>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Whisper" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="tiny.en.html" class="btn btn-neutral float-right" title="tiny.en" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022-2026, sherpa development team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>