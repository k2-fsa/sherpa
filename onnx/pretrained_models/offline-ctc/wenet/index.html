<!-- see https://stackoverflow.com/questions/2454577/sphinx-restructuredtext-show-hide-code-snippets -->
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>WeNet CTC-based models &mdash; sherpa 1.3 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/user.define.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/clipboard.min.js"></script>
        <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="yesno" href="../yesno/index.html" />
    <link rel="prev" title="Japanese" href="../nemo/japanese.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../index.html" class="icon icon-home"> sherpa
          </a>
              <div class="version">
                1.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pdf.html">Download pdf</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../social-groups.html">Social groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../huggingface/index.html">Run Next-gen Kaldi in your browser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pretrained-models.html">Pre-trained models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../sherpa/index.html">sherpa</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-ncnn</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../ncnn/index.html">sherpa-ncnn</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">k2-fsa/sherpa-onnx</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../index.html">sherpa-onnx</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/index.html">Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../install/index.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../faqs/index.html">Frequently Asked Question (FAQs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/index.html">Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../c-api/index.html">C API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../java-api/index.html">Java API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../javascript-api/index.html">Javascript API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kotlin-api/index.html">Kotlin API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../swift-api/index.html">Swift API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../go-api/index.html">Go API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../csharp-api/index.html">C# API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pascal-api/index.html">Pascal API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../lazarus/index.html">Lazarus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../wasm/index.html">WebAssembly</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../android/index.html">Android</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../harmony-os/index.html">HarmonyOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ios/index.html">iOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../flutter/index.html">Flutter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../websocket/index.html">WebSocket</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../hotwords/index.html">Hotwords (Contextual biasing)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../kws/index.html">Keyword spotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../punctuation/index.html">Punctuation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../audio-tagging/index.html">Audio tagging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../spoken-language-identification/index.html">Spoken language identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../vad/index.html">VAD</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html">Pre-trained models</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../../online-transducer/index.html">Online transducer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../online-paraformer/index.html">Online paraformer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../online-ctc/index.html">Online CTC models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../offline-transducer/index.html">Offline transducer models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../offline-paraformer/index.html">Offline paraformer models</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">Offline CTC models</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../icefall/index.html">icefall</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nemo/index.html">NeMo CTC-based models</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">WeNet CTC-based models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../yesno/index.html">yesno</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../telespeech/index.html">TeleSpeech</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../whisper/index.html">Whisper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../wenet/index.html">WeNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../small-online-models.html">Small models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../sense-voice/index.html">SenseVoice</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../whisper/index.html">Whisper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../moonshine/index.html">Moonshine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../omnilingual-asr/index.html">Omnilingual ASR</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../sense-voice/index.html">SenseVoice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../funasr-nano/index.html">FunASR Nano</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../paraformer/index.html">Paraformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../nemo/index.html">NeMo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../FireRedAsr/index.html">FireRedAsr</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../Dolphin/index.html">Dolphin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../homophone-replacer/index.html">拼音词组匹配替换</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../speaker-diarization/index.html">Speaker Diarization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../speaker-identification/index.html">Speaker Identification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../speech-enhancement/index.html">Speech enhancement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../source-separation/index.html">Source separation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../qnn/index.html">Qualcomm NPU (QNN, HTP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rknn/index.html">rknn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ascend/index.html">Ascend NPU (昇腾 NPU)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tts/index.html">Text-to-speech (TTS)</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../triton/overview.html">Triton</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">sherpa</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">sherpa-onnx</a> &raquo;</li>
          <li><a href="../../index.html">Pre-trained models</a> &raquo;</li>
          <li><a href="../index.html">Offline CTC models</a> &raquo;</li>
      <li>WeNet CTC-based models</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/k2-fsa/sherpa/blob/master/docs/source/onnx/pretrained_models/offline-ctc/wenet/index.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="wenet-ctc-based-models">
<span id="wenet-offline-ctc"></span><h1>WeNet CTC-based models<a class="headerlink" href="#wenet-ctc-based-models" title="Permalink to this heading"></a></h1>
<p>This page lists all offline CTC models from <a class="reference external" href="https://github.com/wenet-e2e/wenet">WeNet</a>.</p>
<section id="sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03">
<span id="id1"></span><h2>sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03 (吴语)<a class="headerlink" href="#sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03" title="Permalink to this heading"></a></h2>
<p>This model is converted from</p>
<blockquote>
<div><p><a class="reference external" href="https://huggingface.co/ASLP-lab/WenetSpeech-Wu-Speech-Understanding/tree/main/u2++">https://huggingface.co/ASLP-lab/WenetSpeech-Wu-Speech-Understanding/tree/main/u2++</a></p>
</div></blockquote>
<p>It uses 8k hours of training data.</p>
<p>It supports Shanghainese, Suzhounese, Shaoxingnese, Ningbonese, Hangzhounese, Jiaxingnese, Taizhounese, and Wenzhounese.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>该模型支持</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>普通话</p></li>
<li><p>上海话</p></li>
<li><p>苏州话</p></li>
<li><p>绍兴话</p></li>
<li><p>宁波话</p></li>
<li><p>杭州话</p></li>
<li><p>嘉兴话</p></li>
<li><p>台州话</p></li>
<li><p>温州话</p></li>
</ol>
</div></blockquote>
</div>
<section id="huggingface-space">
<h3>Huggingface space<a class="headerlink" href="#huggingface-space" title="Permalink to this heading"></a></h3>
<p>You can visit</p>
<blockquote>
<div><p><a class="reference external" href="https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition">https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition</a></p>
</div></blockquote>
<p>to try this model in your browser.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You need to first select the language <code class="docutils literal notranslate"><span class="pre">吴语</span></code>
and then select the model  <code class="docutils literal notranslate"><span class="pre">csukuangfj2/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03</span></code>.</p>
</div>
</section>
<section id="android-apks">
<h3>Android APKs<a class="headerlink" href="#android-apks" title="Permalink to this heading"></a></h3>
<p>Real-time speech recognition Android APKs can be found at</p>
<blockquote>
<div><p><a class="reference external" href="https://k2-fsa.github.io/sherpa/onnx/android/apk-simulate-streaming-asr.html">https://k2-fsa.github.io/sherpa/onnx/android/apk-simulate-streaming-asr.html</a></p>
</div></blockquote>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Please always download the latest version.</p>
<p>Please search for <code class="docutils literal notranslate"><span class="pre">wu-wenetspeech_wu_u2pconformer_ctc_2026_02_03</span></code>.</p>
</div>
</section>
<section id="download">
<h3>Download<a class="headerlink" href="#download" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span>

<span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">k2</span><span class="o">-</span><span class="n">fsa</span><span class="o">/</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">/</span><span class="n">releases</span><span class="o">/</span><span class="n">download</span><span class="o">/</span><span class="n">asr</span><span class="o">-</span><span class="n">models</span><span class="o">/</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">wu</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2026</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mf">03.</span><span class="n">tar</span><span class="o">.</span><span class="n">bz2</span>
<span class="n">tar</span> <span class="n">xf</span> <span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">wu</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2026</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mf">03.</span><span class="n">tar</span><span class="o">.</span><span class="n">bz2</span>
<span class="n">rm</span> <span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">wu</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2026</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mf">03.</span><span class="n">tar</span><span class="o">.</span><span class="n">bz2</span>
</pre></div>
</div>
<p>After downloading, you should find the following files:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ls</span> <span class="o">-</span><span class="n">lh</span> <span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">wu</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2026</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">03</span><span class="o">/</span>
<span class="n">total</span> <span class="mi">264120</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">127</span><span class="n">M</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="n">model</span><span class="o">.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">239</span><span class="n">B</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="n">README</span><span class="o">.</span><span class="n">md</span>
<span class="n">drwxr</span><span class="o">-</span><span class="n">xr</span><span class="o">-</span><span class="n">x</span><span class="o">@</span> <span class="mi">27</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">864</span><span class="n">B</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="n">test_wavs</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span>  <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>    <span class="mi">51</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="n">tokens</span><span class="o">.</span><span class="n">txt</span>

<span class="n">ls</span> <span class="o">-</span><span class="n">lh</span> <span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">wu</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2026</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">03</span><span class="o">/</span><span class="n">test_wavs</span><span class="o">/</span>
<span class="n">total</span> <span class="mi">10888</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">184</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">1.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">238</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">10.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">228</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">11.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">179</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">12.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">214</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">13.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">374</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">14.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">383</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">15.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">181</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">16.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">181</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">17.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">186</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">18.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">181</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">19.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">183</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">2.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">238</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">20.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">193</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">21.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">184</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">22.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">264</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">23.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">180</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">24.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">251</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">3.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">229</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">4.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">257</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">5.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">218</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">6.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">241</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">7.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">183</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">8.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">234</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="mf">9.</span><span class="n">wav</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--@</span> <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mf">2.0</span><span class="n">K</span>  <span class="mi">3</span> <span class="n">Feb</span> <span class="mi">18</span><span class="p">:</span><span class="mi">44</span> <span class="n">transcript</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
</section>
<section id="real-time-streaming-speech-recognition-from-a-microphone-with-vad">
<h3>Real-time/Streaming Speech recognition from a microphone with VAD<a class="headerlink" href="#real-time-streaming-speech-recognition-from-a-microphone-with-vad" title="Permalink to this heading"></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">k2</span><span class="o">-</span><span class="n">fsa</span><span class="o">/</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">/</span><span class="n">releases</span><span class="o">/</span><span class="n">download</span><span class="o">/</span><span class="n">asr</span><span class="o">-</span><span class="n">models</span><span class="o">/</span><span class="n">silero_vad</span><span class="o">.</span><span class="n">onnx</span>

<span class="o">./</span><span class="n">build</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">vad</span><span class="o">-</span><span class="n">microphone</span><span class="o">-</span><span class="n">simulated</span><span class="o">-</span><span class="n">streaming</span><span class="o">-</span><span class="n">asr</span> \
  <span class="o">--</span><span class="n">silero</span><span class="o">-</span><span class="n">vad</span><span class="o">-</span><span class="n">model</span><span class="o">=./</span><span class="n">silero_vad</span><span class="o">.</span><span class="n">onnx</span> \
  <span class="o">--</span><span class="n">tokens</span><span class="o">=./</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">wu</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2026</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">03</span><span class="o">/</span><span class="n">tokens</span><span class="o">.</span><span class="n">txt</span> \
  <span class="o">--</span><span class="n">wenet</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">model</span><span class="o">=./</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">wu</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2026</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">03</span><span class="o">/</span><span class="n">model</span><span class="o">.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span> \
  <span class="o">--</span><span class="n">num</span><span class="o">-</span><span class="n">threads</span><span class="o">=</span><span class="mi">1</span>
</pre></div>
</div>
</section>
<section id="decode-wave-files">
<h3>Decode wave files<a class="headerlink" href="#decode-wave-files" title="Permalink to this heading"></a></h3>
<section id="wav">
<h4>1.wav<a class="headerlink" href="#wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>1.wav</td>
    <td>
     <audio title="1.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/1.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    而宋子文搭子宋美龄搭子端纳呢侪没经过搜查
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/1.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/1.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.179 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/1.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;而宋子文搭子宋美龄搭子端纳呢侪没经过搜查&quot;, &quot;timestamps&quot;: [0.76, 1.00, 1.24, 1.44, 1.60, 1.72, 1.92, 2.16, 2.36, 2.52, 2.68, 2.92, 3.16, 3.36, 3.92, 4.24, 4.44, 4.64, 4.88, 5.12], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;而&quot;, &quot;宋&quot;, &quot;子&quot;, &quot;文&quot;, &quot;搭&quot;, &quot;子&quot;, &quot;宋&quot;, &quot;美&quot;, &quot;龄&quot;, &quot;搭&quot;, &quot;子&quot;, &quot;端&quot;, &quot;纳&quot;, &quot;呢&quot;, &quot;侪&quot;, &quot;没&quot;, &quot;经&quot;, &quot;过&quot;, &quot;搜&quot;, &quot;查&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.232 s
Real time factor (RTF): 0.232 / 5.880 = 0.039
</pre></div>
</div>
</section>
<section id="id2">
<h4>2.wav<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>2.wav</td>
    <td>
     <audio title="2.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/2.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    借搿个机会纷纷响应搿个辰光奥地利个老皇帝已经死脱了
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/2.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/2.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.166 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/2.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;借搿个机会纷纷响应搿个辰光奥地利的老皇帝已经死脱了&quot;, &quot;timestamps&quot;: [0.52, 0.72, 0.84, 0.96, 1.12, 1.32, 1.52, 1.72, 1.92, 3.00, 3.16, 3.24, 3.36, 3.52, 3.68, 3.84, 3.96, 4.12, 4.28, 4.44, 4.56, 4.64, 4.80, 4.96, 5.12], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;借&quot;, &quot;搿&quot;, &quot;个&quot;, &quot;机&quot;, &quot;会&quot;, &quot;纷&quot;, &quot;纷&quot;, &quot;响&quot;, &quot;应&quot;, &quot;搿&quot;, &quot;个&quot;, &quot;辰&quot;, &quot;光&quot;, &quot;奥&quot;, &quot;地&quot;, &quot;利&quot;, &quot;的&quot;, &quot;老&quot;, &quot;皇&quot;, &quot;帝&quot;, &quot;已&quot;, &quot;经&quot;, &quot;死&quot;, &quot;脱&quot;, &quot;了&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.234 s
Real time factor (RTF): 0.234 / 5.860 = 0.040
</pre></div>
</div>
</section>
<section id="id3">
<h4>3.wav<a class="headerlink" href="#id3" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>3.wav</td>
    <td>
     <audio title="3.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/3.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    呃大灰狼就跟山羊奶奶讲山羊奶奶侬一家头蹲阿拉决定拿这点物事侪送拨侬
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/3.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/3.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.187 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/3.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;呃大灰狼就跟山羊奶奶讲山羊奶奶侬一家头等阿拉酒弟拿这点物事侪送拨侬&quot;, &quot;timestamps&quot;: [0.96, 1.68, 1.80, 1.96, 2.08, 2.24, 2.36, 2.52, 2.68, 2.80, 2.92, 3.08, 3.20, 3.36, 3.52, 4.04, 4.20, 4.36, 4.52, 4.76, 5.40, 5.52, 5.68, 5.80, 5.96, 6.08, 6.20, 6.36, 6.48, 6.56, 6.72, 6.88, 7.04], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;呃&quot;, &quot;大&quot;, &quot;灰&quot;, &quot;狼&quot;, &quot;就&quot;, &quot;跟&quot;, &quot;山&quot;, &quot;羊&quot;, &quot;奶&quot;, &quot;奶&quot;, &quot;讲&quot;, &quot;山&quot;, &quot;羊&quot;, &quot;奶&quot;, &quot;奶&quot;, &quot;侬&quot;, &quot;一&quot;, &quot;家&quot;, &quot;头&quot;, &quot;等&quot;, &quot;阿&quot;, &quot;拉&quot;, &quot;酒&quot;, &quot;弟&quot;, &quot;拿&quot;, &quot;这&quot;, &quot;点&quot;, &quot;物&quot;, &quot;事&quot;, &quot;侪&quot;, &quot;送&quot;, &quot;拨&quot;, &quot;侬&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.320 s
Real time factor (RTF): 0.320 / 8.040 = 0.040
</pre></div>
</div>
</section>
<section id="id4">
<h4>4.wav<a class="headerlink" href="#id4" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>4.wav</td>
    <td>
     <audio title="4.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/4.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    胖胖又得意了啥人会得想到玩具汽车里头还囥了物事呢
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/4.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/4.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.171 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/4.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;胖胖又得意了呵啥人会得想到玩具汽车里头还囥了物事呢&quot;, &quot;timestamps&quot;: [1.64, 1.76, 1.92, 2.16, 2.32, 2.48, 2.84, 3.28, 3.44, 3.56, 3.68, 3.84, 4.04, 4.72, 4.96, 5.20, 5.44, 5.60, 5.76, 5.84, 6.00, 6.20, 6.32, 6.44, 6.60], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;胖&quot;, &quot;胖&quot;, &quot;又&quot;, &quot;得&quot;, &quot;意&quot;, &quot;了&quot;, &quot;呵&quot;, &quot;啥&quot;, &quot;人&quot;, &quot;会&quot;, &quot;得&quot;, &quot;想&quot;, &quot;到&quot;, &quot;玩&quot;, &quot;具&quot;, &quot;汽&quot;, &quot;车&quot;, &quot;里&quot;, &quot;头&quot;, &quot;还&quot;, &quot;囥&quot;, &quot;了&quot;, &quot;物&quot;, &quot;事&quot;, &quot;呢&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.294 s
Real time factor (RTF): 0.294 / 7.340 = 0.040
</pre></div>
</div>
</section>
<section id="id5">
<h4>5.wav<a class="headerlink" href="#id5" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>5.wav</td>
    <td>
     <audio title="5.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/5.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    这物事里头是有利益分配的讲好个埃种大生意难做一趟做两三年也做不出的
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/5.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/5.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.171 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/5.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;这物是里都是有利益分配的讲好的埃种大生意难做一趟做两三年也做不出的&quot;, &quot;timestamps&quot;: [0.48, 0.60, 0.76, 0.88, 1.04, 1.20, 1.48, 1.72, 1.92, 2.08, 2.28, 2.48, 2.64, 2.88, 3.08, 3.84, 4.04, 4.20, 4.40, 4.60, 4.84, 5.08, 5.28, 5.40, 6.28, 6.48, 6.72, 6.88, 7.00, 7.16, 7.28, 7.40, 7.56], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;这&quot;, &quot;物&quot;, &quot;是&quot;, &quot;里&quot;, &quot;都&quot;, &quot;是&quot;, &quot;有&quot;, &quot;利&quot;, &quot;益&quot;, &quot;分&quot;, &quot;配&quot;, &quot;的&quot;, &quot;讲&quot;, &quot;好&quot;, &quot;的&quot;, &quot;埃&quot;, &quot;种&quot;, &quot;大&quot;, &quot;生&quot;, &quot;意&quot;, &quot;难&quot;, &quot;做&quot;, &quot;一&quot;, &quot;趟&quot;, &quot;做&quot;, &quot;两&quot;, &quot;三&quot;, &quot;年&quot;, &quot;也&quot;, &quot;做&quot;, &quot;不&quot;, &quot;出&quot;, &quot;的&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.329 s
Real time factor (RTF): 0.329 / 8.220 = 0.040
</pre></div>
</div>
</section>
<section id="id6">
<h4>6.wav<a class="headerlink" href="#id6" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>6.wav</td>
    <td>
     <audio title="6.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/6.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    这个新生儿啊相对来讲偏少大家侪不愿意生嘛
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/6.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/6.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.168 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/6.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;这个新生儿啊相对来讲偏少大家侪不愿意伤嘛&quot;, &quot;timestamps&quot;: [0.48, 0.68, 1.84, 2.04, 2.28, 2.52, 3.08, 3.28, 3.40, 3.56, 3.76, 3.96, 4.68, 4.84, 4.96, 5.08, 5.20, 5.32, 5.48, 5.72], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;这&quot;, &quot;个&quot;, &quot;新&quot;, &quot;生&quot;, &quot;儿&quot;, &quot;啊&quot;, &quot;相&quot;, &quot;对&quot;, &quot;来&quot;, &quot;讲&quot;, &quot;偏&quot;, &quot;少&quot;, &quot;大&quot;, &quot;家&quot;, &quot;侪&quot;, &quot;不&quot;, &quot;愿&quot;, &quot;意&quot;, &quot;伤&quot;, &quot;嘛&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.279 s
Real time factor (RTF): 0.279 / 6.960 = 0.040
</pre></div>
</div>
</section>
<section id="id7">
<h4>7.wav<a class="headerlink" href="#id7" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>7.wav</td>
    <td>
     <audio title="7.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/7.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    这自然应该是像上海大都市这能介告诉伊虽然伊同样是外来的闲话
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/7.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/7.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.184 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/7.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;这自然应该是像上海大都市这样个告所以虽然同样是外来个闲话&quot;, &quot;timestamps&quot;: [0.48, 0.68, 0.84, 1.24, 1.40, 1.52, 1.68, 1.88, 2.08, 2.32, 2.56, 2.72, 2.88, 3.04, 3.16, 4.24, 4.44, 4.64, 5.36, 5.56, 5.80, 5.96, 6.12, 6.36, 6.52, 6.68, 6.80, 6.96], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;这&quot;, &quot;自&quot;, &quot;然&quot;, &quot;应&quot;, &quot;该&quot;, &quot;是&quot;, &quot;像&quot;, &quot;上&quot;, &quot;海&quot;, &quot;大&quot;, &quot;都&quot;, &quot;市&quot;, &quot;这&quot;, &quot;样&quot;, &quot;个&quot;, &quot;告&quot;, &quot;所&quot;, &quot;以&quot;, &quot;虽&quot;, &quot;然&quot;, &quot;同&quot;, &quot;样&quot;, &quot;是&quot;, &quot;外&quot;, &quot;来&quot;, &quot;个&quot;, &quot;闲&quot;, &quot;话&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.311 s
Real time factor (RTF): 0.311 / 7.720 = 0.040
</pre></div>
</div>
</section>
<section id="id8">
<h4>8.wav<a class="headerlink" href="#id8" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>8.wav</td>
    <td>
     <audio title="8.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/8.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    已经有西南亚洲的外国人居住辣辣埃及从事贸易活动
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/8.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/8.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.177 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/8.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;已经由西南亚洲的外国人居住辣辣埃及从事贸易活动&quot;, &quot;timestamps&quot;: [0.48, 0.64, 0.80, 1.08, 1.32, 1.60, 1.92, 2.08, 2.28, 2.48, 2.64, 2.88, 3.12, 3.32, 3.44, 3.64, 3.84, 4.04, 4.28, 4.64, 4.88, 5.00, 5.12], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;已&quot;, &quot;经&quot;, &quot;由&quot;, &quot;西&quot;, &quot;南&quot;, &quot;亚&quot;, &quot;洲&quot;, &quot;的&quot;, &quot;外&quot;, &quot;国&quot;, &quot;人&quot;, &quot;居&quot;, &quot;住&quot;, &quot;辣&quot;, &quot;辣&quot;, &quot;埃&quot;, &quot;及&quot;, &quot;从&quot;, &quot;事&quot;, &quot;贸&quot;, &quot;易&quot;, &quot;活&quot;, &quot;动&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.233 s
Real time factor (RTF): 0.233 / 5.860 = 0.040
</pre></div>
</div>
</section>
<section id="id9">
<h4>9.wav<a class="headerlink" href="#id9" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>9.wav</td>
    <td>
     <audio title="9.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/9.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    青春的舞龙唱出短暂的曲子的清风里后世
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/9.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/9.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.171 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/9.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;清脆的舞咙唱出婉转的曲子搭清风的流&quot;, &quot;timestamps&quot;: [0.56, 0.88, 1.16, 1.32, 1.56, 2.48, 2.76, 3.24, 3.56, 3.84, 4.16, 4.36, 5.36, 5.84, 6.20, 6.40, 6.56], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;清&quot;, &quot;脆&quot;, &quot;的&quot;, &quot;舞&quot;, &quot;咙&quot;, &quot;唱&quot;, &quot;出&quot;, &quot;婉&quot;, &quot;转&quot;, &quot;的&quot;, &quot;曲&quot;, &quot;子&quot;, &quot;搭&quot;, &quot;清&quot;, &quot;风&quot;, &quot;的&quot;, &quot;流&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.298 s
Real time factor (RTF): 0.298 / 7.480 = 0.040
</pre></div>
</div>
</section>
<section id="id10">
<h4>10.wav<a class="headerlink" href="#id10" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>10.wav</td>
    <td>
     <audio title="10.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/10.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    肠道菌群也就是阿拉肠道当中不同种类的细菌等微生物会的影响大脑的健康
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/10.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/10.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.166 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/10.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;肠道菌群也就是阿拉肠道当中不同种类的细菌等微生物会得影响大脑的健康&quot;, &quot;timestamps&quot;: [0.64, 0.88, 1.12, 1.32, 2.44, 2.60, 2.72, 2.80, 2.88, 3.04, 3.20, 3.32, 3.48, 3.60, 3.72, 3.92, 4.08, 4.24, 4.36, 4.56, 4.76, 5.00, 5.20, 5.36, 5.52, 5.64, 5.76, 5.96, 6.16, 6.32, 6.48, 6.60, 6.80], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;肠&quot;, &quot;道&quot;, &quot;菌&quot;, &quot;群&quot;, &quot;也&quot;, &quot;就&quot;, &quot;是&quot;, &quot;阿&quot;, &quot;拉&quot;, &quot;肠&quot;, &quot;道&quot;, &quot;当&quot;, &quot;中&quot;, &quot;不&quot;, &quot;同&quot;, &quot;种&quot;, &quot;类&quot;, &quot;的&quot;, &quot;细&quot;, &quot;菌&quot;, &quot;等&quot;, &quot;微&quot;, &quot;生&quot;, &quot;物&quot;, &quot;会&quot;, &quot;得&quot;, &quot;影&quot;, &quot;响&quot;, &quot;大&quot;, &quot;脑&quot;, &quot;的&quot;, &quot;健&quot;, &quot;康&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.302 s
Real time factor (RTF): 0.302 / 7.600 = 0.040
</pre></div>
</div>
</section>
<section id="id11">
<h4>11.wav<a class="headerlink" href="#id11" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>11.wav</td>
    <td>
     <audio title="11.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/11.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    老百姓大家知了伊也勿中浪向摊头浪向吃两碗豆腐花
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/11.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/11.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.166 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/11.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;老百姓大家醉了伊也勿中浪向摊头浪向吃两碗豆腐花&quot;, &quot;timestamps&quot;: [0.60, 0.88, 1.04, 1.28, 1.48, 1.72, 1.92, 2.08, 2.20, 2.40, 3.64, 3.96, 4.20, 4.60, 4.84, 5.00, 5.24, 5.52, 5.68, 5.88, 6.12, 6.28, 6.44], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;老&quot;, &quot;百&quot;, &quot;姓&quot;, &quot;大&quot;, &quot;家&quot;, &quot;醉&quot;, &quot;了&quot;, &quot;伊&quot;, &quot;也&quot;, &quot;勿&quot;, &quot;中&quot;, &quot;浪&quot;, &quot;向&quot;, &quot;摊&quot;, &quot;头&quot;, &quot;浪&quot;, &quot;向&quot;, &quot;吃&quot;, &quot;两&quot;, &quot;碗&quot;, &quot;豆&quot;, &quot;腐&quot;, &quot;花&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.292 s
Real time factor (RTF): 0.292 / 7.300 = 0.040
</pre></div>
</div>
</section>
<section id="id12">
<h4>12.wav<a class="headerlink" href="#id12" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>12.wav</td>
    <td>
     <audio title="12.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/12.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    孙女告娘当我儿子看我讲的闲话
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/12.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/12.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.172 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/12.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;孙权的娘当我儿子的我讲的闲话&quot;, &quot;timestamps&quot;: [0.60, 1.08, 1.24, 1.44, 1.80, 1.96, 2.20, 2.52, 2.80, 3.88, 4.24, 4.44, 4.60, 4.80], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;孙&quot;, &quot;权&quot;, &quot;的&quot;, &quot;娘&quot;, &quot;当&quot;, &quot;我&quot;, &quot;儿&quot;, &quot;子&quot;, &quot;的&quot;, &quot;我&quot;, &quot;讲&quot;, &quot;的&quot;, &quot;闲&quot;, &quot;话&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.226 s
Real time factor (RTF): 0.226 / 5.740 = 0.039
</pre></div>
</div>
</section>
<section id="id13">
<h4>13.wav<a class="headerlink" href="#id13" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>13.wav</td>
    <td>
     <audio title="13.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/13.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    呃对伐现在实际上是新上海人越来越多了外加未来我觉着这群新上海人会得取代脱阿拉
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/13.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/13.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.164 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/13.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;啊对伐现在实际上是新上海人越来越多了外加未来我觉着这句新上海人会的取略脱阿拉&quot;, &quot;timestamps&quot;: [0.52, 0.88, 1.04, 1.24, 1.32, 1.44, 1.56, 1.64, 1.76, 2.12, 2.28, 2.44, 2.52, 2.64, 2.72, 2.84, 2.92, 3.04, 3.40, 3.52, 3.76, 3.88, 4.04, 4.12, 4.24, 4.72, 4.84, 4.96, 5.08, 5.20, 5.32, 5.40, 5.48, 5.60, 5.72, 5.84, 5.96, 6.04], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;啊&quot;, &quot;对&quot;, &quot;伐&quot;, &quot;现&quot;, &quot;在&quot;, &quot;实&quot;, &quot;际&quot;, &quot;上&quot;, &quot;是&quot;, &quot;新&quot;, &quot;上&quot;, &quot;海&quot;, &quot;人&quot;, &quot;越&quot;, &quot;来&quot;, &quot;越&quot;, &quot;多&quot;, &quot;了&quot;, &quot;外&quot;, &quot;加&quot;, &quot;未&quot;, &quot;来&quot;, &quot;我&quot;, &quot;觉&quot;, &quot;着&quot;, &quot;这&quot;, &quot;句&quot;, &quot;新&quot;, &quot;上&quot;, &quot;海&quot;, &quot;人&quot;, &quot;会&quot;, &quot;的&quot;, &quot;取&quot;, &quot;略&quot;, &quot;脱&quot;, &quot;阿&quot;, &quot;拉&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.272 s
Real time factor (RTF): 0.272 / 6.840 = 0.040
</pre></div>
</div>
</section>
<section id="id14">
<h4>14.wav<a class="headerlink" href="#id14" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>14.wav</td>
    <td>
     <audio title="14.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/14.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    有搿种爷娘对伐但是我觉着现在好像就讲上海哦现在勿是侪讲房子也没人住嘛外国人跑得一批还有就是叫低生育率帮低结婚率嗯
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/14.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/14.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.179 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/14.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;呃有搿种爷娘对伐但是我觉着现在好像就讲上海哦现在勿是侪讲房子也没人住嘛外国人跑得一批还有就是叫低生育率帮低结婚率嗯&quot;, &quot;timestamps&quot;: [0.48, 0.72, 0.84, 1.04, 1.16, 1.36, 1.68, 1.80, 2.04, 2.16, 2.28, 2.40, 2.52, 2.68, 2.84, 3.00, 3.16, 3.48, 3.60, 3.80, 3.96, 4.08, 4.28, 4.40, 4.60, 4.72, 4.88, 5.04, 5.24, 5.40, 5.68, 5.84, 5.96, 6.12, 6.32, 6.60, 6.76, 6.88, 7.00, 7.16, 7.24, 7.36, 7.48, 7.60, 7.68, 7.80, 7.88, 8.20, 8.56, 8.80, 9.00, 9.36, 9.68, 9.92, 10.08, 10.24, 10.52], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;呃&quot;, &quot;有&quot;, &quot;搿&quot;, &quot;种&quot;, &quot;爷&quot;, &quot;娘&quot;, &quot;对&quot;, &quot;伐&quot;, &quot;但&quot;, &quot;是&quot;, &quot;我&quot;, &quot;觉&quot;, &quot;着&quot;, &quot;现&quot;, &quot;在&quot;, &quot;好&quot;, &quot;像&quot;, &quot;就&quot;, &quot;讲&quot;, &quot;上&quot;, &quot;海&quot;, &quot;哦&quot;, &quot;现&quot;, &quot;在&quot;, &quot;勿&quot;, &quot;是&quot;, &quot;侪&quot;, &quot;讲&quot;, &quot;房&quot;, &quot;子&quot;, &quot;也&quot;, &quot;没&quot;, &quot;人&quot;, &quot;住&quot;, &quot;嘛&quot;, &quot;外&quot;, &quot;国&quot;, &quot;人&quot;, &quot;跑&quot;, &quot;得&quot;, &quot;一&quot;, &quot;批&quot;, &quot;还&quot;, &quot;有&quot;, &quot;就&quot;, &quot;是&quot;, &quot;叫&quot;, &quot;低&quot;, &quot;生&quot;, &quot;育&quot;, &quot;率&quot;, &quot;帮&quot;, &quot;低&quot;, &quot;结&quot;, &quot;婚&quot;, &quot;率&quot;, &quot;嗯&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.489 s
Real time factor (RTF): 0.489 / 11.960 = 0.041
</pre></div>
</div>
</section>
<section id="id15">
<h4>15.wav<a class="headerlink" href="#id15" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>15.wav</td>
    <td>
     <audio title="15.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/15.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    当侬老了一个人头发花白坐辣盖落花旁边轻轻的从书架上面取下一本书来慢慢叫的阅读
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/15.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/15.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.172 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/15.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;当侬老了一个人头发花白坐辣盖芦花旁边轻轻的从书界上面取下一本书来慢慢叫的阅读&quot;, &quot;timestamps&quot;: [0.48, 0.72, 1.04, 1.36, 2.92, 3.08, 3.24, 3.68, 3.88, 4.08, 4.32, 5.20, 5.40, 5.52, 5.72, 5.92, 6.16, 6.40, 7.08, 7.32, 7.52, 7.84, 8.04, 8.24, 8.44, 8.68, 8.96, 9.16, 9.32, 9.48, 9.68, 9.96, 10.44, 10.68, 10.84, 11.00, 11.16, 11.32], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;当&quot;, &quot;侬&quot;, &quot;老&quot;, &quot;了&quot;, &quot;一&quot;, &quot;个&quot;, &quot;人&quot;, &quot;头&quot;, &quot;发&quot;, &quot;花&quot;, &quot;白&quot;, &quot;坐&quot;, &quot;辣&quot;, &quot;盖&quot;, &quot;芦&quot;, &quot;花&quot;, &quot;旁&quot;, &quot;边&quot;, &quot;轻&quot;, &quot;轻&quot;, &quot;的&quot;, &quot;从&quot;, &quot;书&quot;, &quot;界&quot;, &quot;上&quot;, &quot;面&quot;, &quot;取&quot;, &quot;下&quot;, &quot;一&quot;, &quot;本&quot;, &quot;书&quot;, &quot;来&quot;, &quot;慢&quot;, &quot;慢&quot;, &quot;叫&quot;, &quot;的&quot;, &quot;阅&quot;, &quot;读&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.505 s
Real time factor (RTF): 0.505 / 12.240 = 0.041
</pre></div>
</div>
</section>
<section id="id16">
<h4>16.wav<a class="headerlink" href="#id16" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>16.wav</td>
    <td>
     <audio title="16.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/16.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    伴着夕阳的余晖一切侪是最美好的样子
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/16.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/16.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.178 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/16.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;伴着夕洋个余晖一切侪是最美好个样子&quot;, &quot;timestamps&quot;: [0.48, 0.72, 1.00, 1.20, 1.40, 1.60, 1.84, 2.60, 2.80, 3.16, 3.36, 3.56, 3.80, 4.08, 4.32, 4.48, 4.80], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;伴&quot;, &quot;着&quot;, &quot;夕&quot;, &quot;洋&quot;, &quot;个&quot;, &quot;余&quot;, &quot;晖&quot;, &quot;一&quot;, &quot;切&quot;, &quot;侪&quot;, &quot;是&quot;, &quot;最&quot;, &quot;美&quot;, &quot;好&quot;, &quot;个&quot;, &quot;样&quot;, &quot;子&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.239 s
Real time factor (RTF): 0.239 / 5.780 = 0.041
</pre></div>
</div>
</section>
<section id="id17">
<h4>17.wav<a class="headerlink" href="#id17" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>17.wav</td>
    <td>
     <audio title="17.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/17.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    勿晓得个呀老早勿是讲旧社会个辰光嘛搿种流氓阿了
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/17.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/17.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.176 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/17.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;勿晓得个呀老早勿是讲旧社会个辰光嘛搿种流氓也费了&quot;, &quot;timestamps&quot;: [0.52, 0.68, 0.80, 0.96, 1.04, 2.24, 2.40, 2.48, 2.56, 2.64, 2.76, 2.92, 3.08, 3.20, 3.32, 3.44, 3.64, 3.76, 3.84, 4.56, 4.76, 4.84, 4.96, 5.12], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;勿&quot;, &quot;晓&quot;, &quot;得&quot;, &quot;个&quot;, &quot;呀&quot;, &quot;老&quot;, &quot;早&quot;, &quot;勿&quot;, &quot;是&quot;, &quot;讲&quot;, &quot;旧&quot;, &quot;社&quot;, &quot;会&quot;, &quot;个&quot;, &quot;辰&quot;, &quot;光&quot;, &quot;嘛&quot;, &quot;搿&quot;, &quot;种&quot;, &quot;流&quot;, &quot;氓&quot;, &quot;也&quot;, &quot;费&quot;, &quot;了&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.232 s
Real time factor (RTF): 0.232 / 5.780 = 0.040
</pre></div>
</div>
</section>
<section id="id18">
<h4>18.wav<a class="headerlink" href="#id18" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>18.wav</td>
    <td>
     <audio title="18.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/18.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    观众朋友们就是教个小诀窍就是屋里向大家一直拌馄饨芯子啊
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/18.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/18.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.183 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/18.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;观众朋友们就是教搞小诀窍就是屋里向大家一直拌馄饨芯子啊&quot;, &quot;timestamps&quot;: [0.44, 0.60, 0.76, 0.92, 1.04, 1.20, 1.32, 1.80, 2.00, 2.16, 2.32, 2.48, 2.88, 3.04, 3.32, 3.44, 3.56, 3.80, 3.96, 4.08, 4.16, 4.36, 4.56, 4.72, 4.88, 5.04, 5.20], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;观&quot;, &quot;众&quot;, &quot;朋&quot;, &quot;友&quot;, &quot;们&quot;, &quot;就&quot;, &quot;是&quot;, &quot;教&quot;, &quot;搞&quot;, &quot;小&quot;, &quot;诀&quot;, &quot;窍&quot;, &quot;就&quot;, &quot;是&quot;, &quot;屋&quot;, &quot;里&quot;, &quot;向&quot;, &quot;大&quot;, &quot;家&quot;, &quot;一&quot;, &quot;直&quot;, &quot;拌&quot;, &quot;馄&quot;, &quot;饨&quot;, &quot;芯&quot;, &quot;子&quot;, &quot;啊&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.243 s
Real time factor (RTF): 0.243 / 5.940 = 0.041
</pre></div>
</div>
</section>
<section id="id19">
<h4>19.wav<a class="headerlink" href="#id19" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>19.wav</td>
    <td>
     <audio title="19.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/19.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    哦对的对的侬讲了对的哎哟这小米侬还是侬脑子好
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/19.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/19.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.182 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/19.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;哦对的对的侬讲了对的哎哟迭小米侬还是侬脑子好&quot;, &quot;timestamps&quot;: [0.48, 1.12, 1.32, 2.08, 2.20, 2.32, 2.44, 2.56, 2.64, 2.80, 3.16, 3.32, 3.64, 3.76, 3.92, 4.04, 4.24, 4.36, 4.52, 4.68, 4.84, 5.00], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;哦&quot;, &quot;对&quot;, &quot;的&quot;, &quot;对&quot;, &quot;的&quot;, &quot;侬&quot;, &quot;讲&quot;, &quot;了&quot;, &quot;对&quot;, &quot;的&quot;, &quot;哎&quot;, &quot;哟&quot;, &quot;迭&quot;, &quot;小&quot;, &quot;米&quot;, &quot;侬&quot;, &quot;还&quot;, &quot;是&quot;, &quot;侬&quot;, &quot;脑&quot;, &quot;子&quot;, &quot;好&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.233 s
Real time factor (RTF): 0.233 / 5.780 = 0.040
</pre></div>
</div>
</section>
<section id="id20">
<h4>20.wav<a class="headerlink" href="#id20" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>20.wav</td>
    <td>
     <audio title="20.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/20.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    嗯沿海各地包括㑚南翔连是日本海的前头一个费城
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/20.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/20.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.176 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/20.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;嗯沿海各地包括南南洋嗯伊是日本海达集头一个返城&quot;, &quot;timestamps&quot;: [0.48, 1.64, 1.88, 2.08, 2.24, 2.56, 2.72, 2.88, 3.16, 3.36, 3.72, 4.20, 4.36, 4.56, 4.76, 5.04, 5.32, 5.72, 5.88, 6.16, 6.28, 6.48, 6.76], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;嗯&quot;, &quot;沿&quot;, &quot;海&quot;, &quot;各&quot;, &quot;地&quot;, &quot;包&quot;, &quot;括&quot;, &quot;南&quot;, &quot;南&quot;, &quot;洋&quot;, &quot;嗯&quot;, &quot;伊&quot;, &quot;是&quot;, &quot;日&quot;, &quot;本&quot;, &quot;海&quot;, &quot;达&quot;, &quot;集&quot;, &quot;头&quot;, &quot;一&quot;, &quot;个&quot;, &quot;返&quot;, &quot;城&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.311 s
Real time factor (RTF): 0.311 / 7.600 = 0.041
</pre></div>
</div>
</section>
<section id="id21">
<h4>21.wav<a class="headerlink" href="#id21" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>21.wav</td>
    <td>
     <audio title="21.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/21.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    侬就没命了为了不叫类似的事体再发生张晨
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/21.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/21.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.174 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/21.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;侬就没命了为了不让类似的事体再发生张晨&quot;, &quot;timestamps&quot;: [0.60, 0.76, 0.96, 1.16, 1.32, 2.24, 2.40, 2.52, 2.68, 2.96, 3.24, 3.40, 3.52, 3.60, 3.76, 3.92, 4.04, 4.96, 5.24], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;侬&quot;, &quot;就&quot;, &quot;没&quot;, &quot;命&quot;, &quot;了&quot;, &quot;为&quot;, &quot;了&quot;, &quot;不&quot;, &quot;让&quot;, &quot;类&quot;, &quot;似&quot;, &quot;的&quot;, &quot;事&quot;, &quot;体&quot;, &quot;再&quot;, &quot;发&quot;, &quot;生&quot;, &quot;张&quot;, &quot;晨&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.252 s
Real time factor (RTF): 0.252 / 6.160 = 0.041
</pre></div>
</div>
</section>
<section id="id22">
<h4>22.wav<a class="headerlink" href="#id22" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>22.wav</td>
    <td>
     <audio title="22.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/22.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    其实这两年我也就是行尸走肉因为老婆没了
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/22.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/22.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.177 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/22.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;其实这两年我也就是行势走肉因为老婆没了&quot;, &quot;timestamps&quot;: [0.56, 0.72, 0.84, 1.00, 1.16, 1.32, 1.48, 1.60, 1.76, 2.16, 2.44, 2.72, 2.92, 4.32, 4.44, 4.64, 4.80, 4.96, 5.08], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;其&quot;, &quot;实&quot;, &quot;这&quot;, &quot;两&quot;, &quot;年&quot;, &quot;我&quot;, &quot;也&quot;, &quot;就&quot;, &quot;是&quot;, &quot;行&quot;, &quot;势&quot;, &quot;走&quot;, &quot;肉&quot;, &quot;因&quot;, &quot;为&quot;, &quot;老&quot;, &quot;婆&quot;, &quot;没&quot;, &quot;了&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.240 s
Real time factor (RTF): 0.240 / 5.900 = 0.041
</pre></div>
</div>
</section>
<section id="id23">
<h4>23.wav<a class="headerlink" href="#id23" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>23.wav</td>
    <td>
     <audio title="23.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/23.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    对的呀末伊拉这评论里向有种侬要讲一个人真个红了对勿啦就讲侬粉丝超过一万了嘛侬这种黑粉丝多
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/23.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/23.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.171 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/23.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;对的呀对么伊拉搿评论里向有种侬要讲一个人真个红了对伐啦就讲侬粉丝超过一万了嘛侬搿种黑粉是多&quot;, &quot;timestamps&quot;: [0.48, 0.60, 0.68, 0.80, 0.88, 1.28, 1.36, 1.48, 1.68, 1.84, 2.00, 2.12, 2.32, 2.48, 2.84, 3.00, 3.16, 3.56, 3.68, 3.80, 4.40, 4.56, 4.72, 4.92, 5.00, 5.12, 5.20, 5.36, 5.52, 5.68, 5.80, 5.96, 6.12, 6.24, 6.36, 6.48, 6.60, 6.72, 6.92, 7.00, 7.12, 7.24, 7.40, 7.56, 7.76], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;对&quot;, &quot;的&quot;, &quot;呀&quot;, &quot;对&quot;, &quot;么&quot;, &quot;伊&quot;, &quot;拉&quot;, &quot;搿&quot;, &quot;评&quot;, &quot;论&quot;, &quot;里&quot;, &quot;向&quot;, &quot;有&quot;, &quot;种&quot;, &quot;侬&quot;, &quot;要&quot;, &quot;讲&quot;, &quot;一&quot;, &quot;个&quot;, &quot;人&quot;, &quot;真&quot;, &quot;个&quot;, &quot;红&quot;, &quot;了&quot;, &quot;对&quot;, &quot;伐&quot;, &quot;啦&quot;, &quot;就&quot;, &quot;讲&quot;, &quot;侬&quot;, &quot;粉&quot;, &quot;丝&quot;, &quot;超&quot;, &quot;过&quot;, &quot;一&quot;, &quot;万&quot;, &quot;了&quot;, &quot;嘛&quot;, &quot;侬&quot;, &quot;搿&quot;, &quot;种&quot;, &quot;黑&quot;, &quot;粉&quot;, &quot;是&quot;, &quot;多&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.346 s
Real time factor (RTF): 0.346 / 8.460 = 0.041
</pre></div>
</div>
</section>
<section id="id24">
<h4>24.wav<a class="headerlink" href="#id24" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>24.wav</td>
    <td>
     <audio title="24.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/24.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    正常保养电池呃电瓶啊搿种轮胎啊还有
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/24.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:373 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx --num-threads=1 ./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/24.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), omnilingual=OfflineOmnilingualAsrCtcModelConfig(model=&quot;&quot;), funasr_nano=OfflineFunASRNanoModelConfig(encoder_adaptor=&quot;&quot;, llm=&quot;&quot;, embedding=&quot;&quot;, tokenizer=&quot;&quot;, system_prompt=&quot;You are a helpful assistant.&quot;, user_prompt=&quot;语音转写：&quot;, max_new_tokens=512, temperature=1e-06, top_p=0.8, seed=42), medasr=OfflineMedAsrCtcModelConfig(model=&quot;&quot;), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
recognizer created in 0.184 s
Started
Done!

./sherpa-onnx-wenetspeech-wu-u2pp-conformer-ctc-zh-int8-2026-02-03/test_wavs/24.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;正常保养电视呃电瓶啊搿种轮胎啊还有&quot;, &quot;timestamps&quot;: [0.48, 0.64, 0.76, 0.96, 1.28, 1.44, 1.64, 1.92, 2.04, 2.20, 2.80, 3.00, 3.20, 3.36, 3.56, 4.44, 4.60], &quot;durations&quot;: [], &quot;tokens&quot;:[&quot;正&quot;, &quot;常&quot;, &quot;保&quot;, &quot;养&quot;, &quot;电&quot;, &quot;视&quot;, &quot;呃&quot;, &quot;电&quot;, &quot;瓶&quot;, &quot;啊&quot;, &quot;搿&quot;, &quot;种&quot;, &quot;轮&quot;, &quot;胎&quot;, &quot;啊&quot;, &quot;还&quot;, &quot;有&quot;], &quot;ys_log_probs&quot;: [], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.233 s
Real time factor (RTF): 0.233 / 5.760 = 0.040
</pre></div>
</div>
</section>
</section>
</section>
<section id="sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10-cantonese">
<span id="sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10"></span><h2>sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10 (Cantonese, 粤语)<a class="headerlink" href="#sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10-cantonese" title="Permalink to this heading"></a></h2>
<p>This model is converted from</p>
<blockquote>
<div><p><a class="reference external" href="https://huggingface.co/ASLP-lab/WSYue-ASR/tree/main/u2pp_conformer_yue">https://huggingface.co/ASLP-lab/WSYue-ASR/tree/main/u2pp_conformer_yue</a></p>
</div></blockquote>
<p>It uses 21.8k hours of training data.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If you want a <code class="docutils literal notranslate"><span class="pre">Cantonese</span></code> ASR model, please choose this model
or <a class="reference internal" href="../../../sense-voice/pretrained.html#sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09"><span class="std std-ref">sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09 (Chinese, English, Japanese, Korean, Cantonese, 中英日韩粤语)</span></a></p>
</div>
<section id="id25">
<h3>Huggingface space<a class="headerlink" href="#id25" title="Permalink to this heading"></a></h3>
<p>You can visit</p>
<blockquote>
<div><p><a class="reference external" href="https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition">https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition</a></p>
</div></blockquote>
<p>to try this model in your browser.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You need to first select the language <code class="docutils literal notranslate"><span class="pre">Cantonese</span></code>
and then select the model  <code class="docutils literal notranslate"><span class="pre">csukuangfj/sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10</span></code>.</p>
</div>
</section>
<section id="id27">
<h3>Android APKs<a class="headerlink" href="#id27" title="Permalink to this heading"></a></h3>
<p>Real-time speech recognition Android APKs can be found at</p>
<blockquote>
<div><p><a class="reference external" href="https://k2-fsa.github.io/sherpa/onnx/android/apk-simulate-streaming-asr.html">https://k2-fsa.github.io/sherpa/onnx/android/apk-simulate-streaming-asr.html</a></p>
</div></blockquote>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Please always download the latest version.</p>
<p>Please search for <code class="docutils literal notranslate"><span class="pre">wenetspeech_yue_u2pconformer_ctc_2025_09_10</span></code>.</p>
</div>
</section>
<section id="id29">
<h3>Download<a class="headerlink" href="#id29" title="Permalink to this heading"></a></h3>
<p>Please use the following commands to download it:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span>

<span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">k2</span><span class="o">-</span><span class="n">fsa</span><span class="o">/</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">/</span><span class="n">releases</span><span class="o">/</span><span class="n">download</span><span class="o">/</span><span class="n">asr</span><span class="o">-</span><span class="n">models</span><span class="o">/</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">yue</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">en</span><span class="o">-</span><span class="n">cantonese</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mf">10.</span><span class="n">tar</span><span class="o">.</span><span class="n">bz2</span>
<span class="n">tar</span> <span class="n">xf</span> <span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">yue</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">en</span><span class="o">-</span><span class="n">cantonese</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mf">10.</span><span class="n">tar</span><span class="o">.</span><span class="n">bz2</span>
<span class="n">rm</span> <span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">yue</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">en</span><span class="o">-</span><span class="n">cantonese</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mf">10.</span><span class="n">tar</span><span class="o">.</span><span class="n">bz2</span>
</pre></div>
</div>
<p>After downloading, you should find the following files:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ls</span> <span class="o">-</span><span class="n">lh</span> <span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">yue</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">en</span><span class="o">-</span><span class="n">cantonese</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">10</span><span class="o">/</span>

<span class="n">total</span> <span class="mi">263264</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">129</span><span class="n">B</span> <span class="n">Sep</span> <span class="mi">10</span> <span class="mi">14</span><span class="p">:</span><span class="mi">18</span> <span class="n">README</span><span class="o">.</span><span class="n">md</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">128</span><span class="n">M</span> <span class="n">Sep</span> <span class="mi">10</span> <span class="mi">14</span><span class="p">:</span><span class="mi">18</span> <span class="n">model</span><span class="o">.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span>
<span class="n">drwxr</span><span class="o">-</span><span class="n">xr</span><span class="o">-</span><span class="n">x</span>  <span class="mi">22</span> <span class="n">fangjun</span>  <span class="n">staff</span>   <span class="mi">704</span><span class="n">B</span> <span class="n">Sep</span> <span class="mi">10</span> <span class="mi">14</span><span class="p">:</span><span class="mi">18</span> <span class="n">test_wavs</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">1</span> <span class="n">fangjun</span>  <span class="n">staff</span>    <span class="mi">83</span><span class="n">K</span> <span class="n">Sep</span> <span class="mi">10</span> <span class="mi">14</span><span class="p">:</span><span class="mi">18</span> <span class="n">tokens</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
</section>
<section id="id30">
<h3>Real-time/Streaming Speech recognition from a microphone with VAD<a class="headerlink" href="#id30" title="Permalink to this heading"></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">k2</span><span class="o">-</span><span class="n">fsa</span><span class="o">/</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">/</span><span class="n">releases</span><span class="o">/</span><span class="n">download</span><span class="o">/</span><span class="n">asr</span><span class="o">-</span><span class="n">models</span><span class="o">/</span><span class="n">silero_vad</span><span class="o">.</span><span class="n">onnx</span>

<span class="o">./</span><span class="n">build</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">vad</span><span class="o">-</span><span class="n">microphone</span><span class="o">-</span><span class="n">simulated</span><span class="o">-</span><span class="n">streaming</span><span class="o">-</span><span class="n">asr</span> \
  <span class="o">--</span><span class="n">silero</span><span class="o">-</span><span class="n">vad</span><span class="o">-</span><span class="n">model</span><span class="o">=./</span><span class="n">silero_vad</span><span class="o">.</span><span class="n">onnx</span> \
  <span class="o">--</span><span class="n">tokens</span><span class="o">=./</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">yue</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">en</span><span class="o">-</span><span class="n">cantonese</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">10</span><span class="o">/</span><span class="n">tokens</span><span class="o">.</span><span class="n">txt</span> \
  <span class="o">--</span><span class="n">wenet</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">model</span><span class="o">=./</span><span class="n">sherpa</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="n">wenetspeech</span><span class="o">-</span><span class="n">yue</span><span class="o">-</span><span class="n">u2pp</span><span class="o">-</span><span class="n">conformer</span><span class="o">-</span><span class="n">ctc</span><span class="o">-</span><span class="n">zh</span><span class="o">-</span><span class="n">en</span><span class="o">-</span><span class="n">cantonese</span><span class="o">-</span><span class="n">int8</span><span class="o">-</span><span class="mi">2025</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">10</span><span class="o">/</span><span class="n">model</span><span class="o">.</span><span class="n">int8</span><span class="o">.</span><span class="n">onnx</span> \
  <span class="o">--</span><span class="n">num</span><span class="o">-</span><span class="n">threads</span><span class="o">=</span><span class="mi">1</span>
</pre></div>
</div>
</section>
<section id="id31">
<h3>Decode wave files<a class="headerlink" href="#id31" title="Permalink to this heading"></a></h3>
<section id="yue-0-wav">
<h4>yue-0.wav<a class="headerlink" href="#yue-0-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-0.wav</td>
    <td>
     <audio title="yue-0.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-0.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    两只小企鹅都有嘢食
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-0.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-0.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-0.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;两只小企鹅都有嘢食&quot;, &quot;timestamps&quot;: [0.48, 0.68, 0.92, 1.16, 1.36, 1.84, 2.00, 2.20, 2.40], &quot;tokens&quot;:[&quot;两&quot;, &quot;只&quot;, &quot;小&quot;, &quot;企&quot;, &quot;鹅&quot;, &quot;都&quot;, &quot;有&quot;, &quot;嘢&quot;, &quot;食&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.226 s
Real time factor (RTF): 0.226 / 3.072 = 0.074
</pre></div>
</div>
</section>
<section id="yue-1-wav">
<h4>yue-1.wav<a class="headerlink" href="#yue-1-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-1.wav</td>
    <td>
     <audio title="yue-1.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-1.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    叫做诶诶直入式你个脑部里边咧记得呢一个嘅以前香港有一个广告好出名嘅佢乜嘢都冇噶净系影住喺弥敦道佢哋间铺头嘅啫但系就不停有人嗌啦平平吧平吧
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-1.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-1.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-1.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;叫做诶诶直入式你个脑部里边咧记得呢一个嘅以前香港有一个广告好出名嘅佢乜嘢都冇噶净系影住喺弥敦道佢哋间铺头嘅啫但系就不停有人嗌啦平平吧平吧&quot;, &quot;timestamps&quot;: [0.04, 0.16, 0.36, 0.84, 1.16, 1.40, 1.64, 1.88, 2.00, 2.24, 2.56, 2.76, 2.92, 3.08, 3.28, 3.44, 3.60, 3.68, 3.80, 4.00, 4.20, 4.36, 4.52, 4.64, 4.76, 4.84, 4.92, 5.04, 5.16, 5.32, 5.48, 5.64, 5.88, 6.48, 6.64, 6.80, 6.92, 7.08, 7.24, 7.60, 7.72, 7.88, 8.04, 8.16, 8.36, 8.52, 8.72, 8.88, 9.00, 9.20, 9.36, 9.48, 9.64, 9.80, 10.12, 10.20, 10.32, 10.52, 10.64, 10.80, 10.88, 11.04, 11.24, 12.04, 12.84, 13.08, 13.96, 14.20], &quot;tokens&quot;:[&quot;叫&quot;, &quot;做&quot;, &quot;诶&quot;, &quot;诶&quot;, &quot;直&quot;, &quot;入&quot;, &quot;式&quot;, &quot;你&quot;, &quot;个&quot;, &quot;脑&quot;, &quot;部&quot;, &quot;里&quot;, &quot;边&quot;, &quot;咧&quot;, &quot;记&quot;, &quot;得&quot;, &quot;呢&quot;, &quot;一&quot;, &quot;个&quot;, &quot;嘅&quot;, &quot;以&quot;, &quot;前&quot;, &quot;香&quot;, &quot;港&quot;, &quot;有&quot;, &quot;一&quot;, &quot;个&quot;, &quot;广&quot;, &quot;告&quot;, &quot;好&quot;, &quot;出&quot;, &quot;名&quot;, &quot;嘅&quot;, &quot;佢&quot;, &quot;乜&quot;, &quot;嘢&quot;, &quot;都&quot;, &quot;冇&quot;, &quot;噶&quot;, &quot;净&quot;, &quot;系&quot;, &quot;影&quot;, &quot;住&quot;, &quot;喺&quot;, &quot;弥&quot;, &quot;敦&quot;, &quot;道&quot;, &quot;佢&quot;, &quot;哋&quot;, &quot;间&quot;, &quot;铺&quot;, &quot;头&quot;, &quot;嘅&quot;, &quot;啫&quot;, &quot;但&quot;, &quot;系&quot;, &quot;就&quot;, &quot;不&quot;, &quot;停&quot;, &quot;有&quot;, &quot;人&quot;, &quot;嗌&quot;, &quot;啦&quot;, &quot;平&quot;, &quot;平&quot;, &quot;吧&quot;, &quot;平&quot;, &quot;吧&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 1.185 s
Real time factor (RTF): 1.185 / 15.104 = 0.078
</pre></div>
</div>
</section>
<section id="yue-2-wav">
<h4>yue-2.wav<a class="headerlink" href="#yue-2-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-2.wav</td>
    <td>
     <audio title="yue-2.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-2.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    忽然从光线死角嘅阴影度窜出一只大猫
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-2.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-2.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-2.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;忽然从光线死角嘅阴影度传出一只大猫&quot;, &quot;timestamps&quot;: [0.44, 0.56, 1.16, 1.36, 1.64, 1.92, 2.12, 2.24, 2.36, 2.56, 2.80, 3.16, 3.36, 3.52, 3.64, 3.80, 3.96], &quot;tokens&quot;:[&quot;忽&quot;, &quot;然&quot;, &quot;从&quot;, &quot;光&quot;, &quot;线&quot;, &quot;死&quot;, &quot;角&quot;, &quot;嘅&quot;, &quot;阴&quot;, &quot;影&quot;, &quot;度&quot;, &quot;传&quot;, &quot;出&quot;, &quot;一&quot;, &quot;只&quot;, &quot;大&quot;, &quot;猫&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.369 s
Real time factor (RTF): 0.369 / 4.608 = 0.080
</pre></div>
</div>
</section>
<section id="yue-3-wav">
<h4>yue-3.wav<a class="headerlink" href="#yue-3-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-3.wav</td>
    <td>
     <audio title="yue-3.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-3.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    今日我带大家去见识一位九零后嘅靓仔咧
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-3.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-3.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-3.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;今日我带大家去见识一位九零后嘅靓仔咧&quot;, &quot;timestamps&quot;: [0.32, 0.48, 0.60, 0.72, 0.92, 1.08, 1.56, 1.76, 1.96, 2.12, 2.24, 2.56, 2.80, 3.04, 3.20, 3.36, 3.56, 3.80], &quot;tokens&quot;:[&quot;今&quot;, &quot;日&quot;, &quot;我&quot;, &quot;带&quot;, &quot;大&quot;, &quot;家&quot;, &quot;去&quot;, &quot;见&quot;, &quot;识&quot;, &quot;一&quot;, &quot;位&quot;, &quot;九&quot;, &quot;零&quot;, &quot;后&quot;, &quot;嘅&quot;, &quot;靓&quot;, &quot;仔&quot;, &quot;咧&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.380 s
Real time factor (RTF): 0.380 / 4.352 = 0.087
</pre></div>
</div>
</section>
<section id="yue-4-wav">
<h4>yue-4.wav<a class="headerlink" href="#yue-4-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-4.wav</td>
    <td>
     <audio title="yue-4.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-4.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    香港嘅消费市场从此不一样
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-4.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-4.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-4.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;香港嘅消费市场从此不一样&quot;, &quot;timestamps&quot;: [0.44, 0.64, 0.80, 0.96, 1.16, 1.44, 1.64, 1.96, 2.16, 2.44, 2.64, 2.80], &quot;tokens&quot;:[&quot;香&quot;, &quot;港&quot;, &quot;嘅&quot;, &quot;消&quot;, &quot;费&quot;, &quot;市&quot;, &quot;场&quot;, &quot;从&quot;, &quot;此&quot;, &quot;不&quot;, &quot;一&quot;, &quot;样&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.228 s
Real time factor (RTF): 0.228 / 3.200 = 0.071
</pre></div>
</div>
</section>
<section id="yue-5-wav">
<h4>yue-5.wav<a class="headerlink" href="#yue-5-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-5.wav</td>
    <td>
     <audio title="yue-5.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-5.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    景天谂唔到呢个守门嘅弟子竟然咁无礼霎时间面色都变埋
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-5.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-5.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-5.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;景天谂唔到呢个守门嘅弟子竟然咁无礼霎时间面色都变埋&quot;, &quot;timestamps&quot;: [0.52, 0.72, 1.00, 1.12, 1.24, 1.40, 1.52, 1.68, 1.92, 2.08, 2.20, 2.40, 3.12, 3.28, 3.52, 3.92, 4.12, 5.00, 5.24, 5.40, 5.72, 5.92, 6.08, 6.28, 6.52], &quot;tokens&quot;:[&quot;景&quot;, &quot;天&quot;, &quot;谂&quot;, &quot;唔&quot;, &quot;到&quot;, &quot;呢&quot;, &quot;个&quot;, &quot;守&quot;, &quot;门&quot;, &quot;嘅&quot;, &quot;弟&quot;, &quot;子&quot;, &quot;竟&quot;, &quot;然&quot;, &quot;咁&quot;, &quot;无&quot;, &quot;礼&quot;, &quot;霎&quot;, &quot;时&quot;, &quot;间&quot;, &quot;面&quot;, &quot;色&quot;, &quot;都&quot;, &quot;变&quot;, &quot;埋&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.551 s
Real time factor (RTF): 0.551 / 7.168 = 0.077
</pre></div>
</div>
</section>
<section id="yue-6-wav">
<h4>yue-6.wav<a class="headerlink" href="#yue-6-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-6.wav</td>
    <td>
     <audio title="yue-6.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-6.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    六个星期嘅课程包括六堂课同两个测验你唔掌握到基本嘅十九个声母五十六个韵母同九个声调我哋仲针对咗广东话学习者会遇到嘅大樽颈啊以国语为母语人士最难掌握嘅五大韵母教课书唔会教你嘅七种变音同十种变调说话生硬唔自然嘅根本性问题提供全新嘅学习方向等你突破难关
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-6.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-6.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-6.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;六个星期嘅课程包括六堂课同两个测验你只掌握到基本嘅十九个声母五十六个韵母同九个声调我哋仲针对咗广东话学习者会遇到嘅大樽颈啊以国语为母语人士最难掌握嘅五大韵母教课书唔会教你嘅七种变音同十种变调说话生硬唔自然嘅根本性问题提供全新嘅学习方向等你突破难关&quot;, &quot;timestamps&quot;: [0.52, 0.68, 0.92, 1.12, 1.32, 1.44, 1.64, 2.20, 2.40, 2.60, 2.80, 3.04, 3.48, 3.68, 3.84, 4.08, 4.28, 4.92, 5.20, 5.36, 5.52, 5.68, 5.92, 6.12, 6.36, 6.64, 6.84, 7.00, 7.12, 7.32, 7.68, 7.88, 8.04, 8.16, 8.28, 8.52, 8.96, 9.20, 9.40, 9.56, 9.72, 10.16, 10.32, 10.48, 10.60, 10.76, 10.92, 11.16, 11.36, 11.56, 11.72, 11.88, 12.08, 12.44, 12.64, 12.84, 13.04, 13.56, 13.80, 14.04, 14.28, 14.68, 14.84, 15.04, 15.24, 15.48, 15.60, 15.76, 15.96, 16.44, 16.68, 16.92, 17.12, 17.32, 17.76, 17.92, 18.08, 18.32, 18.80, 19.08, 19.28, 19.52, 19.68, 19.84, 20.04, 20.20, 20.40, 20.60, 20.84, 21.04, 21.40, 21.64, 21.80, 22.04, 22.20, 23.16, 23.32, 23.56, 23.80, 24.24, 24.44, 24.64, 24.84, 25.24, 25.48, 25.72, 25.92, 26.08, 26.60, 26.76, 27.04, 27.28, 27.44, 27.56, 27.72, 27.88, 28.08, 28.60, 28.76, 29.32, 29.52, 29.76, 29.96], &quot;tokens&quot;:[&quot;六&quot;, &quot;个&quot;, &quot;星&quot;, &quot;期&quot;, &quot;嘅&quot;, &quot;课&quot;, &quot;程&quot;, &quot;包&quot;, &quot;括&quot;, &quot;六&quot;, &quot;堂&quot;, &quot;课&quot;, &quot;同&quot;, &quot;两&quot;, &quot;个&quot;, &quot;测&quot;, &quot;验&quot;, &quot;你&quot;, &quot;只&quot;, &quot;掌&quot;, &quot;握&quot;, &quot;到&quot;, &quot;基&quot;, &quot;本&quot;, &quot;嘅&quot;, &quot;十&quot;, &quot;九&quot;, &quot;个&quot;, &quot;声&quot;, &quot;母&quot;, &quot;五&quot;, &quot;十&quot;, &quot;六&quot;, &quot;个&quot;, &quot;韵&quot;, &quot;母&quot;, &quot;同&quot;, &quot;九&quot;, &quot;个&quot;, &quot;声&quot;, &quot;调&quot;, &quot;我&quot;, &quot;哋&quot;, &quot;仲&quot;, &quot;针&quot;, &quot;对&quot;, &quot;咗&quot;, &quot;广&quot;, &quot;东&quot;, &quot;话&quot;, &quot;学&quot;, &quot;习&quot;, &quot;者&quot;, &quot;会&quot;, &quot;遇&quot;, &quot;到&quot;, &quot;嘅&quot;, &quot;大&quot;, &quot;樽&quot;, &quot;颈&quot;, &quot;啊&quot;, &quot;以&quot;, &quot;国&quot;, &quot;语&quot;, &quot;为&quot;, &quot;母&quot;, &quot;语&quot;, &quot;人&quot;, &quot;士&quot;, &quot;最&quot;, &quot;难&quot;, &quot;掌&quot;, &quot;握&quot;, &quot;嘅&quot;, &quot;五&quot;, &quot;大&quot;, &quot;韵&quot;, &quot;母&quot;, &quot;教&quot;, &quot;课&quot;, &quot;书&quot;, &quot;唔&quot;, &quot;会&quot;, &quot;教&quot;, &quot;你&quot;, &quot;嘅&quot;, &quot;七&quot;, &quot;种&quot;, &quot;变&quot;, &quot;音&quot;, &quot;同&quot;, &quot;十&quot;, &quot;种&quot;, &quot;变&quot;, &quot;调&quot;, &quot;说&quot;, &quot;话&quot;, &quot;生&quot;, &quot;硬&quot;, &quot;唔&quot;, &quot;自&quot;, &quot;然&quot;, &quot;嘅&quot;, &quot;根&quot;, &quot;本&quot;, &quot;性&quot;, &quot;问&quot;, &quot;题&quot;, &quot;提&quot;, &quot;供&quot;, &quot;全&quot;, &quot;新&quot;, &quot;嘅&quot;, &quot;学&quot;, &quot;习&quot;, &quot;方&quot;, &quot;向&quot;, &quot;等&quot;, &quot;你&quot;, &quot;突&quot;, &quot;破&quot;, &quot;难&quot;, &quot;关&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 2.590 s
Real time factor (RTF): 2.590 / 30.592 = 0.085
</pre></div>
</div>
</section>
<section id="yue-7-wav">
<h4>yue-7.wav<a class="headerlink" href="#yue-7-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-7.wav</td>
    <td>
     <audio title="yue-7.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-7.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    同意嘅累积唔系阴同阳嘅累积可以讲三既融合咗一同意融合咗阴同阳
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-7.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-7.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-7.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;同意嘅累积唔系阴同阳嘅累积可以讲三既融合咗一同二融合咗阴同阳&quot;, &quot;timestamps&quot;: [0.64, 0.92, 1.24, 1.40, 1.64, 2.60, 2.80, 3.04, 3.44, 3.76, 4.04, 4.20, 4.40, 5.60, 5.80, 6.08, 6.96, 8.00, 8.24, 8.48, 8.80, 9.36, 9.88, 10.16, 11.28, 11.48, 11.76, 12.16, 12.64, 12.88], &quot;tokens&quot;:[&quot;同&quot;, &quot;意&quot;, &quot;嘅&quot;, &quot;累&quot;, &quot;积&quot;, &quot;唔&quot;, &quot;系&quot;, &quot;阴&quot;, &quot;同&quot;, &quot;阳&quot;, &quot;嘅&quot;, &quot;累&quot;, &quot;积&quot;, &quot;可&quot;, &quot;以&quot;, &quot;讲&quot;, &quot;三&quot;, &quot;既&quot;, &quot;融&quot;, &quot;合&quot;, &quot;咗&quot;, &quot;一&quot;, &quot;同&quot;, &quot;二&quot;, &quot;融&quot;, &quot;合&quot;, &quot;咗&quot;, &quot;阴&quot;, &quot;同&quot;, &quot;阳&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 1.078 s
Real time factor (RTF): 1.078 / 13.900 = 0.078
</pre></div>
</div>
</section>
<section id="yue-8-wav">
<h4>yue-8.wav<a class="headerlink" href="#yue-8-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-8.wav</td>
    <td>
     <audio title="yue-8.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-8.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    而较早前已经复航嘅氹仔北安码头星期五开始增设夜间航班不过两个码头暂时都冇凌晨班次有旅客希望尽快恢复可以留喺澳门长啲时间
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-8.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-8.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-8.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;而较早前已经复航嘅氹仔北安码头星期五开始增设夜间航班不过两个码头暂时都冇凌晨班次有旅客希望尽快恢复可以留喺澳门长啲时间&quot;, &quot;timestamps&quot;: [0.40, 0.56, 0.76, 0.92, 1.16, 1.28, 1.52, 1.68, 1.92, 2.12, 2.32, 2.52, 2.72, 2.92, 3.12, 3.48, 3.64, 3.80, 3.96, 4.16, 4.48, 4.68, 4.92, 5.08, 5.24, 5.40, 6.24, 6.40, 6.68, 6.84, 7.04, 7.20, 7.44, 7.68, 7.88, 8.04, 8.24, 8.40, 8.60, 8.80, 9.60, 9.80, 9.96, 10.12, 10.28, 10.52, 10.72, 10.88, 11.12, 11.68, 11.80, 11.96, 12.12, 12.32, 12.52, 12.76, 12.96, 13.20, 13.40], &quot;tokens&quot;:[&quot;而&quot;, &quot;较&quot;, &quot;早&quot;, &quot;前&quot;, &quot;已&quot;, &quot;经&quot;, &quot;复&quot;, &quot;航&quot;, &quot;嘅&quot;, &quot;氹&quot;, &quot;仔&quot;, &quot;北&quot;, &quot;安&quot;, &quot;码&quot;, &quot;头&quot;, &quot;星&quot;, &quot;期&quot;, &quot;五&quot;, &quot;开&quot;, &quot;始&quot;, &quot;增&quot;, &quot;设&quot;, &quot;夜&quot;, &quot;间&quot;, &quot;航&quot;, &quot;班&quot;, &quot;不&quot;, &quot;过&quot;, &quot;两&quot;, &quot;个&quot;, &quot;码&quot;, &quot;头&quot;, &quot;暂&quot;, &quot;时&quot;, &quot;都&quot;, &quot;冇&quot;, &quot;凌&quot;, &quot;晨&quot;, &quot;班&quot;, &quot;次&quot;, &quot;有&quot;, &quot;旅&quot;, &quot;客&quot;, &quot;希&quot;, &quot;望&quot;, &quot;尽&quot;, &quot;快&quot;, &quot;恢&quot;, &quot;复&quot;, &quot;可&quot;, &quot;以&quot;, &quot;留&quot;, &quot;喺&quot;, &quot;澳&quot;, &quot;门&quot;, &quot;长&quot;, &quot;啲&quot;, &quot;时&quot;, &quot;间&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 1.138 s
Real time factor (RTF): 1.138 / 14.080 = 0.081
</pre></div>
</div>
</section>
<section id="yue-9-wav">
<h4>yue-9.wav<a class="headerlink" href="#yue-9-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-9.wav</td>
    <td>
     <audio title="yue-9.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-9.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    刘备仲马鞭一指蜀兵一齐掩杀过去打到吴兵大败唉刘备八路兵马以雷霆万钧之势啊杀到吴兵啊尸横遍野血流成河
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-9.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-9.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-9.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;刘备仲马鞭一指蜀兵一齐掩杀过去打到吴兵大败嘿刘备八路兵马以雷霆万军之势啊杀到吴兵啊尸横遍野血流成河&quot;, &quot;timestamps&quot;: [0.44, 0.64, 0.80, 1.00, 1.20, 1.36, 1.48, 2.44, 2.64, 2.88, 3.20, 3.44, 3.68, 3.88, 4.04, 4.36, 4.56, 4.80, 5.00, 5.28, 5.48, 6.24, 6.72, 6.96, 7.40, 7.64, 7.84, 8.08, 8.76, 9.00, 9.24, 9.48, 9.68, 9.92, 10.12, 10.28, 10.44, 10.64, 10.84, 11.04, 11.24, 11.80, 12.20, 12.48, 12.76, 13.00, 13.20, 13.40, 13.60], &quot;tokens&quot;:[&quot;刘&quot;, &quot;备&quot;, &quot;仲&quot;, &quot;马&quot;, &quot;鞭&quot;, &quot;一&quot;, &quot;指&quot;, &quot;蜀&quot;, &quot;兵&quot;, &quot;一&quot;, &quot;齐&quot;, &quot;掩&quot;, &quot;杀&quot;, &quot;过&quot;, &quot;去&quot;, &quot;打&quot;, &quot;到&quot;, &quot;吴&quot;, &quot;兵&quot;, &quot;大&quot;, &quot;败&quot;, &quot;嘿&quot;, &quot;刘&quot;, &quot;备&quot;, &quot;八&quot;, &quot;路&quot;, &quot;兵&quot;, &quot;马&quot;, &quot;以&quot;, &quot;雷&quot;, &quot;霆&quot;, &quot;万&quot;, &quot;军&quot;, &quot;之&quot;, &quot;势&quot;, &quot;啊&quot;, &quot;杀&quot;, &quot;到&quot;, &quot;吴&quot;, &quot;兵&quot;, &quot;啊&quot;, &quot;尸&quot;, &quot;横&quot;, &quot;遍&quot;, &quot;野&quot;, &quot;血&quot;, &quot;流&quot;, &quot;成&quot;, &quot;河&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 1.116 s
Real time factor (RTF): 1.116 / 14.336 = 0.078
</pre></div>
</div>
</section>
<section id="yue-10-wav">
<h4>yue-10.wav<a class="headerlink" href="#yue-10-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-10.wav</td>
    <td>
     <audio title="yue-10.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-10.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    原来王力宏咧系佢家中里面咧成就最低个吓哇
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-10.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-10.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-10.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;原来王力宏呢系佢家中里边咧成就最低个吓&quot;, &quot;timestamps&quot;: [0.44, 0.60, 0.92, 1.28, 1.52, 1.68, 1.84, 1.96, 2.20, 2.44, 2.60, 2.76, 2.88, 3.08, 3.32, 3.60, 3.80, 4.20, 5.00], &quot;tokens&quot;:[&quot;原&quot;, &quot;来&quot;, &quot;王&quot;, &quot;力&quot;, &quot;宏&quot;, &quot;呢&quot;, &quot;系&quot;, &quot;佢&quot;, &quot;家&quot;, &quot;中&quot;, &quot;里&quot;, &quot;边&quot;, &quot;咧&quot;, &quot;成&quot;, &quot;就&quot;, &quot;最&quot;, &quot;低&quot;, &quot;个&quot;, &quot;吓&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.481 s
Real time factor (RTF): 0.481 / 6.656 = 0.072
</pre></div>
</div>
</section>
<section id="yue-11-wav">
<h4>yue-11.wav<a class="headerlink" href="#yue-11-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-11.wav</td>
    <td>
     <audio title="yue-11.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-11.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    无论你提出任何嘅要求
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-11.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-11.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-11.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;无论你提出任何嘅要求&quot;, &quot;timestamps&quot;: [0.56, 0.68, 0.84, 1.00, 1.16, 1.36, 1.56, 1.72, 1.88, 2.08], &quot;tokens&quot;:[&quot;无&quot;, &quot;论&quot;, &quot;你&quot;, &quot;提&quot;, &quot;出&quot;, &quot;任&quot;, &quot;何&quot;, &quot;嘅&quot;, &quot;要&quot;, &quot;求&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.225 s
Real time factor (RTF): 0.225 / 2.688 = 0.084
</pre></div>
</div>
</section>
<section id="yue-12-wav">
<h4>yue-12.wav<a class="headerlink" href="#yue-12-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-12.wav</td>
    <td>
     <audio title="yue-12.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-12.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    咁咁多样材料咁我哋首先第一步处理咗一件
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-12.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-12.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-12.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;咁咁多样材料咁我哋首先第一步处理咗一件&quot;, &quot;timestamps&quot;: [0.52, 0.76, 0.96, 1.16, 1.36, 1.60, 2.00, 2.12, 2.24, 2.36, 2.60, 2.84, 3.00, 3.24, 3.68, 3.88, 4.04, 4.16, 4.28], &quot;tokens&quot;:[&quot;咁&quot;, &quot;咁&quot;, &quot;多&quot;, &quot;样&quot;, &quot;材&quot;, &quot;料&quot;, &quot;咁&quot;, &quot;我&quot;, &quot;哋&quot;, &quot;首&quot;, &quot;先&quot;, &quot;第&quot;, &quot;一&quot;, &quot;步&quot;, &quot;处&quot;, &quot;理&quot;, &quot;咗&quot;, &quot;一&quot;, &quot;件&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.355 s
Real time factor (RTF): 0.355 / 4.864 = 0.073
</pre></div>
</div>
</section>
<section id="yue-13-wav">
<h4>yue-13.wav<a class="headerlink" href="#yue-13-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-13.wav</td>
    <td>
     <audio title="yue-13.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-13.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    啲点样对于佢哋嘅服务态度啊不透过呢一年左右嘅时间啦其实大家都静一静啦咁你就会见到香港嘅经济其实
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-13.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-13.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-13.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;啲点样对于佢哋嘅服务态度啊当透过呢一年左右嘅时间啦其实大家都静一静啦咁你就会见到香港嘅经济其实&quot;, &quot;timestamps&quot;: [0.04, 0.24, 0.44, 0.72, 0.88, 1.08, 1.28, 1.88, 2.16, 2.36, 2.60, 2.84, 3.04, 3.32, 3.52, 3.76, 4.04, 4.32, 4.60, 4.80, 5.04, 5.24, 5.36, 5.56, 5.76, 6.16, 6.32, 6.48, 6.68, 6.84, 7.08, 7.24, 7.40, 7.60, 8.08, 8.24, 8.40, 8.52, 8.68, 8.84, 9.04, 9.24, 9.40, 9.52, 9.72, 10.00, 10.20], &quot;tokens&quot;:[&quot;啲&quot;, &quot;点&quot;, &quot;样&quot;, &quot;对&quot;, &quot;于&quot;, &quot;佢&quot;, &quot;哋&quot;, &quot;嘅&quot;, &quot;服&quot;, &quot;务&quot;, &quot;态&quot;, &quot;度&quot;, &quot;啊&quot;, &quot;当&quot;, &quot;透&quot;, &quot;过&quot;, &quot;呢&quot;, &quot;一&quot;, &quot;年&quot;, &quot;左&quot;, &quot;右&quot;, &quot;嘅&quot;, &quot;时&quot;, &quot;间&quot;, &quot;啦&quot;, &quot;其&quot;, &quot;实&quot;, &quot;大&quot;, &quot;家&quot;, &quot;都&quot;, &quot;静&quot;, &quot;一&quot;, &quot;静&quot;, &quot;啦&quot;, &quot;咁&quot;, &quot;你&quot;, &quot;就&quot;, &quot;会&quot;, &quot;见&quot;, &quot;到&quot;, &quot;香&quot;, &quot;港&quot;, &quot;嘅&quot;, &quot;经&quot;, &quot;济&quot;, &quot;其&quot;, &quot;实&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.817 s
Real time factor (RTF): 0.817 / 10.624 = 0.077
</pre></div>
</div>
</section>
<section id="yue-14-wav">
<h4>yue-14.wav<a class="headerlink" href="#yue-14-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-14.wav</td>
    <td>
     <audio title="yue-14.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-14.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    就即刻会同贵正两位八代长老带埋五名七代弟子前啲灵蛇岛想话生擒谢信抢咗屠龙宝刀翻嚟献俾帮主嘅
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-14.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-14.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-14.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;就即刻会同贵正两位八代长老带埋五零七代弟子前啲灵蛇岛想话生擒谢信抢咗屠龙堡都翻嚟献俾帮主嘅&quot;, &quot;timestamps&quot;: [0.28, 0.40, 0.52, 0.72, 0.96, 1.24, 1.52, 1.80, 1.92, 2.12, 2.32, 2.60, 2.84, 3.72, 3.88, 4.20, 4.44, 4.64, 4.84, 5.08, 5.28, 6.00, 6.12, 6.32, 6.56, 6.84, 7.80, 8.00, 8.36, 8.64, 9.00, 9.24, 10.12, 10.28, 10.52, 10.72, 10.92, 11.12, 11.28, 11.48, 11.76, 11.92, 12.16, 12.40, 12.64], &quot;tokens&quot;:[&quot;就&quot;, &quot;即&quot;, &quot;刻&quot;, &quot;会&quot;, &quot;同&quot;, &quot;贵&quot;, &quot;正&quot;, &quot;两&quot;, &quot;位&quot;, &quot;八&quot;, &quot;代&quot;, &quot;长&quot;, &quot;老&quot;, &quot;带&quot;, &quot;埋&quot;, &quot;五&quot;, &quot;零&quot;, &quot;七&quot;, &quot;代&quot;, &quot;弟&quot;, &quot;子&quot;, &quot;前&quot;, &quot;啲&quot;, &quot;灵&quot;, &quot;蛇&quot;, &quot;岛&quot;, &quot;想&quot;, &quot;话&quot;, &quot;生&quot;, &quot;擒&quot;, &quot;谢&quot;, &quot;信&quot;, &quot;抢&quot;, &quot;咗&quot;, &quot;屠&quot;, &quot;龙&quot;, &quot;堡&quot;, &quot;都&quot;, &quot;翻&quot;, &quot;嚟&quot;, &quot;献&quot;, &quot;俾&quot;, &quot;帮&quot;, &quot;主&quot;, &quot;嘅&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 1.000 s
Real time factor (RTF): 1.000 / 13.056 = 0.077
</pre></div>
</div>
</section>
<section id="yue-15-wav">
<h4>yue-15.wav<a class="headerlink" href="#yue-15-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-15.wav</td>
    <td>
     <audio title="yue-15.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-15.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    我知道我的观众大部分都是对广东话有兴趣想学广东话的人
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-15.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-15.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-15.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;我知道我嘅观众大部分都系对广东话有兴趣想学广东话嘅人&quot;, &quot;timestamps&quot;: [0.44, 0.56, 0.72, 0.84, 1.00, 1.12, 1.36, 2.08, 2.28, 2.48, 2.68, 2.80, 2.96, 3.12, 3.32, 3.48, 3.64, 3.84, 4.04, 4.80, 5.00, 5.20, 5.40, 5.56, 5.76, 5.92], &quot;tokens&quot;:[&quot;我&quot;, &quot;知&quot;, &quot;道&quot;, &quot;我&quot;, &quot;嘅&quot;, &quot;观&quot;, &quot;众&quot;, &quot;大&quot;, &quot;部&quot;, &quot;分&quot;, &quot;都&quot;, &quot;系&quot;, &quot;对&quot;, &quot;广&quot;, &quot;东&quot;, &quot;话&quot;, &quot;有&quot;, &quot;兴&quot;, &quot;趣&quot;, &quot;想&quot;, &quot;学&quot;, &quot;广&quot;, &quot;东&quot;, &quot;话&quot;, &quot;嘅&quot;, &quot;人&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.453 s
Real time factor (RTF): 0.453 / 6.400 = 0.071
</pre></div>
</div>
</section>
<section id="yue-16-wav">
<h4>yue-16.wav<a class="headerlink" href="#yue-16-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-16.wav</td>
    <td>
     <audio title="yue-16.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-16.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    诶原来啊我哋中国人呢讲究物极必反
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-16.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-16.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-16.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;啊原来啊我哋中国人呢讲究密极必反&quot;, &quot;timestamps&quot;: [1.80, 1.92, 2.08, 2.24, 2.72, 2.84, 3.00, 3.20, 3.40, 3.56, 3.72, 3.88, 4.08, 4.28, 4.48, 4.76], &quot;tokens&quot;:[&quot;啊&quot;, &quot;原&quot;, &quot;来&quot;, &quot;啊&quot;, &quot;我&quot;, &quot;哋&quot;, &quot;中&quot;, &quot;国&quot;, &quot;人&quot;, &quot;呢&quot;, &quot;讲&quot;, &quot;究&quot;, &quot;密&quot;, &quot;极&quot;, &quot;必&quot;, &quot;反&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 0.467 s
Real time factor (RTF): 0.467 / 5.700 = 0.082
</pre></div>
</div>
</section>
<section id="yue-17-wav">
<h4>yue-17.wav<a class="headerlink" href="#yue-17-wav" title="Permalink to this heading"></a></h4>
<table>
  <tr>
    <th>Wave filename</th>
    <th>Content</th>
    <th>Ground truth</th>
  </tr>
  <tr>
    <td>yue-17.wav</td>
    <td>
     <audio title="yue-17.wav" controls="controls">
           <source src="/sherpa/_static/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-int8-2025-09-09/yue-17.wav" type="audio/wav">
           Your browser does not support the <code>audio</code> element.
     </audio>
    </td>
    <td>
    如果东边道建成咁丹东呢就会成为最近嘅出海港同埋经过哈大线出海相比绥分河则会减少运渠三百五十六公里
    </td>
  </tr>
</table><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build/bin/sherpa-onnx-offline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--tokens<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--wenet-ctc-model<span class="o">=</span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num-threads<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-17.wav
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/Users/fangjun/open-source/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:372 ./build/bin/sherpa-onnx-offline --tokens=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt --wenet-ctc-model=./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx --num-threads=1 sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-17.wav 

OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0, normalize_samples=True, snip_edges=False), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=&quot;&quot;, decoder_filename=&quot;&quot;, joiner_filename=&quot;&quot;), paraformer=OfflineParaformerModelConfig(model=&quot;&quot;), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=&quot;&quot;), whisper=OfflineWhisperModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, language=&quot;&quot;, task=&quot;transcribe&quot;, tail_paddings=-1), fire_red_asr=OfflineFireRedAsrModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;), tdnn=OfflineTdnnModelConfig(model=&quot;&quot;), zipformer_ctc=OfflineZipformerCtcModelConfig(model=&quot;&quot;), wenet_ctc=OfflineWenetCtcModelConfig(model=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/model.int8.onnx&quot;), sense_voice=OfflineSenseVoiceModelConfig(model=&quot;&quot;, language=&quot;auto&quot;, use_itn=False), moonshine=OfflineMoonshineModelConfig(preprocessor=&quot;&quot;, encoder=&quot;&quot;, uncached_decoder=&quot;&quot;, cached_decoder=&quot;&quot;), dolphin=OfflineDolphinModelConfig(model=&quot;&quot;), canary=OfflineCanaryModelConfig(encoder=&quot;&quot;, decoder=&quot;&quot;, src_lang=&quot;&quot;, tgt_lang=&quot;&quot;, use_pnc=True), telespeech_ctc=&quot;&quot;, tokens=&quot;./sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/tokens.txt&quot;, num_threads=1, debug=False, provider=&quot;cpu&quot;, model_type=&quot;&quot;, modeling_unit=&quot;cjkchar&quot;, bpe_vocab=&quot;&quot;), lm_config=OfflineLMConfig(model=&quot;&quot;, scale=0.5, lodr_scale=0.01, lodr_fst=&quot;&quot;, lodr_backoff_id=-1), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=&quot;&quot;, max_active=3000), decoding_method=&quot;greedy_search&quot;, max_active_paths=4, hotwords_file=&quot;&quot;, hotwords_score=1.5, blank_penalty=0, rule_fsts=&quot;&quot;, rule_fars=&quot;&quot;, hr=HomophoneReplacerConfig(dict_dir=&quot;&quot;, lexicon=&quot;&quot;, rule_fsts=&quot;&quot;))
Creating recognizer ...
Started
Done!

sherpa-onnx-wenetspeech-yue-u2pp-conformer-ctc-zh-en-cantonese-int8-2025-09-10/test_wavs/yue-17.wav
{&quot;lang&quot;: &quot;&quot;, &quot;emotion&quot;: &quot;&quot;, &quot;event&quot;: &quot;&quot;, &quot;text&quot;: &quot;如果东边道建城咁丹东呢就会成为最近嘅出海港同埋经过哈大线出海相比绥分河将会减少运距三百五十六公里&quot;, &quot;timestamps&quot;: [0.52, 0.64, 0.84, 1.04, 1.28, 1.52, 1.80, 2.72, 2.96, 3.20, 3.44, 3.96, 4.08, 4.24, 4.40, 4.60, 4.76, 4.92, 5.08, 5.20, 5.44, 6.48, 6.60, 6.80, 6.96, 7.12, 7.36, 7.56, 7.76, 7.96, 8.16, 8.36, 9.40, 9.60, 9.88, 10.40, 10.52, 10.68, 10.92, 11.16, 11.36, 11.92, 12.16, 12.32, 12.48, 12.64, 12.80, 13.00], &quot;tokens&quot;:[&quot;如&quot;, &quot;果&quot;, &quot;东&quot;, &quot;边&quot;, &quot;道&quot;, &quot;建&quot;, &quot;城&quot;, &quot;咁&quot;, &quot;丹&quot;, &quot;东&quot;, &quot;呢&quot;, &quot;就&quot;, &quot;会&quot;, &quot;成&quot;, &quot;为&quot;, &quot;最&quot;, &quot;近&quot;, &quot;嘅&quot;, &quot;出&quot;, &quot;海&quot;, &quot;港&quot;, &quot;同&quot;, &quot;埋&quot;, &quot;经&quot;, &quot;过&quot;, &quot;哈&quot;, &quot;大&quot;, &quot;线&quot;, &quot;出&quot;, &quot;海&quot;, &quot;相&quot;, &quot;比&quot;, &quot;绥&quot;, &quot;分&quot;, &quot;河&quot;, &quot;将&quot;, &quot;会&quot;, &quot;减&quot;, &quot;少&quot;, &quot;运&quot;, &quot;距&quot;, &quot;三&quot;, &quot;百&quot;, &quot;五&quot;, &quot;十&quot;, &quot;六&quot;, &quot;公&quot;, &quot;里&quot;], &quot;words&quot;: []}
----
num threads: 1
decoding method: greedy_search
Elapsed seconds: 1.039 s
Real time factor (RTF): 1.039 / 13.800 = 0.075
</pre></div>
</div>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../nemo/japanese.html" class="btn btn-neutral float-left" title="Japanese" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../yesno/index.html" class="btn btn-neutral float-right" title="yesno" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022-2026, sherpa development team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>